{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "# !wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "# !dpkg -i libta.deb ta.deb\n",
        "# !pip install ta-lib"
      ],
      "metadata": {
        "id": "ICVDGwhNIp6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75326d28-981a-438d-ba72-21f5caf54fa1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libta-lib0.\n",
            "(Reading database ... 123598 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) ...\n",
            "Selecting previously unselected package ta-lib0-dev.\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting ta-lib\n",
            "  Downloading TA-Lib-0.4.32.tar.gz (368 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.5/368.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta-lib) (1.26.4)\n",
            "Building wheels for collected packages: ta-lib\n",
            "  Building wheel for ta-lib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta-lib: filename=TA_Lib-0.4.32-cp310-cp310-linux_x86_64.whl size=2063397 sha256=eb952d6d3597ae8875fa683521a08614bd65f0bc1d3afc336cbc281325e93358\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/21/bd/ca95eb09997c2a18fce271b98b10ffa9fcafbaa161be864dd7\n",
            "Successfully built ta-lib\n",
            "Installing collected packages: ta-lib\n",
            "Successfully installed ta-lib-0.4.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import talib as ta\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "czhfbe6OcXex"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jw64KFZ2BrgQ"
      },
      "outputs": [],
      "source": [
        "def calculate_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "class TechnicalIndicators:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def add_momentum_indicators(self):\n",
        "        self.data['RSI'] = ta.RSI(self.data['Close'], timeperiod=14)\n",
        "        self.data['MACD'], self.data['MACD_signal'], self.data['MACD_hist'] = ta.MACD(self.data['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "        self.data['Stoch_k'], self.data['Stoch_d'] = ta.STOCH(self.data['High'], self.data['Low'], self.data['Close'],\n",
        "                                                              fastk_period=14, slowk_period=3, slowd_period=3)\n",
        "\n",
        "    def add_volume_indicators(self):\n",
        "        self.data['OBV'] = ta.OBV(self.data['Close'], self.data['Volume'])\n",
        "\n",
        "    def add_volatility_indicators(self):\n",
        "        self.data['Upper_BB'], self.data['Middle_BB'], self.data['Lower_BB'] = ta.BBANDS(self.data['Close'], timeperiod=20)\n",
        "        self.data['ATR_1'] = ta.ATR(self.data['High'], self.data['Low'], self.data['Close'], timeperiod=1)\n",
        "\n",
        "    def add_trend_indicators(self):\n",
        "        self.data['ADX'] = ta.ADX(self.data['High'], self.data['Low'], self.data['Close'], timeperiod=14)\n",
        "        self.data['+DI'] = ta.PLUS_DI(self.data['High'], self.data['Low'], self.data['Close'], timeperiod=14)\n",
        "        self.data['-DI'] = ta.MINUS_DI(self.data['High'], self.data['Low'], self.data['Close'], timeperiod=14)\n",
        "\n",
        "    def add_other_indicators(self):\n",
        "        self.data['DLR'] = np.log(self.data['Close'] / self.data['Close'].shift(1))\n",
        "        self.data['VWAP'] = (self.data['Volume'] * (self.data['High'] + self.data['Low']) / 2).cumsum() / self.data['Volume'].cumsum()\n",
        "\n",
        "    def add_all_indicators(self):\n",
        "        self.add_momentum_indicators()\n",
        "        self.add_volume_indicators()\n",
        "        self.add_volatility_indicators()\n",
        "        self.add_trend_indicators()\n",
        "        self.add_other_indicators()\n",
        "        return self.data\n",
        "\n",
        "data = pd.read_csv('/content/xnas-itch-20230703.tbbo.csv')\n",
        "\n",
        "data['price'] = data['price'] / 1e9\n",
        "data['bid_px_00'] = data['bid_px_00'] / 1e9\n",
        "data['ask_px_00'] = data['ask_px_00'] / 1e9\n",
        "\n",
        "data['Close'] = data['price']\n",
        "data['Volume'] = data['size']\n",
        "data['High'] = data[['bid_px_00', 'ask_px_00']].max(axis=1)\n",
        "data['Low'] = data[['bid_px_00', 'ask_px_00']].min(axis=1)\n",
        "data['Open'] = data['Close'].shift(1).fillna(data['Close'])\n",
        "\n",
        "data['ts_event'] = pd.to_datetime(data['ts_event'])\n",
        "data['hour'] = data['ts_event'].dt.hour\n",
        "data['day_of_week'] = data['ts_event'].dt.dayofweek\n",
        "data['month'] = data['ts_event'].dt.month\n",
        "\n",
        "ti = TechnicalIndicators(data)\n",
        "df_with_indicators = ti.add_all_indicators()\n",
        "\n",
        "df_with_indicators['RSI'] = calculate_rsi(df_with_indicators['Close'], period=14)\n",
        "\n",
        "df_with_indicators['signal'] = 1  # Default to Hold\n",
        "\n",
        "df_with_indicators.loc[df_with_indicators['RSI'] < 30, 'signal'] = 2  # Buy\n",
        "df_with_indicators.loc[df_with_indicators['RSI'] > 70, 'signal'] = 0  # Sell\n",
        "\n",
        "market_features_df = df_with_indicators.dropna()\n",
        "\n",
        "feature_columns = [\n",
        "    'Close',        # Closing price of the asset\n",
        "    'Volume',       # Trading volume\n",
        "    'High',         # High price within the period\n",
        "    'Low',          # Low price within the period\n",
        "    'RSI',          # Relative Strength Index\n",
        "    'MACD',         # Moving Average Convergence Divergence\n",
        "    'MACD_hist',    # MACD Histogram\n",
        "    'OBV',          # On-Balance Volume\n",
        "    'Upper_BB',     # Upper Bollinger Band\n",
        "    'Lower_BB',     # Lower Bollinger Band\n",
        "    'ATR_1',        # Average True Range\n",
        "    'ADX',          # Average Directional Index\n",
        "    'DLR',          # Discrete Log Return\n",
        "    'VWAP',         # Volume Weighted Average Price\n",
        "    'hour',         # Hour of the day\n",
        "    'day_of_week',  # Day of the week\n",
        "    'month'         # Month of the year\n",
        "]\n",
        "features = market_features_df[feature_columns].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_features = scaler.fit_transform(features)\n",
        "\n",
        "y = market_features_df['signal'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_features, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "market_features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "cWix8XY-P9wV",
        "outputId": "7fe414c3-fd95-4f05-fe10-0a469c648fab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ts_recv                      ts_event  rtype  publisher_id  \\\n",
              "33  1688371212400094716 2023-07-03 08:00:12.399929624      1             2   \n",
              "34  1688371212400103305 2023-07-03 08:00:12.399937688      1             2   \n",
              "35  1688371214386057385 2023-07-03 08:00:14.385893078      1             2   \n",
              "36  1688371214386063777 2023-07-03 08:00:14.385899379      1             2   \n",
              "37  1688371215804852019 2023-07-03 08:00:15.804687301      1             2   \n",
              "\n",
              "    instrument_id action side  depth   price  size  ...    Upper_BB  \\\n",
              "33             32      T    B      0  194.05   112  ...  194.058166   \n",
              "34             32      T    B      0  194.05    56  ...  194.061497   \n",
              "35             32      T    N      0  194.05    50  ...  194.065621   \n",
              "36             32      T    N      0  194.05    50  ...  194.068990   \n",
              "37             32      T    B      0  194.21    10  ...  194.125889   \n",
              "\n",
              "    Middle_BB    Lower_BB  ATR_1        ADX        +DI       -DI       DLR  \\\n",
              "33   194.0100  193.961834   0.05  97.468037   8.229490  0.300857  0.000000   \n",
              "34   194.0140  193.966503   0.05  97.145048   7.681639  0.280828  0.000000   \n",
              "35   194.0170  193.968379   0.30  97.257397  30.435801  0.196362  0.000000   \n",
              "36   194.0200  193.971010   0.30  97.361721  22.989295  0.148320  0.000000   \n",
              "37   194.0305  193.935111   0.21  97.458593  19.409454  0.125224  0.000824   \n",
              "\n",
              "          VWAP signal  \n",
              "33  194.018217      0  \n",
              "34  194.018423      0  \n",
              "35  194.021894      0  \n",
              "36  194.025188      0  \n",
              "37  194.025596      0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d55fb54-48f7-46e3-8a36-19b6d17e9d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts_recv</th>\n",
              "      <th>ts_event</th>\n",
              "      <th>rtype</th>\n",
              "      <th>publisher_id</th>\n",
              "      <th>instrument_id</th>\n",
              "      <th>action</th>\n",
              "      <th>side</th>\n",
              "      <th>depth</th>\n",
              "      <th>price</th>\n",
              "      <th>size</th>\n",
              "      <th>...</th>\n",
              "      <th>Upper_BB</th>\n",
              "      <th>Middle_BB</th>\n",
              "      <th>Lower_BB</th>\n",
              "      <th>ATR_1</th>\n",
              "      <th>ADX</th>\n",
              "      <th>+DI</th>\n",
              "      <th>-DI</th>\n",
              "      <th>DLR</th>\n",
              "      <th>VWAP</th>\n",
              "      <th>signal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1688371212400094716</td>\n",
              "      <td>2023-07-03 08:00:12.399929624</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>T</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>194.05</td>\n",
              "      <td>112</td>\n",
              "      <td>...</td>\n",
              "      <td>194.058166</td>\n",
              "      <td>194.0100</td>\n",
              "      <td>193.961834</td>\n",
              "      <td>0.05</td>\n",
              "      <td>97.468037</td>\n",
              "      <td>8.229490</td>\n",
              "      <td>0.300857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.018217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1688371212400103305</td>\n",
              "      <td>2023-07-03 08:00:12.399937688</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>T</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>194.05</td>\n",
              "      <td>56</td>\n",
              "      <td>...</td>\n",
              "      <td>194.061497</td>\n",
              "      <td>194.0140</td>\n",
              "      <td>193.966503</td>\n",
              "      <td>0.05</td>\n",
              "      <td>97.145048</td>\n",
              "      <td>7.681639</td>\n",
              "      <td>0.280828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.018423</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1688371214386057385</td>\n",
              "      <td>2023-07-03 08:00:14.385893078</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>T</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>194.05</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>194.065621</td>\n",
              "      <td>194.0170</td>\n",
              "      <td>193.968379</td>\n",
              "      <td>0.30</td>\n",
              "      <td>97.257397</td>\n",
              "      <td>30.435801</td>\n",
              "      <td>0.196362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.021894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1688371214386063777</td>\n",
              "      <td>2023-07-03 08:00:14.385899379</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>T</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>194.05</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>194.068990</td>\n",
              "      <td>194.0200</td>\n",
              "      <td>193.971010</td>\n",
              "      <td>0.30</td>\n",
              "      <td>97.361721</td>\n",
              "      <td>22.989295</td>\n",
              "      <td>0.148320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.025188</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1688371215804852019</td>\n",
              "      <td>2023-07-03 08:00:15.804687301</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>T</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>194.21</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>194.125889</td>\n",
              "      <td>194.0305</td>\n",
              "      <td>193.935111</td>\n",
              "      <td>0.21</td>\n",
              "      <td>97.458593</td>\n",
              "      <td>19.409454</td>\n",
              "      <td>0.125224</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>194.025596</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d55fb54-48f7-46e3-8a36-19b6d17e9d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d55fb54-48f7-46e3-8a36-19b6d17e9d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d55fb54-48f7-46e3-8a36-19b6d17e9d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0963dff-30b6-46f1-b402-4e0aa18646ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0963dff-30b6-46f1-b402-4e0aa18646ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0963dff-30b6-46f1-b402-4e0aa18646ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "market_features_df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "YwWPmF79Hd8J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TradeSignalBERT(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(TradeSignalBERT, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.embedding_layer = nn.Linear(input_size, self.bert.config.hidden_size)\n",
        "\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)  # 3 classes: Buy, Hold, Sell\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs_embeds = self.embedding_layer(inputs).unsqueeze(1)\n",
        "\n",
        "        attention_mask = torch.ones(inputs_embeds.size()[:2]).to(inputs.device)\n",
        "\n",
        "        outputs = self.bert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.classifier(cls_output)"
      ],
      "metadata": {
        "id": "dz7rzQBtHyOB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "N10uUAr7dpRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TradeSignalBERT(input_size=X_train_tensor.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Step [{step + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAeSg7JqcyYi",
        "outputId": "174f6ecf-0184-40b7-ea01-e35267f3ac7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Step [1/1349], Loss: 1.1136\n",
            "Epoch [1/3], Step [2/1349], Loss: 1.1242\n",
            "Epoch [1/3], Step [3/1349], Loss: 1.0646\n",
            "Epoch [1/3], Step [4/1349], Loss: 1.0499\n",
            "Epoch [1/3], Step [5/1349], Loss: 1.0466\n",
            "Epoch [1/3], Step [6/1349], Loss: 1.0445\n",
            "Epoch [1/3], Step [7/1349], Loss: 1.0830\n",
            "Epoch [1/3], Step [8/1349], Loss: 0.9905\n",
            "Epoch [1/3], Step [9/1349], Loss: 0.9589\n",
            "Epoch [1/3], Step [10/1349], Loss: 0.9856\n",
            "Epoch [1/3], Step [11/1349], Loss: 0.9929\n",
            "Epoch [1/3], Step [12/1349], Loss: 1.0384\n",
            "Epoch [1/3], Step [13/1349], Loss: 0.9490\n",
            "Epoch [1/3], Step [14/1349], Loss: 0.9340\n",
            "Epoch [1/3], Step [15/1349], Loss: 0.8670\n",
            "Epoch [1/3], Step [16/1349], Loss: 0.9906\n",
            "Epoch [1/3], Step [17/1349], Loss: 0.9678\n",
            "Epoch [1/3], Step [18/1349], Loss: 0.9172\n",
            "Epoch [1/3], Step [19/1349], Loss: 0.9936\n",
            "Epoch [1/3], Step [20/1349], Loss: 0.9129\n",
            "Epoch [1/3], Step [21/1349], Loss: 0.8550\n",
            "Epoch [1/3], Step [22/1349], Loss: 0.7828\n",
            "Epoch [1/3], Step [23/1349], Loss: 0.8008\n",
            "Epoch [1/3], Step [24/1349], Loss: 0.7363\n",
            "Epoch [1/3], Step [25/1349], Loss: 0.8352\n",
            "Epoch [1/3], Step [26/1349], Loss: 0.7741\n",
            "Epoch [1/3], Step [27/1349], Loss: 0.8065\n",
            "Epoch [1/3], Step [28/1349], Loss: 0.7034\n",
            "Epoch [1/3], Step [29/1349], Loss: 0.7013\n",
            "Epoch [1/3], Step [30/1349], Loss: 0.6705\n",
            "Epoch [1/3], Step [31/1349], Loss: 0.7216\n",
            "Epoch [1/3], Step [32/1349], Loss: 0.7878\n",
            "Epoch [1/3], Step [33/1349], Loss: 0.7151\n",
            "Epoch [1/3], Step [34/1349], Loss: 0.7753\n",
            "Epoch [1/3], Step [35/1349], Loss: 0.6882\n",
            "Epoch [1/3], Step [36/1349], Loss: 0.5777\n",
            "Epoch [1/3], Step [37/1349], Loss: 0.6814\n",
            "Epoch [1/3], Step [38/1349], Loss: 0.6722\n",
            "Epoch [1/3], Step [39/1349], Loss: 0.5949\n",
            "Epoch [1/3], Step [40/1349], Loss: 0.5804\n",
            "Epoch [1/3], Step [41/1349], Loss: 0.5758\n",
            "Epoch [1/3], Step [42/1349], Loss: 0.6075\n",
            "Epoch [1/3], Step [43/1349], Loss: 0.6216\n",
            "Epoch [1/3], Step [44/1349], Loss: 0.6217\n",
            "Epoch [1/3], Step [45/1349], Loss: 0.5716\n",
            "Epoch [1/3], Step [46/1349], Loss: 0.4146\n",
            "Epoch [1/3], Step [47/1349], Loss: 0.6926\n",
            "Epoch [1/3], Step [48/1349], Loss: 0.6309\n",
            "Epoch [1/3], Step [49/1349], Loss: 0.6245\n",
            "Epoch [1/3], Step [50/1349], Loss: 0.5484\n",
            "Epoch [1/3], Step [51/1349], Loss: 0.4310\n",
            "Epoch [1/3], Step [52/1349], Loss: 0.4417\n",
            "Epoch [1/3], Step [53/1349], Loss: 0.3966\n",
            "Epoch [1/3], Step [54/1349], Loss: 0.5608\n",
            "Epoch [1/3], Step [55/1349], Loss: 0.6547\n",
            "Epoch [1/3], Step [56/1349], Loss: 0.4423\n",
            "Epoch [1/3], Step [57/1349], Loss: 0.4203\n",
            "Epoch [1/3], Step [58/1349], Loss: 0.4946\n",
            "Epoch [1/3], Step [59/1349], Loss: 0.6131\n",
            "Epoch [1/3], Step [60/1349], Loss: 0.4876\n",
            "Epoch [1/3], Step [61/1349], Loss: 0.5490\n",
            "Epoch [1/3], Step [62/1349], Loss: 0.4961\n",
            "Epoch [1/3], Step [63/1349], Loss: 0.4745\n",
            "Epoch [1/3], Step [64/1349], Loss: 0.4327\n",
            "Epoch [1/3], Step [65/1349], Loss: 0.5184\n",
            "Epoch [1/3], Step [66/1349], Loss: 0.5262\n",
            "Epoch [1/3], Step [67/1349], Loss: 0.4061\n",
            "Epoch [1/3], Step [68/1349], Loss: 0.4006\n",
            "Epoch [1/3], Step [69/1349], Loss: 0.3937\n",
            "Epoch [1/3], Step [70/1349], Loss: 0.5269\n",
            "Epoch [1/3], Step [71/1349], Loss: 0.3527\n",
            "Epoch [1/3], Step [72/1349], Loss: 0.4594\n",
            "Epoch [1/3], Step [73/1349], Loss: 0.5300\n",
            "Epoch [1/3], Step [74/1349], Loss: 0.3889\n",
            "Epoch [1/3], Step [75/1349], Loss: 0.5321\n",
            "Epoch [1/3], Step [76/1349], Loss: 0.3960\n",
            "Epoch [1/3], Step [77/1349], Loss: 0.4334\n",
            "Epoch [1/3], Step [78/1349], Loss: 0.3836\n",
            "Epoch [1/3], Step [79/1349], Loss: 0.4781\n",
            "Epoch [1/3], Step [80/1349], Loss: 0.2709\n",
            "Epoch [1/3], Step [81/1349], Loss: 0.5512\n",
            "Epoch [1/3], Step [82/1349], Loss: 0.3672\n",
            "Epoch [1/3], Step [83/1349], Loss: 0.4964\n",
            "Epoch [1/3], Step [84/1349], Loss: 0.3808\n",
            "Epoch [1/3], Step [85/1349], Loss: 0.4835\n",
            "Epoch [1/3], Step [86/1349], Loss: 0.3113\n",
            "Epoch [1/3], Step [87/1349], Loss: 0.2164\n",
            "Epoch [1/3], Step [88/1349], Loss: 0.3308\n",
            "Epoch [1/3], Step [89/1349], Loss: 0.3257\n",
            "Epoch [1/3], Step [90/1349], Loss: 0.3696\n",
            "Epoch [1/3], Step [91/1349], Loss: 0.3127\n",
            "Epoch [1/3], Step [92/1349], Loss: 0.3108\n",
            "Epoch [1/3], Step [93/1349], Loss: 0.2262\n",
            "Epoch [1/3], Step [94/1349], Loss: 0.4218\n",
            "Epoch [1/3], Step [95/1349], Loss: 0.3486\n",
            "Epoch [1/3], Step [96/1349], Loss: 0.2715\n",
            "Epoch [1/3], Step [97/1349], Loss: 0.3634\n",
            "Epoch [1/3], Step [98/1349], Loss: 0.2803\n",
            "Epoch [1/3], Step [99/1349], Loss: 0.4232\n",
            "Epoch [1/3], Step [100/1349], Loss: 0.5844\n",
            "Epoch [1/3], Step [101/1349], Loss: 0.4327\n",
            "Epoch [1/3], Step [102/1349], Loss: 0.3039\n",
            "Epoch [1/3], Step [103/1349], Loss: 0.3739\n",
            "Epoch [1/3], Step [104/1349], Loss: 0.5134\n",
            "Epoch [1/3], Step [105/1349], Loss: 0.2810\n",
            "Epoch [1/3], Step [106/1349], Loss: 0.3999\n",
            "Epoch [1/3], Step [107/1349], Loss: 0.3589\n",
            "Epoch [1/3], Step [108/1349], Loss: 0.5520\n",
            "Epoch [1/3], Step [109/1349], Loss: 0.4106\n",
            "Epoch [1/3], Step [110/1349], Loss: 0.4377\n",
            "Epoch [1/3], Step [111/1349], Loss: 0.3788\n",
            "Epoch [1/3], Step [112/1349], Loss: 0.3369\n",
            "Epoch [1/3], Step [113/1349], Loss: 0.3673\n",
            "Epoch [1/3], Step [114/1349], Loss: 0.3622\n",
            "Epoch [1/3], Step [115/1349], Loss: 0.2977\n",
            "Epoch [1/3], Step [116/1349], Loss: 0.3706\n",
            "Epoch [1/3], Step [117/1349], Loss: 0.3496\n",
            "Epoch [1/3], Step [118/1349], Loss: 0.6319\n",
            "Epoch [1/3], Step [119/1349], Loss: 0.5719\n",
            "Epoch [1/3], Step [120/1349], Loss: 0.2571\n",
            "Epoch [1/3], Step [121/1349], Loss: 0.4576\n",
            "Epoch [1/3], Step [122/1349], Loss: 0.3685\n",
            "Epoch [1/3], Step [123/1349], Loss: 0.3862\n",
            "Epoch [1/3], Step [124/1349], Loss: 0.3388\n",
            "Epoch [1/3], Step [125/1349], Loss: 0.2702\n",
            "Epoch [1/3], Step [126/1349], Loss: 0.3137\n",
            "Epoch [1/3], Step [127/1349], Loss: 0.3793\n",
            "Epoch [1/3], Step [128/1349], Loss: 0.4634\n",
            "Epoch [1/3], Step [129/1349], Loss: 0.3329\n",
            "Epoch [1/3], Step [130/1349], Loss: 0.2372\n",
            "Epoch [1/3], Step [131/1349], Loss: 0.3005\n",
            "Epoch [1/3], Step [132/1349], Loss: 0.5540\n",
            "Epoch [1/3], Step [133/1349], Loss: 0.3178\n",
            "Epoch [1/3], Step [134/1349], Loss: 0.2907\n",
            "Epoch [1/3], Step [135/1349], Loss: 0.2283\n",
            "Epoch [1/3], Step [136/1349], Loss: 0.3981\n",
            "Epoch [1/3], Step [137/1349], Loss: 0.2690\n",
            "Epoch [1/3], Step [138/1349], Loss: 0.3820\n",
            "Epoch [1/3], Step [139/1349], Loss: 0.2417\n",
            "Epoch [1/3], Step [140/1349], Loss: 0.1869\n",
            "Epoch [1/3], Step [141/1349], Loss: 0.2305\n",
            "Epoch [1/3], Step [142/1349], Loss: 0.2932\n",
            "Epoch [1/3], Step [143/1349], Loss: 0.3751\n",
            "Epoch [1/3], Step [144/1349], Loss: 0.3046\n",
            "Epoch [1/3], Step [145/1349], Loss: 0.3583\n",
            "Epoch [1/3], Step [146/1349], Loss: 0.3984\n",
            "Epoch [1/3], Step [147/1349], Loss: 0.3745\n",
            "Epoch [1/3], Step [148/1349], Loss: 0.2969\n",
            "Epoch [1/3], Step [149/1349], Loss: 0.4212\n",
            "Epoch [1/3], Step [150/1349], Loss: 0.1896\n",
            "Epoch [1/3], Step [151/1349], Loss: 0.4081\n",
            "Epoch [1/3], Step [152/1349], Loss: 0.3164\n",
            "Epoch [1/3], Step [153/1349], Loss: 0.2906\n",
            "Epoch [1/3], Step [154/1349], Loss: 0.4000\n",
            "Epoch [1/3], Step [155/1349], Loss: 0.2657\n",
            "Epoch [1/3], Step [156/1349], Loss: 0.3342\n",
            "Epoch [1/3], Step [157/1349], Loss: 0.2296\n",
            "Epoch [1/3], Step [158/1349], Loss: 0.2948\n",
            "Epoch [1/3], Step [159/1349], Loss: 0.1898\n",
            "Epoch [1/3], Step [160/1349], Loss: 0.3445\n",
            "Epoch [1/3], Step [161/1349], Loss: 0.4503\n",
            "Epoch [1/3], Step [162/1349], Loss: 0.4226\n",
            "Epoch [1/3], Step [163/1349], Loss: 0.4487\n",
            "Epoch [1/3], Step [164/1349], Loss: 0.2829\n",
            "Epoch [1/3], Step [165/1349], Loss: 0.2997\n",
            "Epoch [1/3], Step [166/1349], Loss: 0.4153\n",
            "Epoch [1/3], Step [167/1349], Loss: 0.1754\n",
            "Epoch [1/3], Step [168/1349], Loss: 0.1489\n",
            "Epoch [1/3], Step [169/1349], Loss: 0.2900\n",
            "Epoch [1/3], Step [170/1349], Loss: 0.2495\n",
            "Epoch [1/3], Step [171/1349], Loss: 0.3314\n",
            "Epoch [1/3], Step [172/1349], Loss: 0.4134\n",
            "Epoch [1/3], Step [173/1349], Loss: 0.2169\n",
            "Epoch [1/3], Step [174/1349], Loss: 0.1407\n",
            "Epoch [1/3], Step [175/1349], Loss: 0.2362\n",
            "Epoch [1/3], Step [176/1349], Loss: 0.3041\n",
            "Epoch [1/3], Step [177/1349], Loss: 0.2796\n",
            "Epoch [1/3], Step [178/1349], Loss: 0.2472\n",
            "Epoch [1/3], Step [179/1349], Loss: 0.3375\n",
            "Epoch [1/3], Step [180/1349], Loss: 0.3283\n",
            "Epoch [1/3], Step [181/1349], Loss: 0.2620\n",
            "Epoch [1/3], Step [182/1349], Loss: 0.1940\n",
            "Epoch [1/3], Step [183/1349], Loss: 0.2672\n",
            "Epoch [1/3], Step [184/1349], Loss: 0.1525\n",
            "Epoch [1/3], Step [185/1349], Loss: 0.1773\n",
            "Epoch [1/3], Step [186/1349], Loss: 0.3576\n",
            "Epoch [1/3], Step [187/1349], Loss: 0.3367\n",
            "Epoch [1/3], Step [188/1349], Loss: 0.2999\n",
            "Epoch [1/3], Step [189/1349], Loss: 0.2540\n",
            "Epoch [1/3], Step [190/1349], Loss: 0.1449\n",
            "Epoch [1/3], Step [191/1349], Loss: 0.1286\n",
            "Epoch [1/3], Step [192/1349], Loss: 0.3219\n",
            "Epoch [1/3], Step [193/1349], Loss: 0.1429\n",
            "Epoch [1/3], Step [194/1349], Loss: 0.1815\n",
            "Epoch [1/3], Step [195/1349], Loss: 0.2635\n",
            "Epoch [1/3], Step [196/1349], Loss: 0.2846\n",
            "Epoch [1/3], Step [197/1349], Loss: 0.2891\n",
            "Epoch [1/3], Step [198/1349], Loss: 0.3481\n",
            "Epoch [1/3], Step [199/1349], Loss: 0.4185\n",
            "Epoch [1/3], Step [200/1349], Loss: 0.2999\n",
            "Epoch [1/3], Step [201/1349], Loss: 0.1493\n",
            "Epoch [1/3], Step [202/1349], Loss: 0.2627\n",
            "Epoch [1/3], Step [203/1349], Loss: 0.3290\n",
            "Epoch [1/3], Step [204/1349], Loss: 0.1670\n",
            "Epoch [1/3], Step [205/1349], Loss: 0.1776\n",
            "Epoch [1/3], Step [206/1349], Loss: 0.1648\n",
            "Epoch [1/3], Step [207/1349], Loss: 0.2457\n",
            "Epoch [1/3], Step [208/1349], Loss: 0.2261\n",
            "Epoch [1/3], Step [209/1349], Loss: 0.3308\n",
            "Epoch [1/3], Step [210/1349], Loss: 0.2372\n",
            "Epoch [1/3], Step [211/1349], Loss: 0.2196\n",
            "Epoch [1/3], Step [212/1349], Loss: 0.2202\n",
            "Epoch [1/3], Step [213/1349], Loss: 0.1623\n",
            "Epoch [1/3], Step [214/1349], Loss: 0.2421\n",
            "Epoch [1/3], Step [215/1349], Loss: 0.1937\n",
            "Epoch [1/3], Step [216/1349], Loss: 0.3180\n",
            "Epoch [1/3], Step [217/1349], Loss: 0.1837\n",
            "Epoch [1/3], Step [218/1349], Loss: 0.2847\n",
            "Epoch [1/3], Step [219/1349], Loss: 0.2820\n",
            "Epoch [1/3], Step [220/1349], Loss: 0.3787\n",
            "Epoch [1/3], Step [221/1349], Loss: 0.1064\n",
            "Epoch [1/3], Step [222/1349], Loss: 0.2622\n",
            "Epoch [1/3], Step [223/1349], Loss: 0.1506\n",
            "Epoch [1/3], Step [224/1349], Loss: 0.1605\n",
            "Epoch [1/3], Step [225/1349], Loss: 0.1228\n",
            "Epoch [1/3], Step [226/1349], Loss: 0.2747\n",
            "Epoch [1/3], Step [227/1349], Loss: 0.2325\n",
            "Epoch [1/3], Step [228/1349], Loss: 0.3747\n",
            "Epoch [1/3], Step [229/1349], Loss: 0.1250\n",
            "Epoch [1/3], Step [230/1349], Loss: 0.2775\n",
            "Epoch [1/3], Step [231/1349], Loss: 0.2611\n",
            "Epoch [1/3], Step [232/1349], Loss: 0.1948\n",
            "Epoch [1/3], Step [233/1349], Loss: 0.2524\n",
            "Epoch [1/3], Step [234/1349], Loss: 0.2437\n",
            "Epoch [1/3], Step [235/1349], Loss: 0.2560\n",
            "Epoch [1/3], Step [236/1349], Loss: 0.4010\n",
            "Epoch [1/3], Step [237/1349], Loss: 0.3012\n",
            "Epoch [1/3], Step [238/1349], Loss: 0.5036\n",
            "Epoch [1/3], Step [239/1349], Loss: 0.3961\n",
            "Epoch [1/3], Step [240/1349], Loss: 0.3498\n",
            "Epoch [1/3], Step [241/1349], Loss: 0.1562\n",
            "Epoch [1/3], Step [242/1349], Loss: 0.4303\n",
            "Epoch [1/3], Step [243/1349], Loss: 0.2147\n",
            "Epoch [1/3], Step [244/1349], Loss: 0.2369\n",
            "Epoch [1/3], Step [245/1349], Loss: 0.2078\n",
            "Epoch [1/3], Step [246/1349], Loss: 0.5293\n",
            "Epoch [1/3], Step [247/1349], Loss: 0.0892\n",
            "Epoch [1/3], Step [248/1349], Loss: 0.2565\n",
            "Epoch [1/3], Step [249/1349], Loss: 0.2089\n",
            "Epoch [1/3], Step [250/1349], Loss: 0.3181\n",
            "Epoch [1/3], Step [251/1349], Loss: 0.2588\n",
            "Epoch [1/3], Step [252/1349], Loss: 0.3318\n",
            "Epoch [1/3], Step [253/1349], Loss: 0.2826\n",
            "Epoch [1/3], Step [254/1349], Loss: 0.2087\n",
            "Epoch [1/3], Step [255/1349], Loss: 0.1753\n",
            "Epoch [1/3], Step [256/1349], Loss: 0.3458\n",
            "Epoch [1/3], Step [257/1349], Loss: 0.2641\n",
            "Epoch [1/3], Step [258/1349], Loss: 0.2185\n",
            "Epoch [1/3], Step [259/1349], Loss: 0.2574\n",
            "Epoch [1/3], Step [260/1349], Loss: 0.2566\n",
            "Epoch [1/3], Step [261/1349], Loss: 0.1390\n",
            "Epoch [1/3], Step [262/1349], Loss: 0.4210\n",
            "Epoch [1/3], Step [263/1349], Loss: 0.0964\n",
            "Epoch [1/3], Step [264/1349], Loss: 0.3668\n",
            "Epoch [1/3], Step [265/1349], Loss: 0.2850\n",
            "Epoch [1/3], Step [266/1349], Loss: 0.4826\n",
            "Epoch [1/3], Step [267/1349], Loss: 0.4851\n",
            "Epoch [1/3], Step [268/1349], Loss: 0.6022\n",
            "Epoch [1/3], Step [269/1349], Loss: 0.1422\n",
            "Epoch [1/3], Step [270/1349], Loss: 0.1920\n",
            "Epoch [1/3], Step [271/1349], Loss: 0.3537\n",
            "Epoch [1/3], Step [272/1349], Loss: 0.0891\n",
            "Epoch [1/3], Step [273/1349], Loss: 0.2195\n",
            "Epoch [1/3], Step [274/1349], Loss: 0.1327\n",
            "Epoch [1/3], Step [275/1349], Loss: 0.1921\n",
            "Epoch [1/3], Step [276/1349], Loss: 0.2765\n",
            "Epoch [1/3], Step [277/1349], Loss: 0.2257\n",
            "Epoch [1/3], Step [278/1349], Loss: 0.2515\n",
            "Epoch [1/3], Step [279/1349], Loss: 0.1574\n",
            "Epoch [1/3], Step [280/1349], Loss: 0.0974\n",
            "Epoch [1/3], Step [281/1349], Loss: 0.3735\n",
            "Epoch [1/3], Step [282/1349], Loss: 0.3089\n",
            "Epoch [1/3], Step [283/1349], Loss: 0.2370\n",
            "Epoch [1/3], Step [284/1349], Loss: 0.4610\n",
            "Epoch [1/3], Step [285/1349], Loss: 0.2407\n",
            "Epoch [1/3], Step [286/1349], Loss: 0.2805\n",
            "Epoch [1/3], Step [287/1349], Loss: 0.3269\n",
            "Epoch [1/3], Step [288/1349], Loss: 0.3488\n",
            "Epoch [1/3], Step [289/1349], Loss: 0.2948\n",
            "Epoch [1/3], Step [290/1349], Loss: 0.1641\n",
            "Epoch [1/3], Step [291/1349], Loss: 0.2552\n",
            "Epoch [1/3], Step [292/1349], Loss: 0.3108\n",
            "Epoch [1/3], Step [293/1349], Loss: 0.3116\n",
            "Epoch [1/3], Step [294/1349], Loss: 0.1882\n",
            "Epoch [1/3], Step [295/1349], Loss: 0.1653\n",
            "Epoch [1/3], Step [296/1349], Loss: 0.3449\n",
            "Epoch [1/3], Step [297/1349], Loss: 0.3021\n",
            "Epoch [1/3], Step [298/1349], Loss: 0.2911\n",
            "Epoch [1/3], Step [299/1349], Loss: 0.2948\n",
            "Epoch [1/3], Step [300/1349], Loss: 0.1561\n",
            "Epoch [1/3], Step [301/1349], Loss: 0.0690\n",
            "Epoch [1/3], Step [302/1349], Loss: 0.1643\n",
            "Epoch [1/3], Step [303/1349], Loss: 0.0937\n",
            "Epoch [1/3], Step [304/1349], Loss: 0.2665\n",
            "Epoch [1/3], Step [305/1349], Loss: 0.3959\n",
            "Epoch [1/3], Step [306/1349], Loss: 0.1523\n",
            "Epoch [1/3], Step [307/1349], Loss: 0.3242\n",
            "Epoch [1/3], Step [308/1349], Loss: 0.1696\n",
            "Epoch [1/3], Step [309/1349], Loss: 0.2251\n",
            "Epoch [1/3], Step [310/1349], Loss: 0.1423\n",
            "Epoch [1/3], Step [311/1349], Loss: 0.1294\n",
            "Epoch [1/3], Step [312/1349], Loss: 0.4725\n",
            "Epoch [1/3], Step [313/1349], Loss: 0.1635\n",
            "Epoch [1/3], Step [314/1349], Loss: 0.1306\n",
            "Epoch [1/3], Step [315/1349], Loss: 0.2588\n",
            "Epoch [1/3], Step [316/1349], Loss: 0.1944\n",
            "Epoch [1/3], Step [317/1349], Loss: 0.3003\n",
            "Epoch [1/3], Step [318/1349], Loss: 0.1567\n",
            "Epoch [1/3], Step [319/1349], Loss: 0.1209\n",
            "Epoch [1/3], Step [320/1349], Loss: 0.2814\n",
            "Epoch [1/3], Step [321/1349], Loss: 0.2837\n",
            "Epoch [1/3], Step [322/1349], Loss: 0.2447\n",
            "Epoch [1/3], Step [323/1349], Loss: 0.2426\n",
            "Epoch [1/3], Step [324/1349], Loss: 0.3212\n",
            "Epoch [1/3], Step [325/1349], Loss: 0.2354\n",
            "Epoch [1/3], Step [326/1349], Loss: 0.1585\n",
            "Epoch [1/3], Step [327/1349], Loss: 0.0763\n",
            "Epoch [1/3], Step [328/1349], Loss: 0.1413\n",
            "Epoch [1/3], Step [329/1349], Loss: 0.2791\n",
            "Epoch [1/3], Step [330/1349], Loss: 0.3793\n",
            "Epoch [1/3], Step [331/1349], Loss: 0.1746\n",
            "Epoch [1/3], Step [332/1349], Loss: 0.1878\n",
            "Epoch [1/3], Step [333/1349], Loss: 0.3913\n",
            "Epoch [1/3], Step [334/1349], Loss: 0.1904\n",
            "Epoch [1/3], Step [335/1349], Loss: 0.1705\n",
            "Epoch [1/3], Step [336/1349], Loss: 0.2413\n",
            "Epoch [1/3], Step [337/1349], Loss: 0.2317\n",
            "Epoch [1/3], Step [338/1349], Loss: 0.1649\n",
            "Epoch [1/3], Step [339/1349], Loss: 0.0577\n",
            "Epoch [1/3], Step [340/1349], Loss: 0.2548\n",
            "Epoch [1/3], Step [341/1349], Loss: 0.2829\n",
            "Epoch [1/3], Step [342/1349], Loss: 0.2757\n",
            "Epoch [1/3], Step [343/1349], Loss: 0.2322\n",
            "Epoch [1/3], Step [344/1349], Loss: 0.3524\n",
            "Epoch [1/3], Step [345/1349], Loss: 0.3430\n",
            "Epoch [1/3], Step [346/1349], Loss: 0.2518\n",
            "Epoch [1/3], Step [347/1349], Loss: 0.1827\n",
            "Epoch [1/3], Step [348/1349], Loss: 0.2873\n",
            "Epoch [1/3], Step [349/1349], Loss: 0.1280\n",
            "Epoch [1/3], Step [350/1349], Loss: 0.2928\n",
            "Epoch [1/3], Step [351/1349], Loss: 0.1560\n",
            "Epoch [1/3], Step [352/1349], Loss: 0.1337\n",
            "Epoch [1/3], Step [353/1349], Loss: 0.2245\n",
            "Epoch [1/3], Step [354/1349], Loss: 0.2812\n",
            "Epoch [1/3], Step [355/1349], Loss: 0.1572\n",
            "Epoch [1/3], Step [356/1349], Loss: 0.2041\n",
            "Epoch [1/3], Step [357/1349], Loss: 0.1428\n",
            "Epoch [1/3], Step [358/1349], Loss: 0.1225\n",
            "Epoch [1/3], Step [359/1349], Loss: 0.1329\n",
            "Epoch [1/3], Step [360/1349], Loss: 0.1753\n",
            "Epoch [1/3], Step [361/1349], Loss: 0.1242\n",
            "Epoch [1/3], Step [362/1349], Loss: 0.4129\n",
            "Epoch [1/3], Step [363/1349], Loss: 0.0793\n",
            "Epoch [1/3], Step [364/1349], Loss: 0.1743\n",
            "Epoch [1/3], Step [365/1349], Loss: 0.1156\n",
            "Epoch [1/3], Step [366/1349], Loss: 0.1772\n",
            "Epoch [1/3], Step [367/1349], Loss: 0.1855\n",
            "Epoch [1/3], Step [368/1349], Loss: 0.2061\n",
            "Epoch [1/3], Step [369/1349], Loss: 0.2539\n",
            "Epoch [1/3], Step [370/1349], Loss: 0.1743\n",
            "Epoch [1/3], Step [371/1349], Loss: 0.1287\n",
            "Epoch [1/3], Step [372/1349], Loss: 0.2805\n",
            "Epoch [1/3], Step [373/1349], Loss: 0.0996\n",
            "Epoch [1/3], Step [374/1349], Loss: 0.0698\n",
            "Epoch [1/3], Step [375/1349], Loss: 0.1582\n",
            "Epoch [1/3], Step [376/1349], Loss: 0.2774\n",
            "Epoch [1/3], Step [377/1349], Loss: 0.1442\n",
            "Epoch [1/3], Step [378/1349], Loss: 0.1103\n",
            "Epoch [1/3], Step [379/1349], Loss: 0.1912\n",
            "Epoch [1/3], Step [380/1349], Loss: 0.1681\n",
            "Epoch [1/3], Step [381/1349], Loss: 0.0581\n",
            "Epoch [1/3], Step [382/1349], Loss: 0.0888\n",
            "Epoch [1/3], Step [383/1349], Loss: 0.0699\n",
            "Epoch [1/3], Step [384/1349], Loss: 0.1265\n",
            "Epoch [1/3], Step [385/1349], Loss: 0.1349\n",
            "Epoch [1/3], Step [386/1349], Loss: 0.1436\n",
            "Epoch [1/3], Step [387/1349], Loss: 0.1237\n",
            "Epoch [1/3], Step [388/1349], Loss: 0.2014\n",
            "Epoch [1/3], Step [389/1349], Loss: 0.2073\n",
            "Epoch [1/3], Step [390/1349], Loss: 0.2631\n",
            "Epoch [1/3], Step [391/1349], Loss: 0.1338\n",
            "Epoch [1/3], Step [392/1349], Loss: 0.2051\n",
            "Epoch [1/3], Step [393/1349], Loss: 0.1481\n",
            "Epoch [1/3], Step [394/1349], Loss: 0.1011\n",
            "Epoch [1/3], Step [395/1349], Loss: 0.2096\n",
            "Epoch [1/3], Step [396/1349], Loss: 0.1883\n",
            "Epoch [1/3], Step [397/1349], Loss: 0.4648\n",
            "Epoch [1/3], Step [398/1349], Loss: 0.1072\n",
            "Epoch [1/3], Step [399/1349], Loss: 0.1958\n",
            "Epoch [1/3], Step [400/1349], Loss: 0.3668\n",
            "Epoch [1/3], Step [401/1349], Loss: 0.1800\n",
            "Epoch [1/3], Step [402/1349], Loss: 0.1749\n",
            "Epoch [1/3], Step [403/1349], Loss: 0.2963\n",
            "Epoch [1/3], Step [404/1349], Loss: 0.1747\n",
            "Epoch [1/3], Step [405/1349], Loss: 0.3506\n",
            "Epoch [1/3], Step [406/1349], Loss: 0.1650\n",
            "Epoch [1/3], Step [407/1349], Loss: 0.2314\n",
            "Epoch [1/3], Step [408/1349], Loss: 0.3049\n",
            "Epoch [1/3], Step [409/1349], Loss: 0.1199\n",
            "Epoch [1/3], Step [410/1349], Loss: 0.2292\n",
            "Epoch [1/3], Step [411/1349], Loss: 0.1242\n",
            "Epoch [1/3], Step [412/1349], Loss: 0.3922\n",
            "Epoch [1/3], Step [413/1349], Loss: 0.2045\n",
            "Epoch [1/3], Step [414/1349], Loss: 0.3920\n",
            "Epoch [1/3], Step [415/1349], Loss: 0.1678\n",
            "Epoch [1/3], Step [416/1349], Loss: 0.1431\n",
            "Epoch [1/3], Step [417/1349], Loss: 0.2944\n",
            "Epoch [1/3], Step [418/1349], Loss: 0.0852\n",
            "Epoch [1/3], Step [419/1349], Loss: 0.1465\n",
            "Epoch [1/3], Step [420/1349], Loss: 0.3074\n",
            "Epoch [1/3], Step [421/1349], Loss: 0.2619\n",
            "Epoch [1/3], Step [422/1349], Loss: 0.0816\n",
            "Epoch [1/3], Step [423/1349], Loss: 0.1233\n",
            "Epoch [1/3], Step [424/1349], Loss: 0.1567\n",
            "Epoch [1/3], Step [425/1349], Loss: 0.1480\n",
            "Epoch [1/3], Step [426/1349], Loss: 0.2253\n",
            "Epoch [1/3], Step [427/1349], Loss: 0.4430\n",
            "Epoch [1/3], Step [428/1349], Loss: 0.1759\n",
            "Epoch [1/3], Step [429/1349], Loss: 0.2112\n",
            "Epoch [1/3], Step [430/1349], Loss: 0.1197\n",
            "Epoch [1/3], Step [431/1349], Loss: 0.2888\n",
            "Epoch [1/3], Step [432/1349], Loss: 0.1167\n",
            "Epoch [1/3], Step [433/1349], Loss: 0.1903\n",
            "Epoch [1/3], Step [434/1349], Loss: 0.1688\n",
            "Epoch [1/3], Step [435/1349], Loss: 0.1316\n",
            "Epoch [1/3], Step [436/1349], Loss: 0.2349\n",
            "Epoch [1/3], Step [437/1349], Loss: 0.2003\n",
            "Epoch [1/3], Step [438/1349], Loss: 0.2930\n",
            "Epoch [1/3], Step [439/1349], Loss: 0.1972\n",
            "Epoch [1/3], Step [440/1349], Loss: 0.1148\n",
            "Epoch [1/3], Step [441/1349], Loss: 0.2238\n",
            "Epoch [1/3], Step [442/1349], Loss: 0.1886\n",
            "Epoch [1/3], Step [443/1349], Loss: 0.2901\n",
            "Epoch [1/3], Step [444/1349], Loss: 0.1102\n",
            "Epoch [1/3], Step [445/1349], Loss: 0.1415\n",
            "Epoch [1/3], Step [446/1349], Loss: 0.3545\n",
            "Epoch [1/3], Step [447/1349], Loss: 0.1911\n",
            "Epoch [1/3], Step [448/1349], Loss: 0.1538\n",
            "Epoch [1/3], Step [449/1349], Loss: 0.1712\n",
            "Epoch [1/3], Step [450/1349], Loss: 0.2035\n",
            "Epoch [1/3], Step [451/1349], Loss: 0.2550\n",
            "Epoch [1/3], Step [452/1349], Loss: 0.0493\n",
            "Epoch [1/3], Step [453/1349], Loss: 0.2676\n",
            "Epoch [1/3], Step [454/1349], Loss: 0.0959\n",
            "Epoch [1/3], Step [455/1349], Loss: 0.3538\n",
            "Epoch [1/3], Step [456/1349], Loss: 0.1048\n",
            "Epoch [1/3], Step [457/1349], Loss: 0.1690\n",
            "Epoch [1/3], Step [458/1349], Loss: 0.1949\n",
            "Epoch [1/3], Step [459/1349], Loss: 0.2584\n",
            "Epoch [1/3], Step [460/1349], Loss: 0.1263\n",
            "Epoch [1/3], Step [461/1349], Loss: 0.2079\n",
            "Epoch [1/3], Step [462/1349], Loss: 0.1181\n",
            "Epoch [1/3], Step [463/1349], Loss: 0.1015\n",
            "Epoch [1/3], Step [464/1349], Loss: 0.1682\n",
            "Epoch [1/3], Step [465/1349], Loss: 0.1436\n",
            "Epoch [1/3], Step [466/1349], Loss: 0.3604\n",
            "Epoch [1/3], Step [467/1349], Loss: 0.1367\n",
            "Epoch [1/3], Step [468/1349], Loss: 0.3040\n",
            "Epoch [1/3], Step [469/1349], Loss: 0.0881\n",
            "Epoch [1/3], Step [470/1349], Loss: 0.1985\n",
            "Epoch [1/3], Step [471/1349], Loss: 0.3008\n",
            "Epoch [1/3], Step [472/1349], Loss: 0.1721\n",
            "Epoch [1/3], Step [473/1349], Loss: 0.4668\n",
            "Epoch [1/3], Step [474/1349], Loss: 0.2082\n",
            "Epoch [1/3], Step [475/1349], Loss: 0.0951\n",
            "Epoch [1/3], Step [476/1349], Loss: 0.1923\n",
            "Epoch [1/3], Step [477/1349], Loss: 0.0582\n",
            "Epoch [1/3], Step [478/1349], Loss: 0.1408\n",
            "Epoch [1/3], Step [479/1349], Loss: 0.2209\n",
            "Epoch [1/3], Step [480/1349], Loss: 0.1919\n",
            "Epoch [1/3], Step [481/1349], Loss: 0.1774\n",
            "Epoch [1/3], Step [482/1349], Loss: 0.3476\n",
            "Epoch [1/3], Step [483/1349], Loss: 0.1907\n",
            "Epoch [1/3], Step [484/1349], Loss: 0.3536\n",
            "Epoch [1/3], Step [485/1349], Loss: 0.1549\n",
            "Epoch [1/3], Step [486/1349], Loss: 0.2890\n",
            "Epoch [1/3], Step [487/1349], Loss: 0.2357\n",
            "Epoch [1/3], Step [488/1349], Loss: 0.0960\n",
            "Epoch [1/3], Step [489/1349], Loss: 0.2863\n",
            "Epoch [1/3], Step [490/1349], Loss: 0.2561\n",
            "Epoch [1/3], Step [491/1349], Loss: 0.1073\n",
            "Epoch [1/3], Step [492/1349], Loss: 0.1766\n",
            "Epoch [1/3], Step [493/1349], Loss: 0.0819\n",
            "Epoch [1/3], Step [494/1349], Loss: 0.1566\n",
            "Epoch [1/3], Step [495/1349], Loss: 0.1821\n",
            "Epoch [1/3], Step [496/1349], Loss: 0.3204\n",
            "Epoch [1/3], Step [497/1349], Loss: 0.0470\n",
            "Epoch [1/3], Step [498/1349], Loss: 0.2433\n",
            "Epoch [1/3], Step [499/1349], Loss: 0.1140\n",
            "Epoch [1/3], Step [500/1349], Loss: 0.1400\n",
            "Epoch [1/3], Step [501/1349], Loss: 0.1103\n",
            "Epoch [1/3], Step [502/1349], Loss: 0.2834\n",
            "Epoch [1/3], Step [503/1349], Loss: 0.2263\n",
            "Epoch [1/3], Step [504/1349], Loss: 0.0621\n",
            "Epoch [1/3], Step [505/1349], Loss: 0.2399\n",
            "Epoch [1/3], Step [506/1349], Loss: 0.1948\n",
            "Epoch [1/3], Step [507/1349], Loss: 0.2081\n",
            "Epoch [1/3], Step [508/1349], Loss: 0.1868\n",
            "Epoch [1/3], Step [509/1349], Loss: 0.2117\n",
            "Epoch [1/3], Step [510/1349], Loss: 0.1303\n",
            "Epoch [1/3], Step [511/1349], Loss: 0.0805\n",
            "Epoch [1/3], Step [512/1349], Loss: 0.1701\n",
            "Epoch [1/3], Step [513/1349], Loss: 0.1510\n",
            "Epoch [1/3], Step [514/1349], Loss: 0.1572\n",
            "Epoch [1/3], Step [515/1349], Loss: 0.1178\n",
            "Epoch [1/3], Step [516/1349], Loss: 0.1834\n",
            "Epoch [1/3], Step [517/1349], Loss: 0.0633\n",
            "Epoch [1/3], Step [518/1349], Loss: 0.2177\n",
            "Epoch [1/3], Step [519/1349], Loss: 0.1563\n",
            "Epoch [1/3], Step [520/1349], Loss: 0.1919\n",
            "Epoch [1/3], Step [521/1349], Loss: 0.5502\n",
            "Epoch [1/3], Step [522/1349], Loss: 0.2121\n",
            "Epoch [1/3], Step [523/1349], Loss: 0.1787\n",
            "Epoch [1/3], Step [524/1349], Loss: 0.0986\n",
            "Epoch [1/3], Step [525/1349], Loss: 0.1589\n",
            "Epoch [1/3], Step [526/1349], Loss: 0.1488\n",
            "Epoch [1/3], Step [527/1349], Loss: 0.1067\n",
            "Epoch [1/3], Step [528/1349], Loss: 0.0622\n",
            "Epoch [1/3], Step [529/1349], Loss: 0.0820\n",
            "Epoch [1/3], Step [530/1349], Loss: 0.3088\n",
            "Epoch [1/3], Step [531/1349], Loss: 0.1497\n",
            "Epoch [1/3], Step [532/1349], Loss: 0.1955\n",
            "Epoch [1/3], Step [533/1349], Loss: 0.1379\n",
            "Epoch [1/3], Step [534/1349], Loss: 0.2044\n",
            "Epoch [1/3], Step [535/1349], Loss: 0.1400\n",
            "Epoch [1/3], Step [536/1349], Loss: 0.0498\n",
            "Epoch [1/3], Step [537/1349], Loss: 0.2840\n",
            "Epoch [1/3], Step [538/1349], Loss: 0.2324\n",
            "Epoch [1/3], Step [539/1349], Loss: 0.1289\n",
            "Epoch [1/3], Step [540/1349], Loss: 0.1831\n",
            "Epoch [1/3], Step [541/1349], Loss: 0.4153\n",
            "Epoch [1/3], Step [542/1349], Loss: 0.3109\n",
            "Epoch [1/3], Step [543/1349], Loss: 0.2482\n",
            "Epoch [1/3], Step [544/1349], Loss: 0.0417\n",
            "Epoch [1/3], Step [545/1349], Loss: 0.1545\n",
            "Epoch [1/3], Step [546/1349], Loss: 0.0391\n",
            "Epoch [1/3], Step [547/1349], Loss: 0.0939\n",
            "Epoch [1/3], Step [548/1349], Loss: 0.2221\n",
            "Epoch [1/3], Step [549/1349], Loss: 0.3712\n",
            "Epoch [1/3], Step [550/1349], Loss: 0.2267\n",
            "Epoch [1/3], Step [551/1349], Loss: 0.0880\n",
            "Epoch [1/3], Step [552/1349], Loss: 0.1805\n",
            "Epoch [1/3], Step [553/1349], Loss: 0.0974\n",
            "Epoch [1/3], Step [554/1349], Loss: 0.0828\n",
            "Epoch [1/3], Step [555/1349], Loss: 0.2280\n",
            "Epoch [1/3], Step [556/1349], Loss: 0.1397\n",
            "Epoch [1/3], Step [557/1349], Loss: 0.0403\n",
            "Epoch [1/3], Step [558/1349], Loss: 0.1268\n",
            "Epoch [1/3], Step [559/1349], Loss: 0.2296\n",
            "Epoch [1/3], Step [560/1349], Loss: 0.1760\n",
            "Epoch [1/3], Step [561/1349], Loss: 0.1485\n",
            "Epoch [1/3], Step [562/1349], Loss: 0.0789\n",
            "Epoch [1/3], Step [563/1349], Loss: 0.1488\n",
            "Epoch [1/3], Step [564/1349], Loss: 0.2176\n",
            "Epoch [1/3], Step [565/1349], Loss: 0.3467\n",
            "Epoch [1/3], Step [566/1349], Loss: 0.2740\n",
            "Epoch [1/3], Step [567/1349], Loss: 0.0762\n",
            "Epoch [1/3], Step [568/1349], Loss: 0.2460\n",
            "Epoch [1/3], Step [569/1349], Loss: 0.2057\n",
            "Epoch [1/3], Step [570/1349], Loss: 0.0854\n",
            "Epoch [1/3], Step [571/1349], Loss: 0.1549\n",
            "Epoch [1/3], Step [572/1349], Loss: 0.2408\n",
            "Epoch [1/3], Step [573/1349], Loss: 0.0999\n",
            "Epoch [1/3], Step [574/1349], Loss: 0.2251\n",
            "Epoch [1/3], Step [575/1349], Loss: 0.0642\n",
            "Epoch [1/3], Step [576/1349], Loss: 0.1356\n",
            "Epoch [1/3], Step [577/1349], Loss: 0.2348\n",
            "Epoch [1/3], Step [578/1349], Loss: 0.1840\n",
            "Epoch [1/3], Step [579/1349], Loss: 0.3150\n",
            "Epoch [1/3], Step [580/1349], Loss: 0.1303\n",
            "Epoch [1/3], Step [581/1349], Loss: 0.1449\n",
            "Epoch [1/3], Step [582/1349], Loss: 0.1952\n",
            "Epoch [1/3], Step [583/1349], Loss: 0.0850\n",
            "Epoch [1/3], Step [584/1349], Loss: 0.1315\n",
            "Epoch [1/3], Step [585/1349], Loss: 0.2153\n",
            "Epoch [1/3], Step [586/1349], Loss: 0.1021\n",
            "Epoch [1/3], Step [587/1349], Loss: 0.2486\n",
            "Epoch [1/3], Step [588/1349], Loss: 0.1749\n",
            "Epoch [1/3], Step [589/1349], Loss: 0.2887\n",
            "Epoch [1/3], Step [590/1349], Loss: 0.1217\n",
            "Epoch [1/3], Step [591/1349], Loss: 0.1277\n",
            "Epoch [1/3], Step [592/1349], Loss: 0.1266\n",
            "Epoch [1/3], Step [593/1349], Loss: 0.3923\n",
            "Epoch [1/3], Step [594/1349], Loss: 0.3773\n",
            "Epoch [1/3], Step [595/1349], Loss: 0.1585\n",
            "Epoch [1/3], Step [596/1349], Loss: 0.1065\n",
            "Epoch [1/3], Step [597/1349], Loss: 0.2688\n",
            "Epoch [1/3], Step [598/1349], Loss: 0.1817\n",
            "Epoch [1/3], Step [599/1349], Loss: 0.2031\n",
            "Epoch [1/3], Step [600/1349], Loss: 0.1239\n",
            "Epoch [1/3], Step [601/1349], Loss: 0.1544\n",
            "Epoch [1/3], Step [602/1349], Loss: 0.1444\n",
            "Epoch [1/3], Step [603/1349], Loss: 0.1323\n",
            "Epoch [1/3], Step [604/1349], Loss: 0.3282\n",
            "Epoch [1/3], Step [605/1349], Loss: 0.1097\n",
            "Epoch [1/3], Step [606/1349], Loss: 0.1735\n",
            "Epoch [1/3], Step [607/1349], Loss: 0.1119\n",
            "Epoch [1/3], Step [608/1349], Loss: 0.0682\n",
            "Epoch [1/3], Step [609/1349], Loss: 0.1937\n",
            "Epoch [1/3], Step [610/1349], Loss: 0.0656\n",
            "Epoch [1/3], Step [611/1349], Loss: 0.0594\n",
            "Epoch [1/3], Step [612/1349], Loss: 0.3303\n",
            "Epoch [1/3], Step [613/1349], Loss: 0.1042\n",
            "Epoch [1/3], Step [614/1349], Loss: 0.2231\n",
            "Epoch [1/3], Step [615/1349], Loss: 0.1357\n",
            "Epoch [1/3], Step [616/1349], Loss: 0.2094\n",
            "Epoch [1/3], Step [617/1349], Loss: 0.1005\n",
            "Epoch [1/3], Step [618/1349], Loss: 0.1112\n",
            "Epoch [1/3], Step [619/1349], Loss: 0.2289\n",
            "Epoch [1/3], Step [620/1349], Loss: 0.0981\n",
            "Epoch [1/3], Step [621/1349], Loss: 0.2777\n",
            "Epoch [1/3], Step [622/1349], Loss: 0.0857\n",
            "Epoch [1/3], Step [623/1349], Loss: 0.0837\n",
            "Epoch [1/3], Step [624/1349], Loss: 0.3393\n",
            "Epoch [1/3], Step [625/1349], Loss: 0.1468\n",
            "Epoch [1/3], Step [626/1349], Loss: 0.1478\n",
            "Epoch [1/3], Step [627/1349], Loss: 0.2367\n",
            "Epoch [1/3], Step [628/1349], Loss: 0.2640\n",
            "Epoch [1/3], Step [629/1349], Loss: 0.1741\n",
            "Epoch [1/3], Step [630/1349], Loss: 0.0984\n",
            "Epoch [1/3], Step [631/1349], Loss: 0.2580\n",
            "Epoch [1/3], Step [632/1349], Loss: 0.0988\n",
            "Epoch [1/3], Step [633/1349], Loss: 0.2125\n",
            "Epoch [1/3], Step [634/1349], Loss: 0.2374\n",
            "Epoch [1/3], Step [635/1349], Loss: 0.1143\n",
            "Epoch [1/3], Step [636/1349], Loss: 0.1440\n",
            "Epoch [1/3], Step [637/1349], Loss: 0.3941\n",
            "Epoch [1/3], Step [638/1349], Loss: 0.2818\n",
            "Epoch [1/3], Step [639/1349], Loss: 0.1740\n",
            "Epoch [1/3], Step [640/1349], Loss: 0.0972\n",
            "Epoch [1/3], Step [641/1349], Loss: 0.2439\n",
            "Epoch [1/3], Step [642/1349], Loss: 0.1503\n",
            "Epoch [1/3], Step [643/1349], Loss: 0.2030\n",
            "Epoch [1/3], Step [644/1349], Loss: 0.3599\n",
            "Epoch [1/3], Step [645/1349], Loss: 0.1214\n",
            "Epoch [1/3], Step [646/1349], Loss: 0.1925\n",
            "Epoch [1/3], Step [647/1349], Loss: 0.1051\n",
            "Epoch [1/3], Step [648/1349], Loss: 0.1491\n",
            "Epoch [1/3], Step [649/1349], Loss: 0.1268\n",
            "Epoch [1/3], Step [650/1349], Loss: 0.1607\n",
            "Epoch [1/3], Step [651/1349], Loss: 0.2230\n",
            "Epoch [1/3], Step [652/1349], Loss: 0.2217\n",
            "Epoch [1/3], Step [653/1349], Loss: 0.2719\n",
            "Epoch [1/3], Step [654/1349], Loss: 0.3233\n",
            "Epoch [1/3], Step [655/1349], Loss: 0.5065\n",
            "Epoch [1/3], Step [656/1349], Loss: 0.0856\n",
            "Epoch [1/3], Step [657/1349], Loss: 0.2260\n",
            "Epoch [1/3], Step [658/1349], Loss: 0.2254\n",
            "Epoch [1/3], Step [659/1349], Loss: 0.2298\n",
            "Epoch [1/3], Step [660/1349], Loss: 0.0741\n",
            "Epoch [1/3], Step [661/1349], Loss: 0.2396\n",
            "Epoch [1/3], Step [662/1349], Loss: 0.1572\n",
            "Epoch [1/3], Step [663/1349], Loss: 0.1794\n",
            "Epoch [1/3], Step [664/1349], Loss: 0.1924\n",
            "Epoch [1/3], Step [665/1349], Loss: 0.2208\n",
            "Epoch [1/3], Step [666/1349], Loss: 0.1538\n",
            "Epoch [1/3], Step [667/1349], Loss: 0.1106\n",
            "Epoch [1/3], Step [668/1349], Loss: 0.2284\n",
            "Epoch [1/3], Step [669/1349], Loss: 0.1068\n",
            "Epoch [1/3], Step [670/1349], Loss: 0.1040\n",
            "Epoch [1/3], Step [671/1349], Loss: 0.0531\n",
            "Epoch [1/3], Step [672/1349], Loss: 0.2665\n",
            "Epoch [1/3], Step [673/1349], Loss: 0.1535\n",
            "Epoch [1/3], Step [674/1349], Loss: 0.1485\n",
            "Epoch [1/3], Step [675/1349], Loss: 0.1823\n",
            "Epoch [1/3], Step [676/1349], Loss: 0.0660\n",
            "Epoch [1/3], Step [677/1349], Loss: 0.1358\n",
            "Epoch [1/3], Step [678/1349], Loss: 0.1389\n",
            "Epoch [1/3], Step [679/1349], Loss: 0.1514\n",
            "Epoch [1/3], Step [680/1349], Loss: 0.2233\n",
            "Epoch [1/3], Step [681/1349], Loss: 0.0534\n",
            "Epoch [1/3], Step [682/1349], Loss: 0.1608\n",
            "Epoch [1/3], Step [683/1349], Loss: 0.2258\n",
            "Epoch [1/3], Step [684/1349], Loss: 0.0794\n",
            "Epoch [1/3], Step [685/1349], Loss: 0.2016\n",
            "Epoch [1/3], Step [686/1349], Loss: 0.0550\n",
            "Epoch [1/3], Step [687/1349], Loss: 0.1329\n",
            "Epoch [1/3], Step [688/1349], Loss: 0.2359\n",
            "Epoch [1/3], Step [689/1349], Loss: 0.0660\n",
            "Epoch [1/3], Step [690/1349], Loss: 0.3265\n",
            "Epoch [1/3], Step [691/1349], Loss: 0.2083\n",
            "Epoch [1/3], Step [692/1349], Loss: 0.1679\n",
            "Epoch [1/3], Step [693/1349], Loss: 0.3252\n",
            "Epoch [1/3], Step [694/1349], Loss: 0.2177\n",
            "Epoch [1/3], Step [695/1349], Loss: 0.1576\n",
            "Epoch [1/3], Step [696/1349], Loss: 0.0793\n",
            "Epoch [1/3], Step [697/1349], Loss: 0.0967\n",
            "Epoch [1/3], Step [698/1349], Loss: 0.1205\n",
            "Epoch [1/3], Step [699/1349], Loss: 0.3655\n",
            "Epoch [1/3], Step [700/1349], Loss: 0.1872\n",
            "Epoch [1/3], Step [701/1349], Loss: 0.1261\n",
            "Epoch [1/3], Step [702/1349], Loss: 0.1638\n",
            "Epoch [1/3], Step [703/1349], Loss: 0.2323\n",
            "Epoch [1/3], Step [704/1349], Loss: 0.2933\n",
            "Epoch [1/3], Step [705/1349], Loss: 0.1770\n",
            "Epoch [1/3], Step [706/1349], Loss: 0.0667\n",
            "Epoch [1/3], Step [707/1349], Loss: 0.1129\n",
            "Epoch [1/3], Step [708/1349], Loss: 0.1448\n",
            "Epoch [1/3], Step [709/1349], Loss: 0.1614\n",
            "Epoch [1/3], Step [710/1349], Loss: 0.0906\n",
            "Epoch [1/3], Step [711/1349], Loss: 0.2338\n",
            "Epoch [1/3], Step [712/1349], Loss: 0.3476\n",
            "Epoch [1/3], Step [713/1349], Loss: 0.1424\n",
            "Epoch [1/3], Step [714/1349], Loss: 0.2027\n",
            "Epoch [1/3], Step [715/1349], Loss: 0.1408\n",
            "Epoch [1/3], Step [716/1349], Loss: 0.2014\n",
            "Epoch [1/3], Step [717/1349], Loss: 0.1611\n",
            "Epoch [1/3], Step [718/1349], Loss: 0.0828\n",
            "Epoch [1/3], Step [719/1349], Loss: 0.1773\n",
            "Epoch [1/3], Step [720/1349], Loss: 0.1752\n",
            "Epoch [1/3], Step [721/1349], Loss: 0.1212\n",
            "Epoch [1/3], Step [722/1349], Loss: 0.2285\n",
            "Epoch [1/3], Step [723/1349], Loss: 0.1771\n",
            "Epoch [1/3], Step [724/1349], Loss: 0.0766\n",
            "Epoch [1/3], Step [725/1349], Loss: 0.2567\n",
            "Epoch [1/3], Step [726/1349], Loss: 0.2395\n",
            "Epoch [1/3], Step [727/1349], Loss: 0.0349\n",
            "Epoch [1/3], Step [728/1349], Loss: 0.0433\n",
            "Epoch [1/3], Step [729/1349], Loss: 0.2587\n",
            "Epoch [1/3], Step [730/1349], Loss: 0.2101\n",
            "Epoch [1/3], Step [731/1349], Loss: 0.1491\n",
            "Epoch [1/3], Step [732/1349], Loss: 0.1490\n",
            "Epoch [1/3], Step [733/1349], Loss: 0.1811\n",
            "Epoch [1/3], Step [734/1349], Loss: 0.1004\n",
            "Epoch [1/3], Step [735/1349], Loss: 0.1441\n",
            "Epoch [1/3], Step [736/1349], Loss: 0.1751\n",
            "Epoch [1/3], Step [737/1349], Loss: 0.1107\n",
            "Epoch [1/3], Step [738/1349], Loss: 0.0937\n",
            "Epoch [1/3], Step [739/1349], Loss: 0.0645\n",
            "Epoch [1/3], Step [740/1349], Loss: 0.1816\n",
            "Epoch [1/3], Step [741/1349], Loss: 0.0817\n",
            "Epoch [1/3], Step [742/1349], Loss: 0.1080\n",
            "Epoch [1/3], Step [743/1349], Loss: 0.1092\n",
            "Epoch [1/3], Step [744/1349], Loss: 0.1033\n",
            "Epoch [1/3], Step [745/1349], Loss: 0.1238\n",
            "Epoch [1/3], Step [746/1349], Loss: 0.1398\n",
            "Epoch [1/3], Step [747/1349], Loss: 0.2100\n",
            "Epoch [1/3], Step [748/1349], Loss: 0.1873\n",
            "Epoch [1/3], Step [749/1349], Loss: 0.1784\n",
            "Epoch [1/3], Step [750/1349], Loss: 0.1765\n",
            "Epoch [1/3], Step [751/1349], Loss: 0.2992\n",
            "Epoch [1/3], Step [752/1349], Loss: 0.0731\n",
            "Epoch [1/3], Step [753/1349], Loss: 0.0949\n",
            "Epoch [1/3], Step [754/1349], Loss: 0.1585\n",
            "Epoch [1/3], Step [755/1349], Loss: 0.1200\n",
            "Epoch [1/3], Step [756/1349], Loss: 0.0942\n",
            "Epoch [1/3], Step [757/1349], Loss: 0.1227\n",
            "Epoch [1/3], Step [758/1349], Loss: 0.0959\n",
            "Epoch [1/3], Step [759/1349], Loss: 0.1303\n",
            "Epoch [1/3], Step [760/1349], Loss: 0.1883\n",
            "Epoch [1/3], Step [761/1349], Loss: 0.0143\n",
            "Epoch [1/3], Step [762/1349], Loss: 0.1474\n",
            "Epoch [1/3], Step [763/1349], Loss: 0.1633\n",
            "Epoch [1/3], Step [764/1349], Loss: 0.1613\n",
            "Epoch [1/3], Step [765/1349], Loss: 0.2753\n",
            "Epoch [1/3], Step [766/1349], Loss: 0.0681\n",
            "Epoch [1/3], Step [767/1349], Loss: 0.1875\n",
            "Epoch [1/3], Step [768/1349], Loss: 0.0844\n",
            "Epoch [1/3], Step [769/1349], Loss: 0.0735\n",
            "Epoch [1/3], Step [770/1349], Loss: 0.0942\n",
            "Epoch [1/3], Step [771/1349], Loss: 0.2403\n",
            "Epoch [1/3], Step [772/1349], Loss: 0.1436\n",
            "Epoch [1/3], Step [773/1349], Loss: 0.2685\n",
            "Epoch [1/3], Step [774/1349], Loss: 0.0498\n",
            "Epoch [1/3], Step [775/1349], Loss: 0.3067\n",
            "Epoch [1/3], Step [776/1349], Loss: 0.1914\n",
            "Epoch [1/3], Step [777/1349], Loss: 0.0921\n",
            "Epoch [1/3], Step [778/1349], Loss: 0.0395\n",
            "Epoch [1/3], Step [779/1349], Loss: 0.2045\n",
            "Epoch [1/3], Step [780/1349], Loss: 0.0868\n",
            "Epoch [1/3], Step [781/1349], Loss: 0.0908\n",
            "Epoch [1/3], Step [782/1349], Loss: 0.1389\n",
            "Epoch [1/3], Step [783/1349], Loss: 0.0481\n",
            "Epoch [1/3], Step [784/1349], Loss: 0.1815\n",
            "Epoch [1/3], Step [785/1349], Loss: 0.1452\n",
            "Epoch [1/3], Step [786/1349], Loss: 0.1048\n",
            "Epoch [1/3], Step [787/1349], Loss: 0.2312\n",
            "Epoch [1/3], Step [788/1349], Loss: 0.1098\n",
            "Epoch [1/3], Step [789/1349], Loss: 0.1034\n",
            "Epoch [1/3], Step [790/1349], Loss: 0.2284\n",
            "Epoch [1/3], Step [791/1349], Loss: 0.1626\n",
            "Epoch [1/3], Step [792/1349], Loss: 0.1980\n",
            "Epoch [1/3], Step [793/1349], Loss: 0.1635\n",
            "Epoch [1/3], Step [794/1349], Loss: 0.1315\n",
            "Epoch [1/3], Step [795/1349], Loss: 0.3143\n",
            "Epoch [1/3], Step [796/1349], Loss: 0.2413\n",
            "Epoch [1/3], Step [797/1349], Loss: 0.2149\n",
            "Epoch [1/3], Step [798/1349], Loss: 0.0416\n",
            "Epoch [1/3], Step [799/1349], Loss: 0.0867\n",
            "Epoch [1/3], Step [800/1349], Loss: 0.0661\n",
            "Epoch [1/3], Step [801/1349], Loss: 0.1153\n",
            "Epoch [1/3], Step [802/1349], Loss: 0.1746\n",
            "Epoch [1/3], Step [803/1349], Loss: 0.0943\n",
            "Epoch [1/3], Step [804/1349], Loss: 0.0564\n",
            "Epoch [1/3], Step [805/1349], Loss: 0.1053\n",
            "Epoch [1/3], Step [806/1349], Loss: 0.1892\n",
            "Epoch [1/3], Step [807/1349], Loss: 0.1568\n",
            "Epoch [1/3], Step [808/1349], Loss: 0.1578\n",
            "Epoch [1/3], Step [809/1349], Loss: 0.1653\n",
            "Epoch [1/3], Step [810/1349], Loss: 0.0710\n",
            "Epoch [1/3], Step [811/1349], Loss: 0.0651\n",
            "Epoch [1/3], Step [812/1349], Loss: 0.1245\n",
            "Epoch [1/3], Step [813/1349], Loss: 0.2470\n",
            "Epoch [1/3], Step [814/1349], Loss: 0.1128\n",
            "Epoch [1/3], Step [815/1349], Loss: 0.1330\n",
            "Epoch [1/3], Step [816/1349], Loss: 0.3226\n",
            "Epoch [1/3], Step [817/1349], Loss: 0.0736\n",
            "Epoch [1/3], Step [818/1349], Loss: 0.1800\n",
            "Epoch [1/3], Step [819/1349], Loss: 0.2437\n",
            "Epoch [1/3], Step [820/1349], Loss: 0.0494\n",
            "Epoch [1/3], Step [821/1349], Loss: 0.1279\n",
            "Epoch [1/3], Step [822/1349], Loss: 0.1450\n",
            "Epoch [1/3], Step [823/1349], Loss: 0.0909\n",
            "Epoch [1/3], Step [824/1349], Loss: 0.1366\n",
            "Epoch [1/3], Step [825/1349], Loss: 0.0838\n",
            "Epoch [1/3], Step [826/1349], Loss: 0.1097\n",
            "Epoch [1/3], Step [827/1349], Loss: 0.1024\n",
            "Epoch [1/3], Step [828/1349], Loss: 0.1341\n",
            "Epoch [1/3], Step [829/1349], Loss: 0.1718\n",
            "Epoch [1/3], Step [830/1349], Loss: 0.1084\n",
            "Epoch [1/3], Step [831/1349], Loss: 0.0786\n",
            "Epoch [1/3], Step [832/1349], Loss: 0.3125\n",
            "Epoch [1/3], Step [833/1349], Loss: 0.0982\n",
            "Epoch [1/3], Step [834/1349], Loss: 0.0537\n",
            "Epoch [1/3], Step [835/1349], Loss: 0.0451\n",
            "Epoch [1/3], Step [836/1349], Loss: 0.0928\n",
            "Epoch [1/3], Step [837/1349], Loss: 0.0958\n",
            "Epoch [1/3], Step [838/1349], Loss: 0.2590\n",
            "Epoch [1/3], Step [839/1349], Loss: 0.1549\n",
            "Epoch [1/3], Step [840/1349], Loss: 0.2266\n",
            "Epoch [1/3], Step [841/1349], Loss: 0.1467\n",
            "Epoch [1/3], Step [842/1349], Loss: 0.1786\n",
            "Epoch [1/3], Step [843/1349], Loss: 0.0625\n",
            "Epoch [1/3], Step [844/1349], Loss: 0.1465\n",
            "Epoch [1/3], Step [845/1349], Loss: 0.1725\n",
            "Epoch [1/3], Step [846/1349], Loss: 0.1308\n",
            "Epoch [1/3], Step [847/1349], Loss: 0.1575\n",
            "Epoch [1/3], Step [848/1349], Loss: 0.0615\n",
            "Epoch [1/3], Step [849/1349], Loss: 0.0696\n",
            "Epoch [1/3], Step [850/1349], Loss: 0.0472\n",
            "Epoch [1/3], Step [851/1349], Loss: 0.1251\n",
            "Epoch [1/3], Step [852/1349], Loss: 0.1957\n",
            "Epoch [1/3], Step [853/1349], Loss: 0.1072\n",
            "Epoch [1/3], Step [854/1349], Loss: 0.3135\n",
            "Epoch [1/3], Step [855/1349], Loss: 0.1427\n",
            "Epoch [1/3], Step [856/1349], Loss: 0.1659\n",
            "Epoch [1/3], Step [857/1349], Loss: 0.0957\n",
            "Epoch [1/3], Step [858/1349], Loss: 0.2100\n",
            "Epoch [1/3], Step [859/1349], Loss: 0.2135\n",
            "Epoch [1/3], Step [860/1349], Loss: 0.0806\n",
            "Epoch [1/3], Step [861/1349], Loss: 0.0948\n",
            "Epoch [1/3], Step [862/1349], Loss: 0.0288\n",
            "Epoch [1/3], Step [863/1349], Loss: 0.0913\n",
            "Epoch [1/3], Step [864/1349], Loss: 0.0901\n",
            "Epoch [1/3], Step [865/1349], Loss: 0.0775\n",
            "Epoch [1/3], Step [866/1349], Loss: 0.1746\n",
            "Epoch [1/3], Step [867/1349], Loss: 0.1504\n",
            "Epoch [1/3], Step [868/1349], Loss: 0.1228\n",
            "Epoch [1/3], Step [869/1349], Loss: 0.1814\n",
            "Epoch [1/3], Step [870/1349], Loss: 0.0335\n",
            "Epoch [1/3], Step [871/1349], Loss: 0.0838\n",
            "Epoch [1/3], Step [872/1349], Loss: 0.2706\n",
            "Epoch [1/3], Step [873/1349], Loss: 0.1173\n",
            "Epoch [1/3], Step [874/1349], Loss: 0.0903\n",
            "Epoch [1/3], Step [875/1349], Loss: 0.0233\n",
            "Epoch [1/3], Step [876/1349], Loss: 0.2069\n",
            "Epoch [1/3], Step [877/1349], Loss: 0.0601\n",
            "Epoch [1/3], Step [878/1349], Loss: 0.2424\n",
            "Epoch [1/3], Step [879/1349], Loss: 0.0302\n",
            "Epoch [1/3], Step [880/1349], Loss: 0.0339\n",
            "Epoch [1/3], Step [881/1349], Loss: 0.2480\n",
            "Epoch [1/3], Step [882/1349], Loss: 0.0405\n",
            "Epoch [1/3], Step [883/1349], Loss: 0.1452\n",
            "Epoch [1/3], Step [884/1349], Loss: 0.2141\n",
            "Epoch [1/3], Step [885/1349], Loss: 0.2117\n",
            "Epoch [1/3], Step [886/1349], Loss: 0.1892\n",
            "Epoch [1/3], Step [887/1349], Loss: 0.1336\n",
            "Epoch [1/3], Step [888/1349], Loss: 0.2494\n",
            "Epoch [1/3], Step [889/1349], Loss: 0.1191\n",
            "Epoch [1/3], Step [890/1349], Loss: 0.0862\n",
            "Epoch [1/3], Step [891/1349], Loss: 0.0747\n",
            "Epoch [1/3], Step [892/1349], Loss: 0.3594\n",
            "Epoch [1/3], Step [893/1349], Loss: 0.1922\n",
            "Epoch [1/3], Step [894/1349], Loss: 0.0373\n",
            "Epoch [1/3], Step [895/1349], Loss: 0.1346\n",
            "Epoch [1/3], Step [896/1349], Loss: 0.1764\n",
            "Epoch [1/3], Step [897/1349], Loss: 0.0240\n",
            "Epoch [1/3], Step [898/1349], Loss: 0.0957\n",
            "Epoch [1/3], Step [899/1349], Loss: 0.2003\n",
            "Epoch [1/3], Step [900/1349], Loss: 0.1182\n",
            "Epoch [1/3], Step [901/1349], Loss: 0.1149\n",
            "Epoch [1/3], Step [902/1349], Loss: 0.1234\n",
            "Epoch [1/3], Step [903/1349], Loss: 0.1521\n",
            "Epoch [1/3], Step [904/1349], Loss: 0.2728\n",
            "Epoch [1/3], Step [905/1349], Loss: 0.3575\n",
            "Epoch [1/3], Step [906/1349], Loss: 0.2551\n",
            "Epoch [1/3], Step [907/1349], Loss: 0.1044\n",
            "Epoch [1/3], Step [908/1349], Loss: 0.1286\n",
            "Epoch [1/3], Step [909/1349], Loss: 0.0268\n",
            "Epoch [1/3], Step [910/1349], Loss: 0.1230\n",
            "Epoch [1/3], Step [911/1349], Loss: 0.0970\n",
            "Epoch [1/3], Step [912/1349], Loss: 0.1926\n",
            "Epoch [1/3], Step [913/1349], Loss: 0.2047\n",
            "Epoch [1/3], Step [914/1349], Loss: 0.0691\n",
            "Epoch [1/3], Step [915/1349], Loss: 0.1670\n",
            "Epoch [1/3], Step [916/1349], Loss: 0.0266\n",
            "Epoch [1/3], Step [917/1349], Loss: 0.0329\n",
            "Epoch [1/3], Step [918/1349], Loss: 0.2940\n",
            "Epoch [1/3], Step [919/1349], Loss: 0.2058\n",
            "Epoch [1/3], Step [920/1349], Loss: 0.2261\n",
            "Epoch [1/3], Step [921/1349], Loss: 0.0286\n",
            "Epoch [1/3], Step [922/1349], Loss: 0.1398\n",
            "Epoch [1/3], Step [923/1349], Loss: 0.2654\n",
            "Epoch [1/3], Step [924/1349], Loss: 0.2321\n",
            "Epoch [1/3], Step [925/1349], Loss: 0.0792\n",
            "Epoch [1/3], Step [926/1349], Loss: 0.1215\n",
            "Epoch [1/3], Step [927/1349], Loss: 0.1993\n",
            "Epoch [1/3], Step [928/1349], Loss: 0.1694\n",
            "Epoch [1/3], Step [929/1349], Loss: 0.0216\n",
            "Epoch [1/3], Step [930/1349], Loss: 0.0871\n",
            "Epoch [1/3], Step [931/1349], Loss: 0.1387\n",
            "Epoch [1/3], Step [932/1349], Loss: 0.1071\n",
            "Epoch [1/3], Step [933/1349], Loss: 0.2170\n",
            "Epoch [1/3], Step [934/1349], Loss: 0.1426\n",
            "Epoch [1/3], Step [935/1349], Loss: 0.1644\n",
            "Epoch [1/3], Step [936/1349], Loss: 0.0765\n",
            "Epoch [1/3], Step [937/1349], Loss: 0.1071\n",
            "Epoch [1/3], Step [938/1349], Loss: 0.1692\n",
            "Epoch [1/3], Step [939/1349], Loss: 0.1682\n",
            "Epoch [1/3], Step [940/1349], Loss: 0.0432\n",
            "Epoch [1/3], Step [941/1349], Loss: 0.1914\n",
            "Epoch [1/3], Step [942/1349], Loss: 0.1662\n",
            "Epoch [1/3], Step [943/1349], Loss: 0.0876\n",
            "Epoch [1/3], Step [944/1349], Loss: 0.0686\n",
            "Epoch [1/3], Step [945/1349], Loss: 0.2889\n",
            "Epoch [1/3], Step [946/1349], Loss: 0.2594\n",
            "Epoch [1/3], Step [947/1349], Loss: 0.1260\n",
            "Epoch [1/3], Step [948/1349], Loss: 0.3156\n",
            "Epoch [1/3], Step [949/1349], Loss: 0.1249\n",
            "Epoch [1/3], Step [950/1349], Loss: 0.3294\n",
            "Epoch [1/3], Step [951/1349], Loss: 0.2839\n",
            "Epoch [1/3], Step [952/1349], Loss: 0.1431\n",
            "Epoch [1/3], Step [953/1349], Loss: 0.0690\n",
            "Epoch [1/3], Step [954/1349], Loss: 0.1172\n",
            "Epoch [1/3], Step [955/1349], Loss: 0.1887\n",
            "Epoch [1/3], Step [956/1349], Loss: 0.0662\n",
            "Epoch [1/3], Step [957/1349], Loss: 0.0488\n",
            "Epoch [1/3], Step [958/1349], Loss: 0.0630\n",
            "Epoch [1/3], Step [959/1349], Loss: 0.0948\n",
            "Epoch [1/3], Step [960/1349], Loss: 0.2332\n",
            "Epoch [1/3], Step [961/1349], Loss: 0.0471\n",
            "Epoch [1/3], Step [962/1349], Loss: 0.1833\n",
            "Epoch [1/3], Step [963/1349], Loss: 0.1721\n",
            "Epoch [1/3], Step [964/1349], Loss: 0.0884\n",
            "Epoch [1/3], Step [965/1349], Loss: 0.3089\n",
            "Epoch [1/3], Step [966/1349], Loss: 0.0649\n",
            "Epoch [1/3], Step [967/1349], Loss: 0.1298\n",
            "Epoch [1/3], Step [968/1349], Loss: 0.0994\n",
            "Epoch [1/3], Step [969/1349], Loss: 0.0953\n",
            "Epoch [1/3], Step [970/1349], Loss: 0.0420\n",
            "Epoch [1/3], Step [971/1349], Loss: 0.1186\n",
            "Epoch [1/3], Step [972/1349], Loss: 0.0735\n",
            "Epoch [1/3], Step [973/1349], Loss: 0.1335\n",
            "Epoch [1/3], Step [974/1349], Loss: 0.1002\n",
            "Epoch [1/3], Step [975/1349], Loss: 0.0449\n",
            "Epoch [1/3], Step [976/1349], Loss: 0.1932\n",
            "Epoch [1/3], Step [977/1349], Loss: 0.3677\n",
            "Epoch [1/3], Step [978/1349], Loss: 0.0433\n",
            "Epoch [1/3], Step [979/1349], Loss: 0.1144\n",
            "Epoch [1/3], Step [980/1349], Loss: 0.2180\n",
            "Epoch [1/3], Step [981/1349], Loss: 0.0949\n",
            "Epoch [1/3], Step [982/1349], Loss: 0.1004\n",
            "Epoch [1/3], Step [983/1349], Loss: 0.1945\n",
            "Epoch [1/3], Step [984/1349], Loss: 0.0717\n",
            "Epoch [1/3], Step [985/1349], Loss: 0.1051\n",
            "Epoch [1/3], Step [986/1349], Loss: 0.0856\n",
            "Epoch [1/3], Step [987/1349], Loss: 0.0768\n",
            "Epoch [1/3], Step [988/1349], Loss: 0.1106\n",
            "Epoch [1/3], Step [989/1349], Loss: 0.0673\n",
            "Epoch [1/3], Step [990/1349], Loss: 0.1115\n",
            "Epoch [1/3], Step [991/1349], Loss: 0.2672\n",
            "Epoch [1/3], Step [992/1349], Loss: 0.0173\n",
            "Epoch [1/3], Step [993/1349], Loss: 0.2081\n",
            "Epoch [1/3], Step [994/1349], Loss: 0.1203\n",
            "Epoch [1/3], Step [995/1349], Loss: 0.1025\n",
            "Epoch [1/3], Step [996/1349], Loss: 0.1075\n",
            "Epoch [1/3], Step [997/1349], Loss: 0.2840\n",
            "Epoch [1/3], Step [998/1349], Loss: 0.0290\n",
            "Epoch [1/3], Step [999/1349], Loss: 0.3049\n",
            "Epoch [1/3], Step [1000/1349], Loss: 0.3623\n",
            "Epoch [1/3], Step [1001/1349], Loss: 0.2681\n",
            "Epoch [1/3], Step [1002/1349], Loss: 0.1040\n",
            "Epoch [1/3], Step [1003/1349], Loss: 0.2958\n",
            "Epoch [1/3], Step [1004/1349], Loss: 0.1693\n",
            "Epoch [1/3], Step [1005/1349], Loss: 0.1526\n",
            "Epoch [1/3], Step [1006/1349], Loss: 0.0972\n",
            "Epoch [1/3], Step [1007/1349], Loss: 0.0466\n",
            "Epoch [1/3], Step [1008/1349], Loss: 0.1503\n",
            "Epoch [1/3], Step [1009/1349], Loss: 0.0645\n",
            "Epoch [1/3], Step [1010/1349], Loss: 0.2563\n",
            "Epoch [1/3], Step [1011/1349], Loss: 0.0640\n",
            "Epoch [1/3], Step [1012/1349], Loss: 0.0951\n",
            "Epoch [1/3], Step [1013/1349], Loss: 0.1568\n",
            "Epoch [1/3], Step [1014/1349], Loss: 0.0179\n",
            "Epoch [1/3], Step [1015/1349], Loss: 0.3744\n",
            "Epoch [1/3], Step [1016/1349], Loss: 0.1234\n",
            "Epoch [1/3], Step [1017/1349], Loss: 0.1380\n",
            "Epoch [1/3], Step [1018/1349], Loss: 0.2694\n",
            "Epoch [1/3], Step [1019/1349], Loss: 0.0898\n",
            "Epoch [1/3], Step [1020/1349], Loss: 0.1201\n",
            "Epoch [1/3], Step [1021/1349], Loss: 0.2581\n",
            "Epoch [1/3], Step [1022/1349], Loss: 0.0443\n",
            "Epoch [1/3], Step [1023/1349], Loss: 0.0737\n",
            "Epoch [1/3], Step [1024/1349], Loss: 0.2364\n",
            "Epoch [1/3], Step [1025/1349], Loss: 0.1189\n",
            "Epoch [1/3], Step [1026/1349], Loss: 0.0186\n",
            "Epoch [1/3], Step [1027/1349], Loss: 0.0909\n",
            "Epoch [1/3], Step [1028/1349], Loss: 0.1766\n",
            "Epoch [1/3], Step [1029/1349], Loss: 0.1031\n",
            "Epoch [1/3], Step [1030/1349], Loss: 0.1781\n",
            "Epoch [1/3], Step [1031/1349], Loss: 0.1636\n",
            "Epoch [1/3], Step [1032/1349], Loss: 0.1656\n",
            "Epoch [1/3], Step [1033/1349], Loss: 0.0726\n",
            "Epoch [1/3], Step [1034/1349], Loss: 0.1235\n",
            "Epoch [1/3], Step [1035/1349], Loss: 0.0340\n",
            "Epoch [1/3], Step [1036/1349], Loss: 0.1062\n",
            "Epoch [1/3], Step [1037/1349], Loss: 0.3483\n",
            "Epoch [1/3], Step [1038/1349], Loss: 0.2367\n",
            "Epoch [1/3], Step [1039/1349], Loss: 0.2191\n",
            "Epoch [1/3], Step [1040/1349], Loss: 0.1567\n",
            "Epoch [1/3], Step [1041/1349], Loss: 0.1321\n",
            "Epoch [1/3], Step [1042/1349], Loss: 0.2104\n",
            "Epoch [1/3], Step [1043/1349], Loss: 0.3717\n",
            "Epoch [1/3], Step [1044/1349], Loss: 0.1287\n",
            "Epoch [1/3], Step [1045/1349], Loss: 0.1252\n",
            "Epoch [1/3], Step [1046/1349], Loss: 0.1844\n",
            "Epoch [1/3], Step [1047/1349], Loss: 0.1700\n",
            "Epoch [1/3], Step [1048/1349], Loss: 0.0419\n",
            "Epoch [1/3], Step [1049/1349], Loss: 0.0826\n",
            "Epoch [1/3], Step [1050/1349], Loss: 0.0952\n",
            "Epoch [1/3], Step [1051/1349], Loss: 0.1591\n",
            "Epoch [1/3], Step [1052/1349], Loss: 0.1703\n",
            "Epoch [1/3], Step [1053/1349], Loss: 0.1010\n",
            "Epoch [1/3], Step [1054/1349], Loss: 0.1237\n",
            "Epoch [1/3], Step [1055/1349], Loss: 0.1185\n",
            "Epoch [1/3], Step [1056/1349], Loss: 0.2361\n",
            "Epoch [1/3], Step [1057/1349], Loss: 0.0813\n",
            "Epoch [1/3], Step [1058/1349], Loss: 0.0712\n",
            "Epoch [1/3], Step [1059/1349], Loss: 0.0333\n",
            "Epoch [1/3], Step [1060/1349], Loss: 0.1689\n",
            "Epoch [1/3], Step [1061/1349], Loss: 0.0358\n",
            "Epoch [1/3], Step [1062/1349], Loss: 0.1717\n",
            "Epoch [1/3], Step [1063/1349], Loss: 0.1296\n",
            "Epoch [1/3], Step [1064/1349], Loss: 0.1308\n",
            "Epoch [1/3], Step [1065/1349], Loss: 0.1681\n",
            "Epoch [1/3], Step [1066/1349], Loss: 0.2474\n",
            "Epoch [1/3], Step [1067/1349], Loss: 0.1315\n",
            "Epoch [1/3], Step [1068/1349], Loss: 0.2901\n",
            "Epoch [1/3], Step [1069/1349], Loss: 0.0300\n",
            "Epoch [1/3], Step [1070/1349], Loss: 0.0495\n",
            "Epoch [1/3], Step [1071/1349], Loss: 0.0866\n",
            "Epoch [1/3], Step [1072/1349], Loss: 0.1309\n",
            "Epoch [1/3], Step [1073/1349], Loss: 0.0916\n",
            "Epoch [1/3], Step [1074/1349], Loss: 0.2053\n",
            "Epoch [1/3], Step [1075/1349], Loss: 0.1745\n",
            "Epoch [1/3], Step [1076/1349], Loss: 0.0592\n",
            "Epoch [1/3], Step [1077/1349], Loss: 0.1078\n",
            "Epoch [1/3], Step [1078/1349], Loss: 0.0869\n",
            "Epoch [1/3], Step [1079/1349], Loss: 0.0698\n",
            "Epoch [1/3], Step [1080/1349], Loss: 0.2837\n",
            "Epoch [1/3], Step [1081/1349], Loss: 0.1063\n",
            "Epoch [1/3], Step [1082/1349], Loss: 0.3272\n",
            "Epoch [1/3], Step [1083/1349], Loss: 0.1263\n",
            "Epoch [1/3], Step [1084/1349], Loss: 0.0627\n",
            "Epoch [1/3], Step [1085/1349], Loss: 0.0504\n",
            "Epoch [1/3], Step [1086/1349], Loss: 0.1209\n",
            "Epoch [1/3], Step [1087/1349], Loss: 0.0589\n",
            "Epoch [1/3], Step [1088/1349], Loss: 0.0715\n",
            "Epoch [1/3], Step [1089/1349], Loss: 0.0775\n",
            "Epoch [1/3], Step [1090/1349], Loss: 0.2447\n",
            "Epoch [1/3], Step [1091/1349], Loss: 0.1141\n",
            "Epoch [1/3], Step [1092/1349], Loss: 0.0395\n",
            "Epoch [1/3], Step [1093/1349], Loss: 0.1344\n",
            "Epoch [1/3], Step [1094/1349], Loss: 0.1945\n",
            "Epoch [1/3], Step [1095/1349], Loss: 0.1733\n",
            "Epoch [1/3], Step [1096/1349], Loss: 0.2598\n",
            "Epoch [1/3], Step [1097/1349], Loss: 0.1679\n",
            "Epoch [1/3], Step [1098/1349], Loss: 0.0747\n",
            "Epoch [1/3], Step [1099/1349], Loss: 0.1298\n",
            "Epoch [1/3], Step [1100/1349], Loss: 0.0770\n",
            "Epoch [1/3], Step [1101/1349], Loss: 0.2605\n",
            "Epoch [1/3], Step [1102/1349], Loss: 0.1324\n",
            "Epoch [1/3], Step [1103/1349], Loss: 0.1509\n",
            "Epoch [1/3], Step [1104/1349], Loss: 0.1332\n",
            "Epoch [1/3], Step [1105/1349], Loss: 0.1277\n",
            "Epoch [1/3], Step [1106/1349], Loss: 0.2701\n",
            "Epoch [1/3], Step [1107/1349], Loss: 0.1072\n",
            "Epoch [1/3], Step [1108/1349], Loss: 0.0750\n",
            "Epoch [1/3], Step [1109/1349], Loss: 0.0899\n",
            "Epoch [1/3], Step [1110/1349], Loss: 0.0335\n",
            "Epoch [1/3], Step [1111/1349], Loss: 0.0936\n",
            "Epoch [1/3], Step [1112/1349], Loss: 0.0490\n",
            "Epoch [1/3], Step [1113/1349], Loss: 0.2615\n",
            "Epoch [1/3], Step [1114/1349], Loss: 0.2094\n",
            "Epoch [1/3], Step [1115/1349], Loss: 0.0425\n",
            "Epoch [1/3], Step [1116/1349], Loss: 0.1071\n",
            "Epoch [1/3], Step [1117/1349], Loss: 0.0988\n",
            "Epoch [1/3], Step [1118/1349], Loss: 0.2636\n",
            "Epoch [1/3], Step [1119/1349], Loss: 0.0963\n",
            "Epoch [1/3], Step [1120/1349], Loss: 0.1014\n",
            "Epoch [1/3], Step [1121/1349], Loss: 0.0644\n",
            "Epoch [1/3], Step [1122/1349], Loss: 0.1283\n",
            "Epoch [1/3], Step [1123/1349], Loss: 0.1824\n",
            "Epoch [1/3], Step [1124/1349], Loss: 0.0640\n",
            "Epoch [1/3], Step [1125/1349], Loss: 0.2597\n",
            "Epoch [1/3], Step [1126/1349], Loss: 0.1390\n",
            "Epoch [1/3], Step [1127/1349], Loss: 0.0772\n",
            "Epoch [1/3], Step [1128/1349], Loss: 0.1500\n",
            "Epoch [1/3], Step [1129/1349], Loss: 0.1110\n",
            "Epoch [1/3], Step [1130/1349], Loss: 0.3558\n",
            "Epoch [1/3], Step [1131/1349], Loss: 0.3466\n",
            "Epoch [1/3], Step [1132/1349], Loss: 0.1800\n",
            "Epoch [1/3], Step [1133/1349], Loss: 0.0548\n",
            "Epoch [1/3], Step [1134/1349], Loss: 0.1256\n",
            "Epoch [1/3], Step [1135/1349], Loss: 0.1403\n",
            "Epoch [1/3], Step [1136/1349], Loss: 0.0171\n",
            "Epoch [1/3], Step [1137/1349], Loss: 0.0385\n",
            "Epoch [1/3], Step [1138/1349], Loss: 0.1170\n",
            "Epoch [1/3], Step [1139/1349], Loss: 0.1335\n",
            "Epoch [1/3], Step [1140/1349], Loss: 0.1328\n",
            "Epoch [1/3], Step [1141/1349], Loss: 0.0915\n",
            "Epoch [1/3], Step [1142/1349], Loss: 0.2724\n",
            "Epoch [1/3], Step [1143/1349], Loss: 0.0437\n",
            "Epoch [1/3], Step [1144/1349], Loss: 0.1793\n",
            "Epoch [1/3], Step [1145/1349], Loss: 0.0548\n",
            "Epoch [1/3], Step [1146/1349], Loss: 0.1234\n",
            "Epoch [1/3], Step [1147/1349], Loss: 0.1469\n",
            "Epoch [1/3], Step [1148/1349], Loss: 0.1102\n",
            "Epoch [1/3], Step [1149/1349], Loss: 0.1396\n",
            "Epoch [1/3], Step [1150/1349], Loss: 0.0525\n",
            "Epoch [1/3], Step [1151/1349], Loss: 0.0837\n",
            "Epoch [1/3], Step [1152/1349], Loss: 0.1719\n",
            "Epoch [1/3], Step [1153/1349], Loss: 0.0615\n",
            "Epoch [1/3], Step [1154/1349], Loss: 0.0244\n",
            "Epoch [1/3], Step [1155/1349], Loss: 0.2716\n",
            "Epoch [1/3], Step [1156/1349], Loss: 0.0456\n",
            "Epoch [1/3], Step [1157/1349], Loss: 0.0538\n",
            "Epoch [1/3], Step [1158/1349], Loss: 0.0582\n",
            "Epoch [1/3], Step [1159/1349], Loss: 0.0232\n",
            "Epoch [1/3], Step [1160/1349], Loss: 0.0344\n",
            "Epoch [1/3], Step [1161/1349], Loss: 0.1146\n",
            "Epoch [1/3], Step [1162/1349], Loss: 0.1275\n",
            "Epoch [1/3], Step [1163/1349], Loss: 0.1175\n",
            "Epoch [1/3], Step [1164/1349], Loss: 0.0547\n",
            "Epoch [1/3], Step [1165/1349], Loss: 0.0750\n",
            "Epoch [1/3], Step [1166/1349], Loss: 0.3419\n",
            "Epoch [1/3], Step [1167/1349], Loss: 0.0879\n",
            "Epoch [1/3], Step [1168/1349], Loss: 0.0749\n",
            "Epoch [1/3], Step [1169/1349], Loss: 0.1063\n",
            "Epoch [1/3], Step [1170/1349], Loss: 0.2366\n",
            "Epoch [1/3], Step [1171/1349], Loss: 0.0572\n",
            "Epoch [1/3], Step [1172/1349], Loss: 0.3050\n",
            "Epoch [1/3], Step [1173/1349], Loss: 0.1775\n",
            "Epoch [1/3], Step [1174/1349], Loss: 0.0812\n",
            "Epoch [1/3], Step [1175/1349], Loss: 0.1244\n",
            "Epoch [1/3], Step [1176/1349], Loss: 0.0291\n",
            "Epoch [1/3], Step [1177/1349], Loss: 0.1977\n",
            "Epoch [1/3], Step [1178/1349], Loss: 0.0429\n",
            "Epoch [1/3], Step [1179/1349], Loss: 0.1088\n",
            "Epoch [1/3], Step [1180/1349], Loss: 0.0715\n",
            "Epoch [1/3], Step [1181/1349], Loss: 0.0729\n",
            "Epoch [1/3], Step [1182/1349], Loss: 0.2369\n",
            "Epoch [1/3], Step [1183/1349], Loss: 0.1155\n",
            "Epoch [1/3], Step [1184/1349], Loss: 0.1010\n",
            "Epoch [1/3], Step [1185/1349], Loss: 0.0530\n",
            "Epoch [1/3], Step [1186/1349], Loss: 0.1301\n",
            "Epoch [1/3], Step [1187/1349], Loss: 0.1696\n",
            "Epoch [1/3], Step [1188/1349], Loss: 0.0647\n",
            "Epoch [1/3], Step [1189/1349], Loss: 0.1742\n",
            "Epoch [1/3], Step [1190/1349], Loss: 0.1180\n",
            "Epoch [1/3], Step [1191/1349], Loss: 0.0462\n",
            "Epoch [1/3], Step [1192/1349], Loss: 0.0762\n",
            "Epoch [1/3], Step [1193/1349], Loss: 0.0912\n",
            "Epoch [1/3], Step [1194/1349], Loss: 0.2288\n",
            "Epoch [1/3], Step [1195/1349], Loss: 0.2011\n",
            "Epoch [1/3], Step [1196/1349], Loss: 0.2370\n",
            "Epoch [1/3], Step [1197/1349], Loss: 0.1861\n",
            "Epoch [1/3], Step [1198/1349], Loss: 0.1085\n",
            "Epoch [1/3], Step [1199/1349], Loss: 0.0472\n",
            "Epoch [1/3], Step [1200/1349], Loss: 0.0767\n",
            "Epoch [1/3], Step [1201/1349], Loss: 0.0514\n",
            "Epoch [1/3], Step [1202/1349], Loss: 0.0331\n",
            "Epoch [1/3], Step [1203/1349], Loss: 0.0314\n",
            "Epoch [1/3], Step [1204/1349], Loss: 0.1962\n",
            "Epoch [1/3], Step [1205/1349], Loss: 0.0253\n",
            "Epoch [1/3], Step [1206/1349], Loss: 0.1388\n",
            "Epoch [1/3], Step [1207/1349], Loss: 0.1577\n",
            "Epoch [1/3], Step [1208/1349], Loss: 0.0294\n",
            "Epoch [1/3], Step [1209/1349], Loss: 0.1055\n",
            "Epoch [1/3], Step [1210/1349], Loss: 0.2202\n",
            "Epoch [1/3], Step [1211/1349], Loss: 0.1745\n",
            "Epoch [1/3], Step [1212/1349], Loss: 0.1881\n",
            "Epoch [1/3], Step [1213/1349], Loss: 0.1031\n",
            "Epoch [1/3], Step [1214/1349], Loss: 0.1452\n",
            "Epoch [1/3], Step [1215/1349], Loss: 0.2730\n",
            "Epoch [1/3], Step [1216/1349], Loss: 0.1273\n",
            "Epoch [1/3], Step [1217/1349], Loss: 0.1088\n",
            "Epoch [1/3], Step [1218/1349], Loss: 0.3066\n",
            "Epoch [1/3], Step [1219/1349], Loss: 0.1448\n",
            "Epoch [1/3], Step [1220/1349], Loss: 0.0811\n",
            "Epoch [1/3], Step [1221/1349], Loss: 0.0743\n",
            "Epoch [1/3], Step [1222/1349], Loss: 0.1367\n",
            "Epoch [1/3], Step [1223/1349], Loss: 0.2815\n",
            "Epoch [1/3], Step [1224/1349], Loss: 0.1658\n",
            "Epoch [1/3], Step [1225/1349], Loss: 0.0254\n",
            "Epoch [1/3], Step [1226/1349], Loss: 0.1010\n",
            "Epoch [1/3], Step [1227/1349], Loss: 0.0738\n",
            "Epoch [1/3], Step [1228/1349], Loss: 0.0896\n",
            "Epoch [1/3], Step [1229/1349], Loss: 0.1515\n",
            "Epoch [1/3], Step [1230/1349], Loss: 0.1675\n",
            "Epoch [1/3], Step [1231/1349], Loss: 0.1709\n",
            "Epoch [1/3], Step [1232/1349], Loss: 0.1758\n",
            "Epoch [1/3], Step [1233/1349], Loss: 0.1095\n",
            "Epoch [1/3], Step [1234/1349], Loss: 0.0850\n",
            "Epoch [1/3], Step [1235/1349], Loss: 0.1977\n",
            "Epoch [1/3], Step [1236/1349], Loss: 0.1017\n",
            "Epoch [1/3], Step [1237/1349], Loss: 0.0766\n",
            "Epoch [1/3], Step [1238/1349], Loss: 0.2759\n",
            "Epoch [1/3], Step [1239/1349], Loss: 0.0761\n",
            "Epoch [1/3], Step [1240/1349], Loss: 0.0707\n",
            "Epoch [1/3], Step [1241/1349], Loss: 0.0950\n",
            "Epoch [1/3], Step [1242/1349], Loss: 0.1486\n",
            "Epoch [1/3], Step [1243/1349], Loss: 0.2011\n",
            "Epoch [1/3], Step [1244/1349], Loss: 0.1460\n",
            "Epoch [1/3], Step [1245/1349], Loss: 0.0934\n",
            "Epoch [1/3], Step [1246/1349], Loss: 0.0956\n",
            "Epoch [1/3], Step [1247/1349], Loss: 0.0909\n",
            "Epoch [1/3], Step [1248/1349], Loss: 0.1582\n",
            "Epoch [1/3], Step [1249/1349], Loss: 0.0664\n",
            "Epoch [1/3], Step [1250/1349], Loss: 0.2946\n",
            "Epoch [1/3], Step [1251/1349], Loss: 0.1390\n",
            "Epoch [1/3], Step [1252/1349], Loss: 0.2733\n",
            "Epoch [1/3], Step [1253/1349], Loss: 0.0366\n",
            "Epoch [1/3], Step [1254/1349], Loss: 0.0466\n",
            "Epoch [1/3], Step [1255/1349], Loss: 0.1061\n",
            "Epoch [1/3], Step [1256/1349], Loss: 0.0602\n",
            "Epoch [1/3], Step [1257/1349], Loss: 0.0615\n",
            "Epoch [1/3], Step [1258/1349], Loss: 0.0775\n",
            "Epoch [1/3], Step [1259/1349], Loss: 0.1361\n",
            "Epoch [1/3], Step [1260/1349], Loss: 0.0610\n",
            "Epoch [1/3], Step [1261/1349], Loss: 0.0807\n",
            "Epoch [1/3], Step [1262/1349], Loss: 0.0774\n",
            "Epoch [1/3], Step [1263/1349], Loss: 0.0992\n",
            "Epoch [1/3], Step [1264/1349], Loss: 0.1734\n",
            "Epoch [1/3], Step [1265/1349], Loss: 0.0458\n",
            "Epoch [1/3], Step [1266/1349], Loss: 0.0294\n",
            "Epoch [1/3], Step [1267/1349], Loss: 0.1182\n",
            "Epoch [1/3], Step [1268/1349], Loss: 0.0672\n",
            "Epoch [1/3], Step [1269/1349], Loss: 0.1128\n",
            "Epoch [1/3], Step [1270/1349], Loss: 0.0427\n",
            "Epoch [1/3], Step [1271/1349], Loss: 0.1080\n",
            "Epoch [1/3], Step [1272/1349], Loss: 0.0671\n",
            "Epoch [1/3], Step [1273/1349], Loss: 0.0413\n",
            "Epoch [1/3], Step [1274/1349], Loss: 0.0240\n",
            "Epoch [1/3], Step [1275/1349], Loss: 0.1088\n",
            "Epoch [1/3], Step [1276/1349], Loss: 0.0362\n",
            "Epoch [1/3], Step [1277/1349], Loss: 0.1301\n",
            "Epoch [1/3], Step [1278/1349], Loss: 0.1188\n",
            "Epoch [1/3], Step [1279/1349], Loss: 0.2507\n",
            "Epoch [1/3], Step [1280/1349], Loss: 0.0877\n",
            "Epoch [1/3], Step [1281/1349], Loss: 0.0527\n",
            "Epoch [1/3], Step [1282/1349], Loss: 0.0682\n",
            "Epoch [1/3], Step [1283/1349], Loss: 0.0623\n",
            "Epoch [1/3], Step [1284/1349], Loss: 0.1128\n",
            "Epoch [1/3], Step [1285/1349], Loss: 0.1916\n",
            "Epoch [1/3], Step [1286/1349], Loss: 0.0869\n",
            "Epoch [1/3], Step [1287/1349], Loss: 0.0942\n",
            "Epoch [1/3], Step [1288/1349], Loss: 0.1967\n",
            "Epoch [1/3], Step [1289/1349], Loss: 0.0518\n",
            "Epoch [1/3], Step [1290/1349], Loss: 0.0786\n",
            "Epoch [1/3], Step [1291/1349], Loss: 0.0606\n",
            "Epoch [1/3], Step [1292/1349], Loss: 0.0204\n",
            "Epoch [1/3], Step [1293/1349], Loss: 0.1463\n",
            "Epoch [1/3], Step [1294/1349], Loss: 0.0675\n",
            "Epoch [1/3], Step [1295/1349], Loss: 0.1592\n",
            "Epoch [1/3], Step [1296/1349], Loss: 0.2644\n",
            "Epoch [1/3], Step [1297/1349], Loss: 0.0521\n",
            "Epoch [1/3], Step [1298/1349], Loss: 0.0518\n",
            "Epoch [1/3], Step [1299/1349], Loss: 0.0585\n",
            "Epoch [1/3], Step [1300/1349], Loss: 0.0257\n",
            "Epoch [1/3], Step [1301/1349], Loss: 0.1473\n",
            "Epoch [1/3], Step [1302/1349], Loss: 0.1489\n",
            "Epoch [1/3], Step [1303/1349], Loss: 0.0609\n",
            "Epoch [1/3], Step [1304/1349], Loss: 0.1439\n",
            "Epoch [1/3], Step [1305/1349], Loss: 0.0453\n",
            "Epoch [1/3], Step [1306/1349], Loss: 0.1263\n",
            "Epoch [1/3], Step [1307/1349], Loss: 0.0700\n",
            "Epoch [1/3], Step [1308/1349], Loss: 0.1545\n",
            "Epoch [1/3], Step [1309/1349], Loss: 0.0891\n",
            "Epoch [1/3], Step [1310/1349], Loss: 0.0661\n",
            "Epoch [1/3], Step [1311/1349], Loss: 0.0611\n",
            "Epoch [1/3], Step [1312/1349], Loss: 0.2252\n",
            "Epoch [1/3], Step [1313/1349], Loss: 0.0953\n",
            "Epoch [1/3], Step [1314/1349], Loss: 0.0686\n",
            "Epoch [1/3], Step [1315/1349], Loss: 0.1181\n",
            "Epoch [1/3], Step [1316/1349], Loss: 0.1425\n",
            "Epoch [1/3], Step [1317/1349], Loss: 0.0200\n",
            "Epoch [1/3], Step [1318/1349], Loss: 0.2334\n",
            "Epoch [1/3], Step [1319/1349], Loss: 0.0540\n",
            "Epoch [1/3], Step [1320/1349], Loss: 0.0363\n",
            "Epoch [1/3], Step [1321/1349], Loss: 0.0345\n",
            "Epoch [1/3], Step [1322/1349], Loss: 0.2022\n",
            "Epoch [1/3], Step [1323/1349], Loss: 0.1111\n",
            "Epoch [1/3], Step [1324/1349], Loss: 0.0983\n",
            "Epoch [1/3], Step [1325/1349], Loss: 0.1091\n",
            "Epoch [1/3], Step [1326/1349], Loss: 0.0796\n",
            "Epoch [1/3], Step [1327/1349], Loss: 0.0137\n",
            "Epoch [1/3], Step [1328/1349], Loss: 0.1085\n",
            "Epoch [1/3], Step [1329/1349], Loss: 0.0503\n",
            "Epoch [1/3], Step [1330/1349], Loss: 0.0290\n",
            "Epoch [1/3], Step [1331/1349], Loss: 0.1276\n",
            "Epoch [1/3], Step [1332/1349], Loss: 0.1169\n",
            "Epoch [1/3], Step [1333/1349], Loss: 0.0780\n",
            "Epoch [1/3], Step [1334/1349], Loss: 0.1639\n",
            "Epoch [1/3], Step [1335/1349], Loss: 0.0985\n",
            "Epoch [1/3], Step [1336/1349], Loss: 0.0448\n",
            "Epoch [1/3], Step [1337/1349], Loss: 0.0732\n",
            "Epoch [1/3], Step [1338/1349], Loss: 0.0443\n",
            "Epoch [1/3], Step [1339/1349], Loss: 0.0146\n",
            "Epoch [1/3], Step [1340/1349], Loss: 0.0429\n",
            "Epoch [1/3], Step [1341/1349], Loss: 0.0933\n",
            "Epoch [1/3], Step [1342/1349], Loss: 0.0869\n",
            "Epoch [1/3], Step [1343/1349], Loss: 0.1343\n",
            "Epoch [1/3], Step [1344/1349], Loss: 0.0201\n",
            "Epoch [1/3], Step [1345/1349], Loss: 0.1790\n",
            "Epoch [1/3], Step [1346/1349], Loss: 0.0525\n",
            "Epoch [1/3], Step [1347/1349], Loss: 0.0115\n",
            "Epoch [1/3], Step [1348/1349], Loss: 0.0512\n",
            "Epoch [1/3], Step [1349/1349], Loss: 0.0244\n",
            "Epoch [2/3], Step [1/1349], Loss: 0.0830\n",
            "Epoch [2/3], Step [2/1349], Loss: 0.0502\n",
            "Epoch [2/3], Step [3/1349], Loss: 0.2397\n",
            "Epoch [2/3], Step [4/1349], Loss: 0.1147\n",
            "Epoch [2/3], Step [5/1349], Loss: 0.2701\n",
            "Epoch [2/3], Step [6/1349], Loss: 0.2357\n",
            "Epoch [2/3], Step [7/1349], Loss: 0.1557\n",
            "Epoch [2/3], Step [8/1349], Loss: 0.2122\n",
            "Epoch [2/3], Step [9/1349], Loss: 0.2354\n",
            "Epoch [2/3], Step [10/1349], Loss: 0.0649\n",
            "Epoch [2/3], Step [11/1349], Loss: 0.0176\n",
            "Epoch [2/3], Step [12/1349], Loss: 0.0402\n",
            "Epoch [2/3], Step [13/1349], Loss: 0.1557\n",
            "Epoch [2/3], Step [14/1349], Loss: 0.0414\n",
            "Epoch [2/3], Step [15/1349], Loss: 0.1641\n",
            "Epoch [2/3], Step [16/1349], Loss: 0.1265\n",
            "Epoch [2/3], Step [17/1349], Loss: 0.2481\n",
            "Epoch [2/3], Step [18/1349], Loss: 0.2198\n",
            "Epoch [2/3], Step [19/1349], Loss: 0.1628\n",
            "Epoch [2/3], Step [20/1349], Loss: 0.0209\n",
            "Epoch [2/3], Step [21/1349], Loss: 0.0515\n",
            "Epoch [2/3], Step [22/1349], Loss: 0.2387\n",
            "Epoch [2/3], Step [23/1349], Loss: 0.0809\n",
            "Epoch [2/3], Step [24/1349], Loss: 0.1454\n",
            "Epoch [2/3], Step [25/1349], Loss: 0.0506\n",
            "Epoch [2/3], Step [26/1349], Loss: 0.1425\n",
            "Epoch [2/3], Step [27/1349], Loss: 0.2118\n",
            "Epoch [2/3], Step [28/1349], Loss: 0.2179\n",
            "Epoch [2/3], Step [29/1349], Loss: 0.1312\n",
            "Epoch [2/3], Step [30/1349], Loss: 0.0514\n",
            "Epoch [2/3], Step [31/1349], Loss: 0.1448\n",
            "Epoch [2/3], Step [32/1349], Loss: 0.1081\n",
            "Epoch [2/3], Step [33/1349], Loss: 0.0874\n",
            "Epoch [2/3], Step [34/1349], Loss: 0.1085\n",
            "Epoch [2/3], Step [35/1349], Loss: 0.2550\n",
            "Epoch [2/3], Step [36/1349], Loss: 0.1314\n",
            "Epoch [2/3], Step [37/1349], Loss: 0.0922\n",
            "Epoch [2/3], Step [38/1349], Loss: 0.0176\n",
            "Epoch [2/3], Step [39/1349], Loss: 0.0735\n",
            "Epoch [2/3], Step [40/1349], Loss: 0.0898\n",
            "Epoch [2/3], Step [41/1349], Loss: 0.0322\n",
            "Epoch [2/3], Step [42/1349], Loss: 0.0417\n",
            "Epoch [2/3], Step [43/1349], Loss: 0.1002\n",
            "Epoch [2/3], Step [44/1349], Loss: 0.0797\n",
            "Epoch [2/3], Step [45/1349], Loss: 0.0685\n",
            "Epoch [2/3], Step [46/1349], Loss: 0.0953\n",
            "Epoch [2/3], Step [47/1349], Loss: 0.0296\n",
            "Epoch [2/3], Step [48/1349], Loss: 0.0828\n",
            "Epoch [2/3], Step [49/1349], Loss: 0.0654\n",
            "Epoch [2/3], Step [50/1349], Loss: 0.1026\n",
            "Epoch [2/3], Step [51/1349], Loss: 0.1090\n",
            "Epoch [2/3], Step [52/1349], Loss: 0.1504\n",
            "Epoch [2/3], Step [53/1349], Loss: 0.0947\n",
            "Epoch [2/3], Step [54/1349], Loss: 0.0261\n",
            "Epoch [2/3], Step [55/1349], Loss: 0.0652\n",
            "Epoch [2/3], Step [56/1349], Loss: 0.0596\n",
            "Epoch [2/3], Step [57/1349], Loss: 0.1073\n",
            "Epoch [2/3], Step [58/1349], Loss: 0.2052\n",
            "Epoch [2/3], Step [59/1349], Loss: 0.0907\n",
            "Epoch [2/3], Step [60/1349], Loss: 0.0239\n",
            "Epoch [2/3], Step [61/1349], Loss: 0.1071\n",
            "Epoch [2/3], Step [62/1349], Loss: 0.0162\n",
            "Epoch [2/3], Step [63/1349], Loss: 0.0316\n",
            "Epoch [2/3], Step [64/1349], Loss: 0.0533\n",
            "Epoch [2/3], Step [65/1349], Loss: 0.0177\n",
            "Epoch [2/3], Step [66/1349], Loss: 0.0461\n",
            "Epoch [2/3], Step [67/1349], Loss: 0.0216\n",
            "Epoch [2/3], Step [68/1349], Loss: 0.1428\n",
            "Epoch [2/3], Step [69/1349], Loss: 0.1645\n",
            "Epoch [2/3], Step [70/1349], Loss: 0.0080\n",
            "Epoch [2/3], Step [71/1349], Loss: 0.1529\n",
            "Epoch [2/3], Step [72/1349], Loss: 0.0345\n",
            "Epoch [2/3], Step [73/1349], Loss: 0.0320\n",
            "Epoch [2/3], Step [74/1349], Loss: 0.1669\n",
            "Epoch [2/3], Step [75/1349], Loss: 0.0243\n",
            "Epoch [2/3], Step [76/1349], Loss: 0.1464\n",
            "Epoch [2/3], Step [77/1349], Loss: 0.3250\n",
            "Epoch [2/3], Step [78/1349], Loss: 0.0631\n",
            "Epoch [2/3], Step [79/1349], Loss: 0.1014\n",
            "Epoch [2/3], Step [80/1349], Loss: 0.0683\n",
            "Epoch [2/3], Step [81/1349], Loss: 0.1128\n",
            "Epoch [2/3], Step [82/1349], Loss: 0.0066\n",
            "Epoch [2/3], Step [83/1349], Loss: 0.2659\n",
            "Epoch [2/3], Step [84/1349], Loss: 0.0787\n",
            "Epoch [2/3], Step [85/1349], Loss: 0.1134\n",
            "Epoch [2/3], Step [86/1349], Loss: 0.0983\n",
            "Epoch [2/3], Step [87/1349], Loss: 0.0331\n",
            "Epoch [2/3], Step [88/1349], Loss: 0.1822\n",
            "Epoch [2/3], Step [89/1349], Loss: 0.1248\n",
            "Epoch [2/3], Step [90/1349], Loss: 0.0174\n",
            "Epoch [2/3], Step [91/1349], Loss: 0.0675\n",
            "Epoch [2/3], Step [92/1349], Loss: 0.0226\n",
            "Epoch [2/3], Step [93/1349], Loss: 0.1464\n",
            "Epoch [2/3], Step [94/1349], Loss: 0.1445\n",
            "Epoch [2/3], Step [95/1349], Loss: 0.1473\n",
            "Epoch [2/3], Step [96/1349], Loss: 0.0832\n",
            "Epoch [2/3], Step [97/1349], Loss: 0.1847\n",
            "Epoch [2/3], Step [98/1349], Loss: 0.0164\n",
            "Epoch [2/3], Step [99/1349], Loss: 0.0383\n",
            "Epoch [2/3], Step [100/1349], Loss: 0.1414\n",
            "Epoch [2/3], Step [101/1349], Loss: 0.2684\n",
            "Epoch [2/3], Step [102/1349], Loss: 0.1299\n",
            "Epoch [2/3], Step [103/1349], Loss: 0.0893\n",
            "Epoch [2/3], Step [104/1349], Loss: 0.0721\n",
            "Epoch [2/3], Step [105/1349], Loss: 0.0876\n",
            "Epoch [2/3], Step [106/1349], Loss: 0.0391\n",
            "Epoch [2/3], Step [107/1349], Loss: 0.0902\n",
            "Epoch [2/3], Step [108/1349], Loss: 0.1045\n",
            "Epoch [2/3], Step [109/1349], Loss: 0.1199\n",
            "Epoch [2/3], Step [110/1349], Loss: 0.0871\n",
            "Epoch [2/3], Step [111/1349], Loss: 0.1395\n",
            "Epoch [2/3], Step [112/1349], Loss: 0.1533\n",
            "Epoch [2/3], Step [113/1349], Loss: 0.1451\n",
            "Epoch [2/3], Step [114/1349], Loss: 0.1222\n",
            "Epoch [2/3], Step [115/1349], Loss: 0.1025\n",
            "Epoch [2/3], Step [116/1349], Loss: 0.0659\n",
            "Epoch [2/3], Step [117/1349], Loss: 0.3277\n",
            "Epoch [2/3], Step [118/1349], Loss: 0.1253\n",
            "Epoch [2/3], Step [119/1349], Loss: 0.1064\n",
            "Epoch [2/3], Step [120/1349], Loss: 0.2005\n",
            "Epoch [2/3], Step [121/1349], Loss: 0.0735\n",
            "Epoch [2/3], Step [122/1349], Loss: 0.1496\n",
            "Epoch [2/3], Step [123/1349], Loss: 0.0994\n",
            "Epoch [2/3], Step [124/1349], Loss: 0.0758\n",
            "Epoch [2/3], Step [125/1349], Loss: 0.0439\n",
            "Epoch [2/3], Step [126/1349], Loss: 0.1446\n",
            "Epoch [2/3], Step [127/1349], Loss: 0.0972\n",
            "Epoch [2/3], Step [128/1349], Loss: 0.0403\n",
            "Epoch [2/3], Step [129/1349], Loss: 0.1455\n",
            "Epoch [2/3], Step [130/1349], Loss: 0.1272\n",
            "Epoch [2/3], Step [131/1349], Loss: 0.1197\n",
            "Epoch [2/3], Step [132/1349], Loss: 0.1483\n",
            "Epoch [2/3], Step [133/1349], Loss: 0.0379\n",
            "Epoch [2/3], Step [134/1349], Loss: 0.1038\n",
            "Epoch [2/3], Step [135/1349], Loss: 0.1032\n",
            "Epoch [2/3], Step [136/1349], Loss: 0.0489\n",
            "Epoch [2/3], Step [137/1349], Loss: 0.1239\n",
            "Epoch [2/3], Step [138/1349], Loss: 0.1504\n",
            "Epoch [2/3], Step [139/1349], Loss: 0.0704\n",
            "Epoch [2/3], Step [140/1349], Loss: 0.1167\n",
            "Epoch [2/3], Step [141/1349], Loss: 0.1768\n",
            "Epoch [2/3], Step [142/1349], Loss: 0.0756\n",
            "Epoch [2/3], Step [143/1349], Loss: 0.1264\n",
            "Epoch [2/3], Step [144/1349], Loss: 0.0571\n",
            "Epoch [2/3], Step [145/1349], Loss: 0.0620\n",
            "Epoch [2/3], Step [146/1349], Loss: 0.0436\n",
            "Epoch [2/3], Step [147/1349], Loss: 0.0176\n",
            "Epoch [2/3], Step [148/1349], Loss: 0.1051\n",
            "Epoch [2/3], Step [149/1349], Loss: 0.0863\n",
            "Epoch [2/3], Step [150/1349], Loss: 0.0281\n",
            "Epoch [2/3], Step [151/1349], Loss: 0.0513\n",
            "Epoch [2/3], Step [152/1349], Loss: 0.0494\n",
            "Epoch [2/3], Step [153/1349], Loss: 0.2262\n",
            "Epoch [2/3], Step [154/1349], Loss: 0.1498\n",
            "Epoch [2/3], Step [155/1349], Loss: 0.0590\n",
            "Epoch [2/3], Step [156/1349], Loss: 0.0941\n",
            "Epoch [2/3], Step [157/1349], Loss: 0.0617\n",
            "Epoch [2/3], Step [158/1349], Loss: 0.1067\n",
            "Epoch [2/3], Step [159/1349], Loss: 0.0523\n",
            "Epoch [2/3], Step [160/1349], Loss: 0.1425\n",
            "Epoch [2/3], Step [161/1349], Loss: 0.0987\n",
            "Epoch [2/3], Step [162/1349], Loss: 0.2028\n",
            "Epoch [2/3], Step [163/1349], Loss: 0.1244\n",
            "Epoch [2/3], Step [164/1349], Loss: 0.1933\n",
            "Epoch [2/3], Step [165/1349], Loss: 0.1383\n",
            "Epoch [2/3], Step [166/1349], Loss: 0.1603\n",
            "Epoch [2/3], Step [167/1349], Loss: 0.0399\n",
            "Epoch [2/3], Step [168/1349], Loss: 0.0262\n",
            "Epoch [2/3], Step [169/1349], Loss: 0.0658\n",
            "Epoch [2/3], Step [170/1349], Loss: 0.1689\n",
            "Epoch [2/3], Step [171/1349], Loss: 0.0641\n",
            "Epoch [2/3], Step [172/1349], Loss: 0.1670\n",
            "Epoch [2/3], Step [173/1349], Loss: 0.1209\n",
            "Epoch [2/3], Step [174/1349], Loss: 0.1146\n",
            "Epoch [2/3], Step [175/1349], Loss: 0.0071\n",
            "Epoch [2/3], Step [176/1349], Loss: 0.0721\n",
            "Epoch [2/3], Step [177/1349], Loss: 0.0651\n",
            "Epoch [2/3], Step [178/1349], Loss: 0.1180\n",
            "Epoch [2/3], Step [179/1349], Loss: 0.1052\n",
            "Epoch [2/3], Step [180/1349], Loss: 0.0560\n",
            "Epoch [2/3], Step [181/1349], Loss: 0.0842\n",
            "Epoch [2/3], Step [182/1349], Loss: 0.0792\n",
            "Epoch [2/3], Step [183/1349], Loss: 0.2371\n",
            "Epoch [2/3], Step [184/1349], Loss: 0.0480\n",
            "Epoch [2/3], Step [185/1349], Loss: 0.0553\n",
            "Epoch [2/3], Step [186/1349], Loss: 0.0523\n",
            "Epoch [2/3], Step [187/1349], Loss: 0.2066\n",
            "Epoch [2/3], Step [188/1349], Loss: 0.0528\n",
            "Epoch [2/3], Step [189/1349], Loss: 0.0255\n",
            "Epoch [2/3], Step [190/1349], Loss: 0.0915\n",
            "Epoch [2/3], Step [191/1349], Loss: 0.1054\n",
            "Epoch [2/3], Step [192/1349], Loss: 0.1332\n",
            "Epoch [2/3], Step [193/1349], Loss: 0.1209\n",
            "Epoch [2/3], Step [194/1349], Loss: 0.2336\n",
            "Epoch [2/3], Step [195/1349], Loss: 0.0126\n",
            "Epoch [2/3], Step [196/1349], Loss: 0.1973\n",
            "Epoch [2/3], Step [197/1349], Loss: 0.0329\n",
            "Epoch [2/3], Step [198/1349], Loss: 0.0641\n",
            "Epoch [2/3], Step [199/1349], Loss: 0.1493\n",
            "Epoch [2/3], Step [200/1349], Loss: 0.2054\n",
            "Epoch [2/3], Step [201/1349], Loss: 0.1496\n",
            "Epoch [2/3], Step [202/1349], Loss: 0.1063\n",
            "Epoch [2/3], Step [203/1349], Loss: 0.0801\n",
            "Epoch [2/3], Step [204/1349], Loss: 0.1352\n",
            "Epoch [2/3], Step [205/1349], Loss: 0.1577\n",
            "Epoch [2/3], Step [206/1349], Loss: 0.0258\n",
            "Epoch [2/3], Step [207/1349], Loss: 0.0401\n",
            "Epoch [2/3], Step [208/1349], Loss: 0.1330\n",
            "Epoch [2/3], Step [209/1349], Loss: 0.0395\n",
            "Epoch [2/3], Step [210/1349], Loss: 0.0920\n",
            "Epoch [2/3], Step [211/1349], Loss: 0.0574\n",
            "Epoch [2/3], Step [212/1349], Loss: 0.0245\n",
            "Epoch [2/3], Step [213/1349], Loss: 0.0328\n",
            "Epoch [2/3], Step [214/1349], Loss: 0.0283\n",
            "Epoch [2/3], Step [215/1349], Loss: 0.0638\n",
            "Epoch [2/3], Step [216/1349], Loss: 0.1143\n",
            "Epoch [2/3], Step [217/1349], Loss: 0.0882\n",
            "Epoch [2/3], Step [218/1349], Loss: 0.1591\n",
            "Epoch [2/3], Step [219/1349], Loss: 0.0991\n",
            "Epoch [2/3], Step [220/1349], Loss: 0.1552\n",
            "Epoch [2/3], Step [221/1349], Loss: 0.1019\n",
            "Epoch [2/3], Step [222/1349], Loss: 0.1729\n",
            "Epoch [2/3], Step [223/1349], Loss: 0.0639\n",
            "Epoch [2/3], Step [224/1349], Loss: 0.0131\n",
            "Epoch [2/3], Step [225/1349], Loss: 0.0561\n",
            "Epoch [2/3], Step [226/1349], Loss: 0.0622\n",
            "Epoch [2/3], Step [227/1349], Loss: 0.1264\n",
            "Epoch [2/3], Step [228/1349], Loss: 0.0515\n",
            "Epoch [2/3], Step [229/1349], Loss: 0.2478\n",
            "Epoch [2/3], Step [230/1349], Loss: 0.0959\n",
            "Epoch [2/3], Step [231/1349], Loss: 0.1235\n",
            "Epoch [2/3], Step [232/1349], Loss: 0.2191\n",
            "Epoch [2/3], Step [233/1349], Loss: 0.0630\n",
            "Epoch [2/3], Step [234/1349], Loss: 0.1732\n",
            "Epoch [2/3], Step [235/1349], Loss: 0.1815\n",
            "Epoch [2/3], Step [236/1349], Loss: 0.0362\n",
            "Epoch [2/3], Step [237/1349], Loss: 0.2389\n",
            "Epoch [2/3], Step [238/1349], Loss: 0.0350\n",
            "Epoch [2/3], Step [239/1349], Loss: 0.0389\n",
            "Epoch [2/3], Step [240/1349], Loss: 0.0888\n",
            "Epoch [2/3], Step [241/1349], Loss: 0.1962\n",
            "Epoch [2/3], Step [242/1349], Loss: 0.1245\n",
            "Epoch [2/3], Step [243/1349], Loss: 0.0820\n",
            "Epoch [2/3], Step [244/1349], Loss: 0.0873\n",
            "Epoch [2/3], Step [245/1349], Loss: 0.0663\n",
            "Epoch [2/3], Step [246/1349], Loss: 0.0192\n",
            "Epoch [2/3], Step [247/1349], Loss: 0.0147\n",
            "Epoch [2/3], Step [248/1349], Loss: 0.0829\n",
            "Epoch [2/3], Step [249/1349], Loss: 0.0643\n",
            "Epoch [2/3], Step [250/1349], Loss: 0.0111\n",
            "Epoch [2/3], Step [251/1349], Loss: 0.1653\n",
            "Epoch [2/3], Step [252/1349], Loss: 0.0815\n",
            "Epoch [2/3], Step [253/1349], Loss: 0.0663\n",
            "Epoch [2/3], Step [254/1349], Loss: 0.0789\n",
            "Epoch [2/3], Step [255/1349], Loss: 0.0195\n",
            "Epoch [2/3], Step [256/1349], Loss: 0.1906\n",
            "Epoch [2/3], Step [257/1349], Loss: 0.0724\n",
            "Epoch [2/3], Step [258/1349], Loss: 0.0653\n",
            "Epoch [2/3], Step [259/1349], Loss: 0.0577\n",
            "Epoch [2/3], Step [260/1349], Loss: 0.0043\n",
            "Epoch [2/3], Step [261/1349], Loss: 0.0417\n",
            "Epoch [2/3], Step [262/1349], Loss: 0.0531\n",
            "Epoch [2/3], Step [263/1349], Loss: 0.0397\n",
            "Epoch [2/3], Step [264/1349], Loss: 0.0582\n",
            "Epoch [2/3], Step [265/1349], Loss: 0.0329\n",
            "Epoch [2/3], Step [266/1349], Loss: 0.0611\n",
            "Epoch [2/3], Step [267/1349], Loss: 0.0472\n",
            "Epoch [2/3], Step [268/1349], Loss: 0.1632\n",
            "Epoch [2/3], Step [269/1349], Loss: 0.0047\n",
            "Epoch [2/3], Step [270/1349], Loss: 0.0070\n",
            "Epoch [2/3], Step [271/1349], Loss: 0.0670\n",
            "Epoch [2/3], Step [272/1349], Loss: 0.1044\n",
            "Epoch [2/3], Step [273/1349], Loss: 0.0182\n",
            "Epoch [2/3], Step [274/1349], Loss: 0.0623\n",
            "Epoch [2/3], Step [275/1349], Loss: 0.2110\n",
            "Epoch [2/3], Step [276/1349], Loss: 0.1061\n",
            "Epoch [2/3], Step [277/1349], Loss: 0.1142\n",
            "Epoch [2/3], Step [278/1349], Loss: 0.1372\n",
            "Epoch [2/3], Step [279/1349], Loss: 0.1226\n",
            "Epoch [2/3], Step [280/1349], Loss: 0.0363\n",
            "Epoch [2/3], Step [281/1349], Loss: 0.0668\n",
            "Epoch [2/3], Step [282/1349], Loss: 0.0468\n",
            "Epoch [2/3], Step [283/1349], Loss: 0.0412\n",
            "Epoch [2/3], Step [284/1349], Loss: 0.1119\n",
            "Epoch [2/3], Step [285/1349], Loss: 0.0334\n",
            "Epoch [2/3], Step [286/1349], Loss: 0.0440\n",
            "Epoch [2/3], Step [287/1349], Loss: 0.2110\n",
            "Epoch [2/3], Step [288/1349], Loss: 0.0137\n",
            "Epoch [2/3], Step [289/1349], Loss: 0.0204\n",
            "Epoch [2/3], Step [290/1349], Loss: 0.0233\n",
            "Epoch [2/3], Step [291/1349], Loss: 0.2311\n",
            "Epoch [2/3], Step [292/1349], Loss: 0.1398\n",
            "Epoch [2/3], Step [293/1349], Loss: 0.1013\n",
            "Epoch [2/3], Step [294/1349], Loss: 0.0811\n",
            "Epoch [2/3], Step [295/1349], Loss: 0.0114\n",
            "Epoch [2/3], Step [296/1349], Loss: 0.1728\n",
            "Epoch [2/3], Step [297/1349], Loss: 0.1179\n",
            "Epoch [2/3], Step [298/1349], Loss: 0.0201\n",
            "Epoch [2/3], Step [299/1349], Loss: 0.2457\n",
            "Epoch [2/3], Step [300/1349], Loss: 0.0450\n",
            "Epoch [2/3], Step [301/1349], Loss: 0.1957\n",
            "Epoch [2/3], Step [302/1349], Loss: 0.0477\n",
            "Epoch [2/3], Step [303/1349], Loss: 0.0822\n",
            "Epoch [2/3], Step [304/1349], Loss: 0.0712\n",
            "Epoch [2/3], Step [305/1349], Loss: 0.0408\n",
            "Epoch [2/3], Step [306/1349], Loss: 0.1384\n",
            "Epoch [2/3], Step [307/1349], Loss: 0.2250\n",
            "Epoch [2/3], Step [308/1349], Loss: 0.0732\n",
            "Epoch [2/3], Step [309/1349], Loss: 0.0074\n",
            "Epoch [2/3], Step [310/1349], Loss: 0.0384\n",
            "Epoch [2/3], Step [311/1349], Loss: 0.0376\n",
            "Epoch [2/3], Step [312/1349], Loss: 0.1647\n",
            "Epoch [2/3], Step [313/1349], Loss: 0.1396\n",
            "Epoch [2/3], Step [314/1349], Loss: 0.0378\n",
            "Epoch [2/3], Step [315/1349], Loss: 0.0790\n",
            "Epoch [2/3], Step [316/1349], Loss: 0.2092\n",
            "Epoch [2/3], Step [317/1349], Loss: 0.0399\n",
            "Epoch [2/3], Step [318/1349], Loss: 0.0473\n",
            "Epoch [2/3], Step [319/1349], Loss: 0.0057\n",
            "Epoch [2/3], Step [320/1349], Loss: 0.1369\n",
            "Epoch [2/3], Step [321/1349], Loss: 0.2453\n",
            "Epoch [2/3], Step [322/1349], Loss: 0.0834\n",
            "Epoch [2/3], Step [323/1349], Loss: 0.0788\n",
            "Epoch [2/3], Step [324/1349], Loss: 0.1324\n",
            "Epoch [2/3], Step [325/1349], Loss: 0.0260\n",
            "Epoch [2/3], Step [326/1349], Loss: 0.0539\n",
            "Epoch [2/3], Step [327/1349], Loss: 0.1437\n",
            "Epoch [2/3], Step [328/1349], Loss: 0.0130\n",
            "Epoch [2/3], Step [329/1349], Loss: 0.1529\n",
            "Epoch [2/3], Step [330/1349], Loss: 0.1446\n",
            "Epoch [2/3], Step [331/1349], Loss: 0.0781\n",
            "Epoch [2/3], Step [332/1349], Loss: 0.1950\n",
            "Epoch [2/3], Step [333/1349], Loss: 0.0106\n",
            "Epoch [2/3], Step [334/1349], Loss: 0.0734\n",
            "Epoch [2/3], Step [335/1349], Loss: 0.0869\n",
            "Epoch [2/3], Step [336/1349], Loss: 0.0225\n",
            "Epoch [2/3], Step [337/1349], Loss: 0.0889\n",
            "Epoch [2/3], Step [338/1349], Loss: 0.0415\n",
            "Epoch [2/3], Step [339/1349], Loss: 0.0510\n",
            "Epoch [2/3], Step [340/1349], Loss: 0.1264\n",
            "Epoch [2/3], Step [341/1349], Loss: 0.0939\n",
            "Epoch [2/3], Step [342/1349], Loss: 0.0261\n",
            "Epoch [2/3], Step [343/1349], Loss: 0.0180\n",
            "Epoch [2/3], Step [344/1349], Loss: 0.1675\n",
            "Epoch [2/3], Step [345/1349], Loss: 0.0276\n",
            "Epoch [2/3], Step [346/1349], Loss: 0.0367\n",
            "Epoch [2/3], Step [347/1349], Loss: 0.0395\n",
            "Epoch [2/3], Step [348/1349], Loss: 0.1250\n",
            "Epoch [2/3], Step [349/1349], Loss: 0.0662\n",
            "Epoch [2/3], Step [350/1349], Loss: 0.0855\n",
            "Epoch [2/3], Step [351/1349], Loss: 0.0280\n",
            "Epoch [2/3], Step [352/1349], Loss: 0.0391\n",
            "Epoch [2/3], Step [353/1349], Loss: 0.0364\n",
            "Epoch [2/3], Step [354/1349], Loss: 0.1599\n",
            "Epoch [2/3], Step [355/1349], Loss: 0.2008\n",
            "Epoch [2/3], Step [356/1349], Loss: 0.0913\n",
            "Epoch [2/3], Step [357/1349], Loss: 0.0460\n",
            "Epoch [2/3], Step [358/1349], Loss: 0.1377\n",
            "Epoch [2/3], Step [359/1349], Loss: 0.0732\n",
            "Epoch [2/3], Step [360/1349], Loss: 0.0116\n",
            "Epoch [2/3], Step [361/1349], Loss: 0.0930\n",
            "Epoch [2/3], Step [362/1349], Loss: 0.2401\n",
            "Epoch [2/3], Step [363/1349], Loss: 0.0334\n",
            "Epoch [2/3], Step [364/1349], Loss: 0.0269\n",
            "Epoch [2/3], Step [365/1349], Loss: 0.0477\n",
            "Epoch [2/3], Step [366/1349], Loss: 0.0350\n",
            "Epoch [2/3], Step [367/1349], Loss: 0.1615\n",
            "Epoch [2/3], Step [368/1349], Loss: 0.1790\n",
            "Epoch [2/3], Step [369/1349], Loss: 0.1004\n",
            "Epoch [2/3], Step [370/1349], Loss: 0.1375\n",
            "Epoch [2/3], Step [371/1349], Loss: 0.0906\n",
            "Epoch [2/3], Step [372/1349], Loss: 0.0271\n",
            "Epoch [2/3], Step [373/1349], Loss: 0.0131\n",
            "Epoch [2/3], Step [374/1349], Loss: 0.2810\n",
            "Epoch [2/3], Step [375/1349], Loss: 0.0288\n",
            "Epoch [2/3], Step [376/1349], Loss: 0.2501\n",
            "Epoch [2/3], Step [377/1349], Loss: 0.1513\n",
            "Epoch [2/3], Step [378/1349], Loss: 0.2618\n",
            "Epoch [2/3], Step [379/1349], Loss: 0.0684\n",
            "Epoch [2/3], Step [380/1349], Loss: 0.0740\n",
            "Epoch [2/3], Step [381/1349], Loss: 0.1409\n",
            "Epoch [2/3], Step [382/1349], Loss: 0.1215\n",
            "Epoch [2/3], Step [383/1349], Loss: 0.1221\n",
            "Epoch [2/3], Step [384/1349], Loss: 0.0541\n",
            "Epoch [2/3], Step [385/1349], Loss: 0.0339\n",
            "Epoch [2/3], Step [386/1349], Loss: 0.1876\n",
            "Epoch [2/3], Step [387/1349], Loss: 0.0388\n",
            "Epoch [2/3], Step [388/1349], Loss: 0.0504\n",
            "Epoch [2/3], Step [389/1349], Loss: 0.1107\n",
            "Epoch [2/3], Step [390/1349], Loss: 0.0598\n",
            "Epoch [2/3], Step [391/1349], Loss: 0.0472\n",
            "Epoch [2/3], Step [392/1349], Loss: 0.0102\n",
            "Epoch [2/3], Step [393/1349], Loss: 0.0384\n",
            "Epoch [2/3], Step [394/1349], Loss: 0.0537\n",
            "Epoch [2/3], Step [395/1349], Loss: 0.1118\n",
            "Epoch [2/3], Step [396/1349], Loss: 0.0859\n",
            "Epoch [2/3], Step [397/1349], Loss: 0.0934\n",
            "Epoch [2/3], Step [398/1349], Loss: 0.0682\n",
            "Epoch [2/3], Step [399/1349], Loss: 0.0980\n",
            "Epoch [2/3], Step [400/1349], Loss: 0.0888\n",
            "Epoch [2/3], Step [401/1349], Loss: 0.1360\n",
            "Epoch [2/3], Step [402/1349], Loss: 0.0302\n",
            "Epoch [2/3], Step [403/1349], Loss: 0.0683\n",
            "Epoch [2/3], Step [404/1349], Loss: 0.0843\n",
            "Epoch [2/3], Step [405/1349], Loss: 0.1034\n",
            "Epoch [2/3], Step [406/1349], Loss: 0.1237\n",
            "Epoch [2/3], Step [407/1349], Loss: 0.0703\n",
            "Epoch [2/3], Step [408/1349], Loss: 0.0144\n",
            "Epoch [2/3], Step [409/1349], Loss: 0.1351\n",
            "Epoch [2/3], Step [410/1349], Loss: 0.1233\n",
            "Epoch [2/3], Step [411/1349], Loss: 0.0130\n",
            "Epoch [2/3], Step [412/1349], Loss: 0.0168\n",
            "Epoch [2/3], Step [413/1349], Loss: 0.1693\n",
            "Epoch [2/3], Step [414/1349], Loss: 0.1139\n",
            "Epoch [2/3], Step [415/1349], Loss: 0.0417\n",
            "Epoch [2/3], Step [416/1349], Loss: 0.0035\n",
            "Epoch [2/3], Step [417/1349], Loss: 0.1460\n",
            "Epoch [2/3], Step [418/1349], Loss: 0.0293\n",
            "Epoch [2/3], Step [419/1349], Loss: 0.0916\n",
            "Epoch [2/3], Step [420/1349], Loss: 0.0460\n",
            "Epoch [2/3], Step [421/1349], Loss: 0.0879\n",
            "Epoch [2/3], Step [422/1349], Loss: 0.0690\n",
            "Epoch [2/3], Step [423/1349], Loss: 0.1348\n",
            "Epoch [2/3], Step [424/1349], Loss: 0.0508\n",
            "Epoch [2/3], Step [425/1349], Loss: 0.0312\n",
            "Epoch [2/3], Step [426/1349], Loss: 0.1060\n",
            "Epoch [2/3], Step [427/1349], Loss: 0.0333\n",
            "Epoch [2/3], Step [428/1349], Loss: 0.1024\n",
            "Epoch [2/3], Step [429/1349], Loss: 0.0282\n",
            "Epoch [2/3], Step [430/1349], Loss: 0.1554\n",
            "Epoch [2/3], Step [431/1349], Loss: 0.0265\n",
            "Epoch [2/3], Step [432/1349], Loss: 0.0182\n",
            "Epoch [2/3], Step [433/1349], Loss: 0.1191\n",
            "Epoch [2/3], Step [434/1349], Loss: 0.1704\n",
            "Epoch [2/3], Step [435/1349], Loss: 0.0299\n",
            "Epoch [2/3], Step [436/1349], Loss: 0.0882\n",
            "Epoch [2/3], Step [437/1349], Loss: 0.1729\n",
            "Epoch [2/3], Step [438/1349], Loss: 0.0126\n",
            "Epoch [2/3], Step [439/1349], Loss: 0.0294\n",
            "Epoch [2/3], Step [440/1349], Loss: 0.0103\n",
            "Epoch [2/3], Step [441/1349], Loss: 0.1161\n",
            "Epoch [2/3], Step [442/1349], Loss: 0.0583\n",
            "Epoch [2/3], Step [443/1349], Loss: 0.0157\n",
            "Epoch [2/3], Step [444/1349], Loss: 0.0164\n",
            "Epoch [2/3], Step [445/1349], Loss: 0.1611\n",
            "Epoch [2/3], Step [446/1349], Loss: 0.0908\n",
            "Epoch [2/3], Step [447/1349], Loss: 0.0598\n",
            "Epoch [2/3], Step [448/1349], Loss: 0.1776\n",
            "Epoch [2/3], Step [449/1349], Loss: 0.0818\n",
            "Epoch [2/3], Step [450/1349], Loss: 0.0649\n",
            "Epoch [2/3], Step [451/1349], Loss: 0.0664\n",
            "Epoch [2/3], Step [452/1349], Loss: 0.0732\n",
            "Epoch [2/3], Step [453/1349], Loss: 0.0096\n",
            "Epoch [2/3], Step [454/1349], Loss: 0.4671\n",
            "Epoch [2/3], Step [455/1349], Loss: 0.1021\n",
            "Epoch [2/3], Step [456/1349], Loss: 0.0297\n",
            "Epoch [2/3], Step [457/1349], Loss: 0.1195\n",
            "Epoch [2/3], Step [458/1349], Loss: 0.1703\n",
            "Epoch [2/3], Step [459/1349], Loss: 0.0409\n",
            "Epoch [2/3], Step [460/1349], Loss: 0.2124\n",
            "Epoch [2/3], Step [461/1349], Loss: 0.1537\n",
            "Epoch [2/3], Step [462/1349], Loss: 0.2135\n",
            "Epoch [2/3], Step [463/1349], Loss: 0.1681\n",
            "Epoch [2/3], Step [464/1349], Loss: 0.1983\n",
            "Epoch [2/3], Step [465/1349], Loss: 0.1383\n",
            "Epoch [2/3], Step [466/1349], Loss: 0.0654\n",
            "Epoch [2/3], Step [467/1349], Loss: 0.0375\n",
            "Epoch [2/3], Step [468/1349], Loss: 0.0667\n",
            "Epoch [2/3], Step [469/1349], Loss: 0.2125\n",
            "Epoch [2/3], Step [470/1349], Loss: 0.0654\n",
            "Epoch [2/3], Step [471/1349], Loss: 0.0250\n",
            "Epoch [2/3], Step [472/1349], Loss: 0.0392\n",
            "Epoch [2/3], Step [473/1349], Loss: 0.2281\n",
            "Epoch [2/3], Step [474/1349], Loss: 0.0315\n",
            "Epoch [2/3], Step [475/1349], Loss: 0.0150\n",
            "Epoch [2/3], Step [476/1349], Loss: 0.0998\n",
            "Epoch [2/3], Step [477/1349], Loss: 0.0786\n",
            "Epoch [2/3], Step [478/1349], Loss: 0.0586\n",
            "Epoch [2/3], Step [479/1349], Loss: 0.0965\n",
            "Epoch [2/3], Step [480/1349], Loss: 0.0413\n",
            "Epoch [2/3], Step [481/1349], Loss: 0.1937\n",
            "Epoch [2/3], Step [482/1349], Loss: 0.0750\n",
            "Epoch [2/3], Step [483/1349], Loss: 0.1056\n",
            "Epoch [2/3], Step [484/1349], Loss: 0.1497\n",
            "Epoch [2/3], Step [485/1349], Loss: 0.2100\n",
            "Epoch [2/3], Step [486/1349], Loss: 0.0933\n",
            "Epoch [2/3], Step [487/1349], Loss: 0.1168\n",
            "Epoch [2/3], Step [488/1349], Loss: 0.1439\n",
            "Epoch [2/3], Step [489/1349], Loss: 0.0934\n",
            "Epoch [2/3], Step [490/1349], Loss: 0.1464\n",
            "Epoch [2/3], Step [491/1349], Loss: 0.0537\n",
            "Epoch [2/3], Step [492/1349], Loss: 0.0890\n",
            "Epoch [2/3], Step [493/1349], Loss: 0.0609\n",
            "Epoch [2/3], Step [494/1349], Loss: 0.0078\n",
            "Epoch [2/3], Step [495/1349], Loss: 0.0166\n",
            "Epoch [2/3], Step [496/1349], Loss: 0.0545\n",
            "Epoch [2/3], Step [497/1349], Loss: 0.0642\n",
            "Epoch [2/3], Step [498/1349], Loss: 0.0844\n",
            "Epoch [2/3], Step [499/1349], Loss: 0.2657\n",
            "Epoch [2/3], Step [500/1349], Loss: 0.1062\n",
            "Epoch [2/3], Step [501/1349], Loss: 0.1470\n",
            "Epoch [2/3], Step [502/1349], Loss: 0.0529\n",
            "Epoch [2/3], Step [503/1349], Loss: 0.1088\n",
            "Epoch [2/3], Step [504/1349], Loss: 0.1453\n",
            "Epoch [2/3], Step [505/1349], Loss: 0.0752\n",
            "Epoch [2/3], Step [506/1349], Loss: 0.1909\n",
            "Epoch [2/3], Step [507/1349], Loss: 0.0520\n",
            "Epoch [2/3], Step [508/1349], Loss: 0.0408\n",
            "Epoch [2/3], Step [509/1349], Loss: 0.1286\n",
            "Epoch [2/3], Step [510/1349], Loss: 0.0181\n",
            "Epoch [2/3], Step [511/1349], Loss: 0.0309\n",
            "Epoch [2/3], Step [512/1349], Loss: 0.0451\n",
            "Epoch [2/3], Step [513/1349], Loss: 0.1713\n",
            "Epoch [2/3], Step [514/1349], Loss: 0.1759\n",
            "Epoch [2/3], Step [515/1349], Loss: 0.0430\n",
            "Epoch [2/3], Step [516/1349], Loss: 0.0163\n",
            "Epoch [2/3], Step [517/1349], Loss: 0.1425\n",
            "Epoch [2/3], Step [518/1349], Loss: 0.0220\n",
            "Epoch [2/3], Step [519/1349], Loss: 0.0182\n",
            "Epoch [2/3], Step [520/1349], Loss: 0.0969\n",
            "Epoch [2/3], Step [521/1349], Loss: 0.0255\n",
            "Epoch [2/3], Step [522/1349], Loss: 0.0923\n",
            "Epoch [2/3], Step [523/1349], Loss: 0.0614\n",
            "Epoch [2/3], Step [524/1349], Loss: 0.2626\n",
            "Epoch [2/3], Step [525/1349], Loss: 0.0299\n",
            "Epoch [2/3], Step [526/1349], Loss: 0.0715\n",
            "Epoch [2/3], Step [527/1349], Loss: 0.1691\n",
            "Epoch [2/3], Step [528/1349], Loss: 0.0355\n",
            "Epoch [2/3], Step [529/1349], Loss: 0.1463\n",
            "Epoch [2/3], Step [530/1349], Loss: 0.0303\n",
            "Epoch [2/3], Step [531/1349], Loss: 0.0311\n",
            "Epoch [2/3], Step [532/1349], Loss: 0.0254\n",
            "Epoch [2/3], Step [533/1349], Loss: 0.0853\n",
            "Epoch [2/3], Step [534/1349], Loss: 0.0085\n",
            "Epoch [2/3], Step [535/1349], Loss: 0.0453\n",
            "Epoch [2/3], Step [536/1349], Loss: 0.0124\n",
            "Epoch [2/3], Step [537/1349], Loss: 0.1949\n",
            "Epoch [2/3], Step [538/1349], Loss: 0.0759\n",
            "Epoch [2/3], Step [539/1349], Loss: 0.1837\n",
            "Epoch [2/3], Step [540/1349], Loss: 0.1075\n",
            "Epoch [2/3], Step [541/1349], Loss: 0.0555\n",
            "Epoch [2/3], Step [542/1349], Loss: 0.0477\n",
            "Epoch [2/3], Step [543/1349], Loss: 0.0293\n",
            "Epoch [2/3], Step [544/1349], Loss: 0.0306\n",
            "Epoch [2/3], Step [545/1349], Loss: 0.2114\n",
            "Epoch [2/3], Step [546/1349], Loss: 0.0905\n",
            "Epoch [2/3], Step [547/1349], Loss: 0.0813\n",
            "Epoch [2/3], Step [548/1349], Loss: 0.0265\n",
            "Epoch [2/3], Step [549/1349], Loss: 0.0360\n",
            "Epoch [2/3], Step [550/1349], Loss: 0.0502\n",
            "Epoch [2/3], Step [551/1349], Loss: 0.1713\n",
            "Epoch [2/3], Step [552/1349], Loss: 0.1546\n",
            "Epoch [2/3], Step [553/1349], Loss: 0.0682\n",
            "Epoch [2/3], Step [554/1349], Loss: 0.0699\n",
            "Epoch [2/3], Step [555/1349], Loss: 0.0896\n",
            "Epoch [2/3], Step [556/1349], Loss: 0.0880\n",
            "Epoch [2/3], Step [557/1349], Loss: 0.0280\n",
            "Epoch [2/3], Step [558/1349], Loss: 0.0805\n",
            "Epoch [2/3], Step [559/1349], Loss: 0.0459\n",
            "Epoch [2/3], Step [560/1349], Loss: 0.0922\n",
            "Epoch [2/3], Step [561/1349], Loss: 0.1235\n",
            "Epoch [2/3], Step [562/1349], Loss: 0.0408\n",
            "Epoch [2/3], Step [563/1349], Loss: 0.0555\n",
            "Epoch [2/3], Step [564/1349], Loss: 0.1461\n",
            "Epoch [2/3], Step [565/1349], Loss: 0.1063\n",
            "Epoch [2/3], Step [566/1349], Loss: 0.0531\n",
            "Epoch [2/3], Step [567/1349], Loss: 0.0596\n",
            "Epoch [2/3], Step [568/1349], Loss: 0.0842\n",
            "Epoch [2/3], Step [569/1349], Loss: 0.0897\n",
            "Epoch [2/3], Step [570/1349], Loss: 0.1612\n",
            "Epoch [2/3], Step [571/1349], Loss: 0.2098\n",
            "Epoch [2/3], Step [572/1349], Loss: 0.2145\n",
            "Epoch [2/3], Step [573/1349], Loss: 0.1750\n",
            "Epoch [2/3], Step [574/1349], Loss: 0.1082\n",
            "Epoch [2/3], Step [575/1349], Loss: 0.0358\n",
            "Epoch [2/3], Step [576/1349], Loss: 0.0204\n",
            "Epoch [2/3], Step [577/1349], Loss: 0.0655\n",
            "Epoch [2/3], Step [578/1349], Loss: 0.0973\n",
            "Epoch [2/3], Step [579/1349], Loss: 0.0771\n",
            "Epoch [2/3], Step [580/1349], Loss: 0.0383\n",
            "Epoch [2/3], Step [581/1349], Loss: 0.0186\n",
            "Epoch [2/3], Step [582/1349], Loss: 0.0900\n",
            "Epoch [2/3], Step [583/1349], Loss: 0.0679\n",
            "Epoch [2/3], Step [584/1349], Loss: 0.0549\n",
            "Epoch [2/3], Step [585/1349], Loss: 0.2959\n",
            "Epoch [2/3], Step [586/1349], Loss: 0.0196\n",
            "Epoch [2/3], Step [587/1349], Loss: 0.2406\n",
            "Epoch [2/3], Step [588/1349], Loss: 0.0319\n",
            "Epoch [2/3], Step [589/1349], Loss: 0.0630\n",
            "Epoch [2/3], Step [590/1349], Loss: 0.1729\n",
            "Epoch [2/3], Step [591/1349], Loss: 0.1027\n",
            "Epoch [2/3], Step [592/1349], Loss: 0.0497\n",
            "Epoch [2/3], Step [593/1349], Loss: 0.0908\n",
            "Epoch [2/3], Step [594/1349], Loss: 0.0160\n",
            "Epoch [2/3], Step [595/1349], Loss: 0.0356\n",
            "Epoch [2/3], Step [596/1349], Loss: 0.1381\n",
            "Epoch [2/3], Step [597/1349], Loss: 0.0934\n",
            "Epoch [2/3], Step [598/1349], Loss: 0.0524\n",
            "Epoch [2/3], Step [599/1349], Loss: 0.1203\n",
            "Epoch [2/3], Step [600/1349], Loss: 0.0123\n",
            "Epoch [2/3], Step [601/1349], Loss: 0.0678\n",
            "Epoch [2/3], Step [602/1349], Loss: 0.0426\n",
            "Epoch [2/3], Step [603/1349], Loss: 0.3051\n",
            "Epoch [2/3], Step [604/1349], Loss: 0.0634\n",
            "Epoch [2/3], Step [605/1349], Loss: 0.0096\n",
            "Epoch [2/3], Step [606/1349], Loss: 0.0436\n",
            "Epoch [2/3], Step [607/1349], Loss: 0.0677\n",
            "Epoch [2/3], Step [608/1349], Loss: 0.0313\n",
            "Epoch [2/3], Step [609/1349], Loss: 0.1244\n",
            "Epoch [2/3], Step [610/1349], Loss: 0.1003\n",
            "Epoch [2/3], Step [611/1349], Loss: 0.0634\n",
            "Epoch [2/3], Step [612/1349], Loss: 0.2189\n",
            "Epoch [2/3], Step [613/1349], Loss: 0.0169\n",
            "Epoch [2/3], Step [614/1349], Loss: 0.1868\n",
            "Epoch [2/3], Step [615/1349], Loss: 0.0615\n",
            "Epoch [2/3], Step [616/1349], Loss: 0.1280\n",
            "Epoch [2/3], Step [617/1349], Loss: 0.0261\n",
            "Epoch [2/3], Step [618/1349], Loss: 0.1006\n",
            "Epoch [2/3], Step [619/1349], Loss: 0.1686\n",
            "Epoch [2/3], Step [620/1349], Loss: 0.1642\n",
            "Epoch [2/3], Step [621/1349], Loss: 0.0560\n",
            "Epoch [2/3], Step [622/1349], Loss: 0.2032\n",
            "Epoch [2/3], Step [623/1349], Loss: 0.0817\n",
            "Epoch [2/3], Step [624/1349], Loss: 0.1157\n",
            "Epoch [2/3], Step [625/1349], Loss: 0.1552\n",
            "Epoch [2/3], Step [626/1349], Loss: 0.0419\n",
            "Epoch [2/3], Step [627/1349], Loss: 0.1704\n",
            "Epoch [2/3], Step [628/1349], Loss: 0.0194\n",
            "Epoch [2/3], Step [629/1349], Loss: 0.1603\n",
            "Epoch [2/3], Step [630/1349], Loss: 0.0742\n",
            "Epoch [2/3], Step [631/1349], Loss: 0.0472\n",
            "Epoch [2/3], Step [632/1349], Loss: 0.0349\n",
            "Epoch [2/3], Step [633/1349], Loss: 0.0325\n",
            "Epoch [2/3], Step [634/1349], Loss: 0.0701\n",
            "Epoch [2/3], Step [635/1349], Loss: 0.2614\n",
            "Epoch [2/3], Step [636/1349], Loss: 0.0057\n",
            "Epoch [2/3], Step [637/1349], Loss: 0.1119\n",
            "Epoch [2/3], Step [638/1349], Loss: 0.1685\n",
            "Epoch [2/3], Step [639/1349], Loss: 0.0812\n",
            "Epoch [2/3], Step [640/1349], Loss: 0.1799\n",
            "Epoch [2/3], Step [641/1349], Loss: 0.1157\n",
            "Epoch [2/3], Step [642/1349], Loss: 0.0146\n",
            "Epoch [2/3], Step [643/1349], Loss: 0.0755\n",
            "Epoch [2/3], Step [644/1349], Loss: 0.1206\n",
            "Epoch [2/3], Step [645/1349], Loss: 0.0185\n",
            "Epoch [2/3], Step [646/1349], Loss: 0.0244\n",
            "Epoch [2/3], Step [647/1349], Loss: 0.1900\n",
            "Epoch [2/3], Step [648/1349], Loss: 0.1484\n",
            "Epoch [2/3], Step [649/1349], Loss: 0.0209\n",
            "Epoch [2/3], Step [650/1349], Loss: 0.0531\n",
            "Epoch [2/3], Step [651/1349], Loss: 0.0373\n",
            "Epoch [2/3], Step [652/1349], Loss: 0.0748\n",
            "Epoch [2/3], Step [653/1349], Loss: 0.0703\n",
            "Epoch [2/3], Step [654/1349], Loss: 0.0751\n",
            "Epoch [2/3], Step [655/1349], Loss: 0.0587\n",
            "Epoch [2/3], Step [656/1349], Loss: 0.3453\n",
            "Epoch [2/3], Step [657/1349], Loss: 0.1587\n",
            "Epoch [2/3], Step [658/1349], Loss: 0.0327\n",
            "Epoch [2/3], Step [659/1349], Loss: 0.0193\n",
            "Epoch [2/3], Step [660/1349], Loss: 0.0300\n",
            "Epoch [2/3], Step [661/1349], Loss: 0.0367\n",
            "Epoch [2/3], Step [662/1349], Loss: 0.0266\n",
            "Epoch [2/3], Step [663/1349], Loss: 0.1832\n",
            "Epoch [2/3], Step [664/1349], Loss: 0.1285\n",
            "Epoch [2/3], Step [665/1349], Loss: 0.2317\n",
            "Epoch [2/3], Step [666/1349], Loss: 0.0600\n",
            "Epoch [2/3], Step [667/1349], Loss: 0.0567\n",
            "Epoch [2/3], Step [668/1349], Loss: 0.0448\n",
            "Epoch [2/3], Step [669/1349], Loss: 0.0708\n",
            "Epoch [2/3], Step [670/1349], Loss: 0.0386\n",
            "Epoch [2/3], Step [671/1349], Loss: 0.2361\n",
            "Epoch [2/3], Step [672/1349], Loss: 0.0247\n",
            "Epoch [2/3], Step [673/1349], Loss: 0.1024\n",
            "Epoch [2/3], Step [674/1349], Loss: 0.1542\n",
            "Epoch [2/3], Step [675/1349], Loss: 0.0572\n",
            "Epoch [2/3], Step [676/1349], Loss: 0.1046\n",
            "Epoch [2/3], Step [677/1349], Loss: 0.2133\n",
            "Epoch [2/3], Step [678/1349], Loss: 0.0770\n",
            "Epoch [2/3], Step [679/1349], Loss: 0.0286\n",
            "Epoch [2/3], Step [680/1349], Loss: 0.0290\n",
            "Epoch [2/3], Step [681/1349], Loss: 0.0841\n",
            "Epoch [2/3], Step [682/1349], Loss: 0.0856\n",
            "Epoch [2/3], Step [683/1349], Loss: 0.0178\n",
            "Epoch [2/3], Step [684/1349], Loss: 0.0323\n",
            "Epoch [2/3], Step [685/1349], Loss: 0.0979\n",
            "Epoch [2/3], Step [686/1349], Loss: 0.0763\n",
            "Epoch [2/3], Step [687/1349], Loss: 0.1005\n",
            "Epoch [2/3], Step [688/1349], Loss: 0.0796\n",
            "Epoch [2/3], Step [689/1349], Loss: 0.0535\n",
            "Epoch [2/3], Step [690/1349], Loss: 0.0787\n",
            "Epoch [2/3], Step [691/1349], Loss: 0.0056\n",
            "Epoch [2/3], Step [692/1349], Loss: 0.0688\n",
            "Epoch [2/3], Step [693/1349], Loss: 0.2166\n",
            "Epoch [2/3], Step [694/1349], Loss: 0.0231\n",
            "Epoch [2/3], Step [695/1349], Loss: 0.0382\n",
            "Epoch [2/3], Step [696/1349], Loss: 0.0370\n",
            "Epoch [2/3], Step [697/1349], Loss: 0.1707\n",
            "Epoch [2/3], Step [698/1349], Loss: 0.0680\n",
            "Epoch [2/3], Step [699/1349], Loss: 0.0652\n",
            "Epoch [2/3], Step [700/1349], Loss: 0.1924\n",
            "Epoch [2/3], Step [701/1349], Loss: 0.0470\n",
            "Epoch [2/3], Step [702/1349], Loss: 0.0574\n",
            "Epoch [2/3], Step [703/1349], Loss: 0.0510\n",
            "Epoch [2/3], Step [704/1349], Loss: 0.0251\n",
            "Epoch [2/3], Step [705/1349], Loss: 0.0126\n",
            "Epoch [2/3], Step [706/1349], Loss: 0.1009\n",
            "Epoch [2/3], Step [707/1349], Loss: 0.0143\n",
            "Epoch [2/3], Step [708/1349], Loss: 0.0047\n",
            "Epoch [2/3], Step [709/1349], Loss: 0.0532\n",
            "Epoch [2/3], Step [710/1349], Loss: 0.1183\n",
            "Epoch [2/3], Step [711/1349], Loss: 0.1221\n",
            "Epoch [2/3], Step [712/1349], Loss: 0.0251\n",
            "Epoch [2/3], Step [713/1349], Loss: 0.0557\n",
            "Epoch [2/3], Step [714/1349], Loss: 0.0606\n",
            "Epoch [2/3], Step [715/1349], Loss: 0.1322\n",
            "Epoch [2/3], Step [716/1349], Loss: 0.0282\n",
            "Epoch [2/3], Step [717/1349], Loss: 0.1902\n",
            "Epoch [2/3], Step [718/1349], Loss: 0.0511\n",
            "Epoch [2/3], Step [719/1349], Loss: 0.1857\n",
            "Epoch [2/3], Step [720/1349], Loss: 0.0428\n",
            "Epoch [2/3], Step [721/1349], Loss: 0.1572\n",
            "Epoch [2/3], Step [722/1349], Loss: 0.0270\n",
            "Epoch [2/3], Step [723/1349], Loss: 0.0888\n",
            "Epoch [2/3], Step [724/1349], Loss: 0.1176\n",
            "Epoch [2/3], Step [725/1349], Loss: 0.0168\n",
            "Epoch [2/3], Step [726/1349], Loss: 0.0456\n",
            "Epoch [2/3], Step [727/1349], Loss: 0.0017\n",
            "Epoch [2/3], Step [728/1349], Loss: 0.2265\n",
            "Epoch [2/3], Step [729/1349], Loss: 0.0581\n",
            "Epoch [2/3], Step [730/1349], Loss: 0.0865\n",
            "Epoch [2/3], Step [731/1349], Loss: 0.0993\n",
            "Epoch [2/3], Step [732/1349], Loss: 0.0349\n",
            "Epoch [2/3], Step [733/1349], Loss: 0.1421\n",
            "Epoch [2/3], Step [734/1349], Loss: 0.0859\n",
            "Epoch [2/3], Step [735/1349], Loss: 0.0913\n",
            "Epoch [2/3], Step [736/1349], Loss: 0.0327\n",
            "Epoch [2/3], Step [737/1349], Loss: 0.1314\n",
            "Epoch [2/3], Step [738/1349], Loss: 0.0682\n",
            "Epoch [2/3], Step [739/1349], Loss: 0.0581\n",
            "Epoch [2/3], Step [740/1349], Loss: 0.1041\n",
            "Epoch [2/3], Step [741/1349], Loss: 0.0795\n",
            "Epoch [2/3], Step [742/1349], Loss: 0.2168\n",
            "Epoch [2/3], Step [743/1349], Loss: 0.0150\n",
            "Epoch [2/3], Step [744/1349], Loss: 0.1246\n",
            "Epoch [2/3], Step [745/1349], Loss: 0.1238\n",
            "Epoch [2/3], Step [746/1349], Loss: 0.1347\n",
            "Epoch [2/3], Step [747/1349], Loss: 0.0521\n",
            "Epoch [2/3], Step [748/1349], Loss: 0.0088\n",
            "Epoch [2/3], Step [749/1349], Loss: 0.0540\n",
            "Epoch [2/3], Step [750/1349], Loss: 0.1228\n",
            "Epoch [2/3], Step [751/1349], Loss: 0.1946\n",
            "Epoch [2/3], Step [752/1349], Loss: 0.2340\n",
            "Epoch [2/3], Step [753/1349], Loss: 0.0664\n",
            "Epoch [2/3], Step [754/1349], Loss: 0.0485\n",
            "Epoch [2/3], Step [755/1349], Loss: 0.1086\n",
            "Epoch [2/3], Step [756/1349], Loss: 0.2062\n",
            "Epoch [2/3], Step [757/1349], Loss: 0.1702\n",
            "Epoch [2/3], Step [758/1349], Loss: 0.0181\n",
            "Epoch [2/3], Step [759/1349], Loss: 0.0534\n",
            "Epoch [2/3], Step [760/1349], Loss: 0.0258\n",
            "Epoch [2/3], Step [761/1349], Loss: 0.1500\n",
            "Epoch [2/3], Step [762/1349], Loss: 0.0749\n",
            "Epoch [2/3], Step [763/1349], Loss: 0.1103\n",
            "Epoch [2/3], Step [764/1349], Loss: 0.0745\n",
            "Epoch [2/3], Step [765/1349], Loss: 0.0161\n",
            "Epoch [2/3], Step [766/1349], Loss: 0.1263\n",
            "Epoch [2/3], Step [767/1349], Loss: 0.1231\n",
            "Epoch [2/3], Step [768/1349], Loss: 0.0543\n",
            "Epoch [2/3], Step [769/1349], Loss: 0.0583\n",
            "Epoch [2/3], Step [770/1349], Loss: 0.0248\n",
            "Epoch [2/3], Step [771/1349], Loss: 0.0258\n",
            "Epoch [2/3], Step [772/1349], Loss: 0.0111\n",
            "Epoch [2/3], Step [773/1349], Loss: 0.0999\n",
            "Epoch [2/3], Step [774/1349], Loss: 0.0708\n",
            "Epoch [2/3], Step [775/1349], Loss: 0.0422\n",
            "Epoch [2/3], Step [776/1349], Loss: 0.1014\n",
            "Epoch [2/3], Step [777/1349], Loss: 0.1000\n",
            "Epoch [2/3], Step [778/1349], Loss: 0.1270\n",
            "Epoch [2/3], Step [779/1349], Loss: 0.0159\n",
            "Epoch [2/3], Step [780/1349], Loss: 0.0753\n",
            "Epoch [2/3], Step [781/1349], Loss: 0.0167\n",
            "Epoch [2/3], Step [782/1349], Loss: 0.0534\n",
            "Epoch [2/3], Step [783/1349], Loss: 0.0644\n",
            "Epoch [2/3], Step [784/1349], Loss: 0.2696\n",
            "Epoch [2/3], Step [785/1349], Loss: 0.0302\n",
            "Epoch [2/3], Step [786/1349], Loss: 0.1449\n",
            "Epoch [2/3], Step [787/1349], Loss: 0.0365\n",
            "Epoch [2/3], Step [788/1349], Loss: 0.0218\n",
            "Epoch [2/3], Step [789/1349], Loss: 0.0249\n",
            "Epoch [2/3], Step [790/1349], Loss: 0.1148\n",
            "Epoch [2/3], Step [791/1349], Loss: 0.1004\n",
            "Epoch [2/3], Step [792/1349], Loss: 0.0152\n",
            "Epoch [2/3], Step [793/1349], Loss: 0.0602\n",
            "Epoch [2/3], Step [794/1349], Loss: 0.0789\n",
            "Epoch [2/3], Step [795/1349], Loss: 0.0582\n",
            "Epoch [2/3], Step [796/1349], Loss: 0.0276\n",
            "Epoch [2/3], Step [797/1349], Loss: 0.0132\n",
            "Epoch [2/3], Step [798/1349], Loss: 0.0698\n",
            "Epoch [2/3], Step [799/1349], Loss: 0.0814\n",
            "Epoch [2/3], Step [800/1349], Loss: 0.1041\n",
            "Epoch [2/3], Step [801/1349], Loss: 0.0331\n",
            "Epoch [2/3], Step [802/1349], Loss: 0.0687\n",
            "Epoch [2/3], Step [803/1349], Loss: 0.0691\n",
            "Epoch [2/3], Step [804/1349], Loss: 0.1764\n",
            "Epoch [2/3], Step [805/1349], Loss: 0.3402\n",
            "Epoch [2/3], Step [806/1349], Loss: 0.2808\n",
            "Epoch [2/3], Step [807/1349], Loss: 0.1216\n",
            "Epoch [2/3], Step [808/1349], Loss: 0.0289\n",
            "Epoch [2/3], Step [809/1349], Loss: 0.1247\n",
            "Epoch [2/3], Step [810/1349], Loss: 0.0903\n",
            "Epoch [2/3], Step [811/1349], Loss: 0.0297\n",
            "Epoch [2/3], Step [812/1349], Loss: 0.0306\n",
            "Epoch [2/3], Step [813/1349], Loss: 0.0299\n",
            "Epoch [2/3], Step [814/1349], Loss: 0.1525\n",
            "Epoch [2/3], Step [815/1349], Loss: 0.0636\n",
            "Epoch [2/3], Step [816/1349], Loss: 0.1964\n",
            "Epoch [2/3], Step [817/1349], Loss: 0.0436\n",
            "Epoch [2/3], Step [818/1349], Loss: 0.1155\n",
            "Epoch [2/3], Step [819/1349], Loss: 0.1071\n",
            "Epoch [2/3], Step [820/1349], Loss: 0.0599\n",
            "Epoch [2/3], Step [821/1349], Loss: 0.1053\n",
            "Epoch [2/3], Step [822/1349], Loss: 0.1041\n",
            "Epoch [2/3], Step [823/1349], Loss: 0.0912\n",
            "Epoch [2/3], Step [824/1349], Loss: 0.0186\n",
            "Epoch [2/3], Step [825/1349], Loss: 0.0776\n",
            "Epoch [2/3], Step [826/1349], Loss: 0.0484\n",
            "Epoch [2/3], Step [827/1349], Loss: 0.1951\n",
            "Epoch [2/3], Step [828/1349], Loss: 0.1348\n",
            "Epoch [2/3], Step [829/1349], Loss: 0.0381\n",
            "Epoch [2/3], Step [830/1349], Loss: 0.1384\n",
            "Epoch [2/3], Step [831/1349], Loss: 0.0566\n",
            "Epoch [2/3], Step [832/1349], Loss: 0.0359\n",
            "Epoch [2/3], Step [833/1349], Loss: 0.0142\n",
            "Epoch [2/3], Step [834/1349], Loss: 0.0317\n",
            "Epoch [2/3], Step [835/1349], Loss: 0.0729\n",
            "Epoch [2/3], Step [836/1349], Loss: 0.0746\n",
            "Epoch [2/3], Step [837/1349], Loss: 0.0796\n",
            "Epoch [2/3], Step [838/1349], Loss: 0.0095\n",
            "Epoch [2/3], Step [839/1349], Loss: 0.0478\n",
            "Epoch [2/3], Step [840/1349], Loss: 0.0793\n",
            "Epoch [2/3], Step [841/1349], Loss: 0.1671\n",
            "Epoch [2/3], Step [842/1349], Loss: 0.0119\n",
            "Epoch [2/3], Step [843/1349], Loss: 0.0246\n",
            "Epoch [2/3], Step [844/1349], Loss: 0.0389\n",
            "Epoch [2/3], Step [845/1349], Loss: 0.0642\n",
            "Epoch [2/3], Step [846/1349], Loss: 0.0679\n",
            "Epoch [2/3], Step [847/1349], Loss: 0.0239\n",
            "Epoch [2/3], Step [848/1349], Loss: 0.0150\n",
            "Epoch [2/3], Step [849/1349], Loss: 0.1024\n",
            "Epoch [2/3], Step [850/1349], Loss: 0.0701\n",
            "Epoch [2/3], Step [851/1349], Loss: 0.0613\n",
            "Epoch [2/3], Step [852/1349], Loss: 0.1432\n",
            "Epoch [2/3], Step [853/1349], Loss: 0.0946\n",
            "Epoch [2/3], Step [854/1349], Loss: 0.1464\n",
            "Epoch [2/3], Step [855/1349], Loss: 0.0508\n",
            "Epoch [2/3], Step [856/1349], Loss: 0.0850\n",
            "Epoch [2/3], Step [857/1349], Loss: 0.0788\n",
            "Epoch [2/3], Step [858/1349], Loss: 0.0585\n",
            "Epoch [2/3], Step [859/1349], Loss: 0.0972\n",
            "Epoch [2/3], Step [860/1349], Loss: 0.0546\n",
            "Epoch [2/3], Step [861/1349], Loss: 0.1360\n",
            "Epoch [2/3], Step [862/1349], Loss: 0.0744\n",
            "Epoch [2/3], Step [863/1349], Loss: 0.1216\n",
            "Epoch [2/3], Step [864/1349], Loss: 0.0968\n",
            "Epoch [2/3], Step [865/1349], Loss: 0.0313\n",
            "Epoch [2/3], Step [866/1349], Loss: 0.0185\n",
            "Epoch [2/3], Step [867/1349], Loss: 0.1722\n",
            "Epoch [2/3], Step [868/1349], Loss: 0.0333\n",
            "Epoch [2/3], Step [869/1349], Loss: 0.1101\n",
            "Epoch [2/3], Step [870/1349], Loss: 0.0866\n",
            "Epoch [2/3], Step [871/1349], Loss: 0.1351\n",
            "Epoch [2/3], Step [872/1349], Loss: 0.1288\n",
            "Epoch [2/3], Step [873/1349], Loss: 0.0842\n",
            "Epoch [2/3], Step [874/1349], Loss: 0.0571\n",
            "Epoch [2/3], Step [875/1349], Loss: 0.0259\n",
            "Epoch [2/3], Step [876/1349], Loss: 0.1231\n",
            "Epoch [2/3], Step [877/1349], Loss: 0.0445\n",
            "Epoch [2/3], Step [878/1349], Loss: 0.1235\n",
            "Epoch [2/3], Step [879/1349], Loss: 0.1547\n",
            "Epoch [2/3], Step [880/1349], Loss: 0.0961\n",
            "Epoch [2/3], Step [881/1349], Loss: 0.0745\n",
            "Epoch [2/3], Step [882/1349], Loss: 0.0453\n",
            "Epoch [2/3], Step [883/1349], Loss: 0.1789\n",
            "Epoch [2/3], Step [884/1349], Loss: 0.0746\n",
            "Epoch [2/3], Step [885/1349], Loss: 0.2361\n",
            "Epoch [2/3], Step [886/1349], Loss: 0.1691\n",
            "Epoch [2/3], Step [887/1349], Loss: 0.0590\n",
            "Epoch [2/3], Step [888/1349], Loss: 0.2337\n",
            "Epoch [2/3], Step [889/1349], Loss: 0.1273\n",
            "Epoch [2/3], Step [890/1349], Loss: 0.1439\n",
            "Epoch [2/3], Step [891/1349], Loss: 0.0753\n",
            "Epoch [2/3], Step [892/1349], Loss: 0.1309\n",
            "Epoch [2/3], Step [893/1349], Loss: 0.0962\n",
            "Epoch [2/3], Step [894/1349], Loss: 0.1477\n",
            "Epoch [2/3], Step [895/1349], Loss: 0.0920\n",
            "Epoch [2/3], Step [896/1349], Loss: 0.0781\n",
            "Epoch [2/3], Step [897/1349], Loss: 0.0246\n",
            "Epoch [2/3], Step [898/1349], Loss: 0.0388\n",
            "Epoch [2/3], Step [899/1349], Loss: 0.1584\n",
            "Epoch [2/3], Step [900/1349], Loss: 0.0436\n",
            "Epoch [2/3], Step [901/1349], Loss: 0.0465\n",
            "Epoch [2/3], Step [902/1349], Loss: 0.1503\n",
            "Epoch [2/3], Step [903/1349], Loss: 0.0609\n",
            "Epoch [2/3], Step [904/1349], Loss: 0.0343\n",
            "Epoch [2/3], Step [905/1349], Loss: 0.1483\n",
            "Epoch [2/3], Step [906/1349], Loss: 0.0136\n",
            "Epoch [2/3], Step [907/1349], Loss: 0.0293\n",
            "Epoch [2/3], Step [908/1349], Loss: 0.0633\n",
            "Epoch [2/3], Step [909/1349], Loss: 0.0633\n",
            "Epoch [2/3], Step [910/1349], Loss: 0.0364\n",
            "Epoch [2/3], Step [911/1349], Loss: 0.1086\n",
            "Epoch [2/3], Step [912/1349], Loss: 0.1094\n",
            "Epoch [2/3], Step [913/1349], Loss: 0.0369\n",
            "Epoch [2/3], Step [914/1349], Loss: 0.0135\n",
            "Epoch [2/3], Step [915/1349], Loss: 0.0217\n",
            "Epoch [2/3], Step [916/1349], Loss: 0.2082\n",
            "Epoch [2/3], Step [917/1349], Loss: 0.0203\n",
            "Epoch [2/3], Step [918/1349], Loss: 0.1017\n",
            "Epoch [2/3], Step [919/1349], Loss: 0.0126\n",
            "Epoch [2/3], Step [920/1349], Loss: 0.0084\n",
            "Epoch [2/3], Step [921/1349], Loss: 0.0516\n",
            "Epoch [2/3], Step [922/1349], Loss: 0.0621\n",
            "Epoch [2/3], Step [923/1349], Loss: 0.1257\n",
            "Epoch [2/3], Step [924/1349], Loss: 0.1233\n",
            "Epoch [2/3], Step [925/1349], Loss: 0.0255\n",
            "Epoch [2/3], Step [926/1349], Loss: 0.0883\n",
            "Epoch [2/3], Step [927/1349], Loss: 0.1568\n",
            "Epoch [2/3], Step [928/1349], Loss: 0.1079\n",
            "Epoch [2/3], Step [929/1349], Loss: 0.1226\n",
            "Epoch [2/3], Step [930/1349], Loss: 0.0424\n",
            "Epoch [2/3], Step [931/1349], Loss: 0.0763\n",
            "Epoch [2/3], Step [932/1349], Loss: 0.1332\n",
            "Epoch [2/3], Step [933/1349], Loss: 0.0449\n",
            "Epoch [2/3], Step [934/1349], Loss: 0.0549\n",
            "Epoch [2/3], Step [935/1349], Loss: 0.0478\n",
            "Epoch [2/3], Step [936/1349], Loss: 0.0321\n",
            "Epoch [2/3], Step [937/1349], Loss: 0.1012\n",
            "Epoch [2/3], Step [938/1349], Loss: 0.0228\n",
            "Epoch [2/3], Step [939/1349], Loss: 0.0837\n",
            "Epoch [2/3], Step [940/1349], Loss: 0.0466\n",
            "Epoch [2/3], Step [941/1349], Loss: 0.0870\n",
            "Epoch [2/3], Step [942/1349], Loss: 0.0174\n",
            "Epoch [2/3], Step [943/1349], Loss: 0.0875\n",
            "Epoch [2/3], Step [944/1349], Loss: 0.0309\n",
            "Epoch [2/3], Step [945/1349], Loss: 0.0371\n",
            "Epoch [2/3], Step [946/1349], Loss: 0.1171\n",
            "Epoch [2/3], Step [947/1349], Loss: 0.0176\n",
            "Epoch [2/3], Step [948/1349], Loss: 0.3026\n",
            "Epoch [2/3], Step [949/1349], Loss: 0.0839\n",
            "Epoch [2/3], Step [950/1349], Loss: 0.0263\n",
            "Epoch [2/3], Step [951/1349], Loss: 0.0675\n",
            "Epoch [2/3], Step [952/1349], Loss: 0.0873\n",
            "Epoch [2/3], Step [953/1349], Loss: 0.0644\n",
            "Epoch [2/3], Step [954/1349], Loss: 0.2653\n",
            "Epoch [2/3], Step [955/1349], Loss: 0.1395\n",
            "Epoch [2/3], Step [956/1349], Loss: 0.0439\n",
            "Epoch [2/3], Step [957/1349], Loss: 0.0352\n",
            "Epoch [2/3], Step [958/1349], Loss: 0.0825\n",
            "Epoch [2/3], Step [959/1349], Loss: 0.0216\n",
            "Epoch [2/3], Step [960/1349], Loss: 0.0145\n",
            "Epoch [2/3], Step [961/1349], Loss: 0.0154\n",
            "Epoch [2/3], Step [962/1349], Loss: 0.1344\n",
            "Epoch [2/3], Step [963/1349], Loss: 0.0416\n",
            "Epoch [2/3], Step [964/1349], Loss: 0.0527\n",
            "Epoch [2/3], Step [965/1349], Loss: 0.0147\n",
            "Epoch [2/3], Step [966/1349], Loss: 0.1255\n",
            "Epoch [2/3], Step [967/1349], Loss: 0.0587\n",
            "Epoch [2/3], Step [968/1349], Loss: 0.2435\n",
            "Epoch [2/3], Step [969/1349], Loss: 0.0537\n",
            "Epoch [2/3], Step [970/1349], Loss: 0.0402\n",
            "Epoch [2/3], Step [971/1349], Loss: 0.0584\n",
            "Epoch [2/3], Step [972/1349], Loss: 0.0824\n",
            "Epoch [2/3], Step [973/1349], Loss: 0.0977\n",
            "Epoch [2/3], Step [974/1349], Loss: 0.0339\n",
            "Epoch [2/3], Step [975/1349], Loss: 0.0309\n",
            "Epoch [2/3], Step [976/1349], Loss: 0.0057\n",
            "Epoch [2/3], Step [977/1349], Loss: 0.1805\n",
            "Epoch [2/3], Step [978/1349], Loss: 0.0083\n",
            "Epoch [2/3], Step [979/1349], Loss: 0.0298\n",
            "Epoch [2/3], Step [980/1349], Loss: 0.0374\n",
            "Epoch [2/3], Step [981/1349], Loss: 0.0944\n",
            "Epoch [2/3], Step [982/1349], Loss: 0.0586\n",
            "Epoch [2/3], Step [983/1349], Loss: 0.1026\n",
            "Epoch [2/3], Step [984/1349], Loss: 0.0929\n",
            "Epoch [2/3], Step [985/1349], Loss: 0.1070\n",
            "Epoch [2/3], Step [986/1349], Loss: 0.0862\n",
            "Epoch [2/3], Step [987/1349], Loss: 0.0506\n",
            "Epoch [2/3], Step [988/1349], Loss: 0.0234\n",
            "Epoch [2/3], Step [989/1349], Loss: 0.0381\n",
            "Epoch [2/3], Step [990/1349], Loss: 0.0960\n",
            "Epoch [2/3], Step [991/1349], Loss: 0.0154\n",
            "Epoch [2/3], Step [992/1349], Loss: 0.1860\n",
            "Epoch [2/3], Step [993/1349], Loss: 0.1096\n",
            "Epoch [2/3], Step [994/1349], Loss: 0.0154\n",
            "Epoch [2/3], Step [995/1349], Loss: 0.0266\n",
            "Epoch [2/3], Step [996/1349], Loss: 0.1048\n",
            "Epoch [2/3], Step [997/1349], Loss: 0.0358\n",
            "Epoch [2/3], Step [998/1349], Loss: 0.0385\n",
            "Epoch [2/3], Step [999/1349], Loss: 0.0611\n",
            "Epoch [2/3], Step [1000/1349], Loss: 0.0372\n",
            "Epoch [2/3], Step [1001/1349], Loss: 0.0273\n",
            "Epoch [2/3], Step [1002/1349], Loss: 0.1970\n",
            "Epoch [2/3], Step [1003/1349], Loss: 0.0511\n",
            "Epoch [2/3], Step [1004/1349], Loss: 0.0467\n",
            "Epoch [2/3], Step [1005/1349], Loss: 0.0317\n",
            "Epoch [2/3], Step [1006/1349], Loss: 0.0023\n",
            "Epoch [2/3], Step [1007/1349], Loss: 0.0334\n",
            "Epoch [2/3], Step [1008/1349], Loss: 0.1046\n",
            "Epoch [2/3], Step [1009/1349], Loss: 0.0096\n",
            "Epoch [2/3], Step [1010/1349], Loss: 0.0559\n",
            "Epoch [2/3], Step [1011/1349], Loss: 0.0663\n",
            "Epoch [2/3], Step [1012/1349], Loss: 0.1899\n",
            "Epoch [2/3], Step [1013/1349], Loss: 0.0087\n",
            "Epoch [2/3], Step [1014/1349], Loss: 0.0511\n",
            "Epoch [2/3], Step [1015/1349], Loss: 0.1062\n",
            "Epoch [2/3], Step [1016/1349], Loss: 0.0916\n",
            "Epoch [2/3], Step [1017/1349], Loss: 0.1326\n",
            "Epoch [2/3], Step [1018/1349], Loss: 0.1996\n",
            "Epoch [2/3], Step [1019/1349], Loss: 0.0421\n",
            "Epoch [2/3], Step [1020/1349], Loss: 0.0427\n",
            "Epoch [2/3], Step [1021/1349], Loss: 0.0848\n",
            "Epoch [2/3], Step [1022/1349], Loss: 0.1457\n",
            "Epoch [2/3], Step [1023/1349], Loss: 0.1163\n",
            "Epoch [2/3], Step [1024/1349], Loss: 0.0832\n",
            "Epoch [2/3], Step [1025/1349], Loss: 0.1019\n",
            "Epoch [2/3], Step [1026/1349], Loss: 0.1614\n",
            "Epoch [2/3], Step [1027/1349], Loss: 0.0085\n",
            "Epoch [2/3], Step [1028/1349], Loss: 0.0802\n",
            "Epoch [2/3], Step [1029/1349], Loss: 0.1486\n",
            "Epoch [2/3], Step [1030/1349], Loss: 0.0571\n",
            "Epoch [2/3], Step [1031/1349], Loss: 0.1431\n",
            "Epoch [2/3], Step [1032/1349], Loss: 0.0197\n",
            "Epoch [2/3], Step [1033/1349], Loss: 0.0455\n",
            "Epoch [2/3], Step [1034/1349], Loss: 0.0580\n",
            "Epoch [2/3], Step [1035/1349], Loss: 0.0212\n",
            "Epoch [2/3], Step [1036/1349], Loss: 0.0798\n",
            "Epoch [2/3], Step [1037/1349], Loss: 0.0389\n",
            "Epoch [2/3], Step [1038/1349], Loss: 0.0033\n",
            "Epoch [2/3], Step [1039/1349], Loss: 0.0500\n",
            "Epoch [2/3], Step [1040/1349], Loss: 0.0228\n",
            "Epoch [2/3], Step [1041/1349], Loss: 0.0202\n",
            "Epoch [2/3], Step [1042/1349], Loss: 0.1958\n",
            "Epoch [2/3], Step [1043/1349], Loss: 0.0112\n",
            "Epoch [2/3], Step [1044/1349], Loss: 0.0931\n",
            "Epoch [2/3], Step [1045/1349], Loss: 0.0060\n",
            "Epoch [2/3], Step [1046/1349], Loss: 0.0108\n",
            "Epoch [2/3], Step [1047/1349], Loss: 0.0473\n",
            "Epoch [2/3], Step [1048/1349], Loss: 0.1079\n",
            "Epoch [2/3], Step [1049/1349], Loss: 0.1291\n",
            "Epoch [2/3], Step [1050/1349], Loss: 0.0746\n",
            "Epoch [2/3], Step [1051/1349], Loss: 0.0568\n",
            "Epoch [2/3], Step [1052/1349], Loss: 0.0540\n",
            "Epoch [2/3], Step [1053/1349], Loss: 0.0694\n",
            "Epoch [2/3], Step [1054/1349], Loss: 0.1674\n",
            "Epoch [2/3], Step [1055/1349], Loss: 0.0044\n",
            "Epoch [2/3], Step [1056/1349], Loss: 0.0064\n",
            "Epoch [2/3], Step [1057/1349], Loss: 0.1613\n",
            "Epoch [2/3], Step [1058/1349], Loss: 0.0860\n",
            "Epoch [2/3], Step [1059/1349], Loss: 0.0447\n",
            "Epoch [2/3], Step [1060/1349], Loss: 0.1265\n",
            "Epoch [2/3], Step [1061/1349], Loss: 0.1163\n",
            "Epoch [2/3], Step [1062/1349], Loss: 0.0108\n",
            "Epoch [2/3], Step [1063/1349], Loss: 0.0358\n",
            "Epoch [2/3], Step [1064/1349], Loss: 0.4387\n",
            "Epoch [2/3], Step [1065/1349], Loss: 0.2017\n",
            "Epoch [2/3], Step [1066/1349], Loss: 0.0543\n",
            "Epoch [2/3], Step [1067/1349], Loss: 0.1129\n",
            "Epoch [2/3], Step [1068/1349], Loss: 0.1443\n",
            "Epoch [2/3], Step [1069/1349], Loss: 0.0555\n",
            "Epoch [2/3], Step [1070/1349], Loss: 0.1940\n",
            "Epoch [2/3], Step [1071/1349], Loss: 0.0353\n",
            "Epoch [2/3], Step [1072/1349], Loss: 0.0453\n",
            "Epoch [2/3], Step [1073/1349], Loss: 0.0966\n",
            "Epoch [2/3], Step [1074/1349], Loss: 0.0502\n",
            "Epoch [2/3], Step [1075/1349], Loss: 0.0781\n",
            "Epoch [2/3], Step [1076/1349], Loss: 0.0270\n",
            "Epoch [2/3], Step [1077/1349], Loss: 0.0713\n",
            "Epoch [2/3], Step [1078/1349], Loss: 0.1930\n",
            "Epoch [2/3], Step [1079/1349], Loss: 0.0450\n",
            "Epoch [2/3], Step [1080/1349], Loss: 0.0211\n",
            "Epoch [2/3], Step [1081/1349], Loss: 0.0954\n",
            "Epoch [2/3], Step [1082/1349], Loss: 0.1029\n",
            "Epoch [2/3], Step [1083/1349], Loss: 0.0529\n",
            "Epoch [2/3], Step [1084/1349], Loss: 0.3054\n",
            "Epoch [2/3], Step [1085/1349], Loss: 0.0922\n",
            "Epoch [2/3], Step [1086/1349], Loss: 0.0512\n",
            "Epoch [2/3], Step [1087/1349], Loss: 0.0127\n",
            "Epoch [2/3], Step [1088/1349], Loss: 0.0778\n",
            "Epoch [2/3], Step [1089/1349], Loss: 0.1068\n",
            "Epoch [2/3], Step [1090/1349], Loss: 0.0482\n",
            "Epoch [2/3], Step [1091/1349], Loss: 0.1260\n",
            "Epoch [2/3], Step [1092/1349], Loss: 0.1876\n",
            "Epoch [2/3], Step [1093/1349], Loss: 0.1715\n",
            "Epoch [2/3], Step [1094/1349], Loss: 0.0690\n",
            "Epoch [2/3], Step [1095/1349], Loss: 0.0112\n",
            "Epoch [2/3], Step [1096/1349], Loss: 0.0269\n",
            "Epoch [2/3], Step [1097/1349], Loss: 0.0570\n",
            "Epoch [2/3], Step [1098/1349], Loss: 0.1871\n",
            "Epoch [2/3], Step [1099/1349], Loss: 0.0788\n",
            "Epoch [2/3], Step [1100/1349], Loss: 0.0649\n",
            "Epoch [2/3], Step [1101/1349], Loss: 0.0971\n",
            "Epoch [2/3], Step [1102/1349], Loss: 0.0646\n",
            "Epoch [2/3], Step [1103/1349], Loss: 0.0113\n",
            "Epoch [2/3], Step [1104/1349], Loss: 0.0308\n",
            "Epoch [2/3], Step [1105/1349], Loss: 0.0473\n",
            "Epoch [2/3], Step [1106/1349], Loss: 0.1085\n",
            "Epoch [2/3], Step [1107/1349], Loss: 0.2682\n",
            "Epoch [2/3], Step [1108/1349], Loss: 0.1091\n",
            "Epoch [2/3], Step [1109/1349], Loss: 0.1804\n",
            "Epoch [2/3], Step [1110/1349], Loss: 0.0360\n",
            "Epoch [2/3], Step [1111/1349], Loss: 0.0553\n",
            "Epoch [2/3], Step [1112/1349], Loss: 0.1378\n",
            "Epoch [2/3], Step [1113/1349], Loss: 0.0623\n",
            "Epoch [2/3], Step [1114/1349], Loss: 0.1396\n",
            "Epoch [2/3], Step [1115/1349], Loss: 0.0583\n",
            "Epoch [2/3], Step [1116/1349], Loss: 0.0207\n",
            "Epoch [2/3], Step [1117/1349], Loss: 0.0654\n",
            "Epoch [2/3], Step [1118/1349], Loss: 0.0528\n",
            "Epoch [2/3], Step [1119/1349], Loss: 0.0336\n",
            "Epoch [2/3], Step [1120/1349], Loss: 0.0563\n",
            "Epoch [2/3], Step [1121/1349], Loss: 0.0125\n",
            "Epoch [2/3], Step [1122/1349], Loss: 0.0260\n",
            "Epoch [2/3], Step [1123/1349], Loss: 0.1172\n",
            "Epoch [2/3], Step [1124/1349], Loss: 0.1495\n",
            "Epoch [2/3], Step [1125/1349], Loss: 0.2359\n",
            "Epoch [2/3], Step [1126/1349], Loss: 0.0221\n",
            "Epoch [2/3], Step [1127/1349], Loss: 0.0361\n",
            "Epoch [2/3], Step [1128/1349], Loss: 0.1140\n",
            "Epoch [2/3], Step [1129/1349], Loss: 0.1186\n",
            "Epoch [2/3], Step [1130/1349], Loss: 0.0460\n",
            "Epoch [2/3], Step [1131/1349], Loss: 0.0234\n",
            "Epoch [2/3], Step [1132/1349], Loss: 0.0386\n",
            "Epoch [2/3], Step [1133/1349], Loss: 0.0833\n",
            "Epoch [2/3], Step [1134/1349], Loss: 0.0699\n",
            "Epoch [2/3], Step [1135/1349], Loss: 0.0147\n",
            "Epoch [2/3], Step [1136/1349], Loss: 0.2234\n",
            "Epoch [2/3], Step [1137/1349], Loss: 0.0831\n",
            "Epoch [2/3], Step [1138/1349], Loss: 0.1522\n",
            "Epoch [2/3], Step [1139/1349], Loss: 0.2421\n",
            "Epoch [2/3], Step [1140/1349], Loss: 0.0372\n",
            "Epoch [2/3], Step [1141/1349], Loss: 0.0623\n",
            "Epoch [2/3], Step [1142/1349], Loss: 0.1894\n",
            "Epoch [2/3], Step [1143/1349], Loss: 0.0573\n",
            "Epoch [2/3], Step [1144/1349], Loss: 0.2622\n",
            "Epoch [2/3], Step [1145/1349], Loss: 0.0844\n",
            "Epoch [2/3], Step [1146/1349], Loss: 0.0289\n",
            "Epoch [2/3], Step [1147/1349], Loss: 0.2871\n",
            "Epoch [2/3], Step [1148/1349], Loss: 0.1412\n",
            "Epoch [2/3], Step [1149/1349], Loss: 0.1454\n",
            "Epoch [2/3], Step [1150/1349], Loss: 0.0367\n",
            "Epoch [2/3], Step [1151/1349], Loss: 0.0368\n",
            "Epoch [2/3], Step [1152/1349], Loss: 0.0645\n",
            "Epoch [2/3], Step [1153/1349], Loss: 0.0493\n",
            "Epoch [2/3], Step [1154/1349], Loss: 0.0445\n",
            "Epoch [2/3], Step [1155/1349], Loss: 0.0185\n",
            "Epoch [2/3], Step [1156/1349], Loss: 0.1597\n",
            "Epoch [2/3], Step [1157/1349], Loss: 0.0456\n",
            "Epoch [2/3], Step [1158/1349], Loss: 0.1798\n",
            "Epoch [2/3], Step [1159/1349], Loss: 0.0662\n",
            "Epoch [2/3], Step [1160/1349], Loss: 0.1007\n",
            "Epoch [2/3], Step [1161/1349], Loss: 0.1336\n",
            "Epoch [2/3], Step [1162/1349], Loss: 0.0420\n",
            "Epoch [2/3], Step [1163/1349], Loss: 0.0943\n",
            "Epoch [2/3], Step [1164/1349], Loss: 0.0230\n",
            "Epoch [2/3], Step [1165/1349], Loss: 0.0597\n",
            "Epoch [2/3], Step [1166/1349], Loss: 0.0559\n",
            "Epoch [2/3], Step [1167/1349], Loss: 0.0601\n",
            "Epoch [2/3], Step [1168/1349], Loss: 0.1755\n",
            "Epoch [2/3], Step [1169/1349], Loss: 0.2235\n",
            "Epoch [2/3], Step [1170/1349], Loss: 0.0670\n",
            "Epoch [2/3], Step [1171/1349], Loss: 0.0662\n",
            "Epoch [2/3], Step [1172/1349], Loss: 0.0785\n",
            "Epoch [2/3], Step [1173/1349], Loss: 0.0139\n",
            "Epoch [2/3], Step [1174/1349], Loss: 0.0336\n",
            "Epoch [2/3], Step [1175/1349], Loss: 0.0755\n",
            "Epoch [2/3], Step [1176/1349], Loss: 0.0943\n",
            "Epoch [2/3], Step [1177/1349], Loss: 0.0514\n",
            "Epoch [2/3], Step [1178/1349], Loss: 0.0061\n",
            "Epoch [2/3], Step [1179/1349], Loss: 0.0384\n",
            "Epoch [2/3], Step [1180/1349], Loss: 0.0231\n",
            "Epoch [2/3], Step [1181/1349], Loss: 0.0603\n",
            "Epoch [2/3], Step [1182/1349], Loss: 0.0125\n",
            "Epoch [2/3], Step [1183/1349], Loss: 0.1422\n",
            "Epoch [2/3], Step [1184/1349], Loss: 0.0069\n",
            "Epoch [2/3], Step [1185/1349], Loss: 0.0779\n",
            "Epoch [2/3], Step [1186/1349], Loss: 0.0113\n",
            "Epoch [2/3], Step [1187/1349], Loss: 0.1089\n",
            "Epoch [2/3], Step [1188/1349], Loss: 0.1052\n",
            "Epoch [2/3], Step [1189/1349], Loss: 0.1094\n",
            "Epoch [2/3], Step [1190/1349], Loss: 0.0279\n",
            "Epoch [2/3], Step [1191/1349], Loss: 0.0836\n",
            "Epoch [2/3], Step [1192/1349], Loss: 0.1698\n",
            "Epoch [2/3], Step [1193/1349], Loss: 0.0618\n",
            "Epoch [2/3], Step [1194/1349], Loss: 0.0297\n",
            "Epoch [2/3], Step [1195/1349], Loss: 0.0877\n",
            "Epoch [2/3], Step [1196/1349], Loss: 0.0577\n",
            "Epoch [2/3], Step [1197/1349], Loss: 0.0256\n",
            "Epoch [2/3], Step [1198/1349], Loss: 0.1077\n",
            "Epoch [2/3], Step [1199/1349], Loss: 0.0570\n",
            "Epoch [2/3], Step [1200/1349], Loss: 0.1198\n",
            "Epoch [2/3], Step [1201/1349], Loss: 0.1084\n",
            "Epoch [2/3], Step [1202/1349], Loss: 0.0097\n",
            "Epoch [2/3], Step [1203/1349], Loss: 0.1284\n",
            "Epoch [2/3], Step [1204/1349], Loss: 0.0688\n",
            "Epoch [2/3], Step [1205/1349], Loss: 0.1162\n",
            "Epoch [2/3], Step [1206/1349], Loss: 0.0349\n",
            "Epoch [2/3], Step [1207/1349], Loss: 0.0056\n",
            "Epoch [2/3], Step [1208/1349], Loss: 0.1124\n",
            "Epoch [2/3], Step [1209/1349], Loss: 0.1309\n",
            "Epoch [2/3], Step [1210/1349], Loss: 0.2654\n",
            "Epoch [2/3], Step [1211/1349], Loss: 0.1317\n",
            "Epoch [2/3], Step [1212/1349], Loss: 0.2051\n",
            "Epoch [2/3], Step [1213/1349], Loss: 0.1499\n",
            "Epoch [2/3], Step [1214/1349], Loss: 0.1098\n",
            "Epoch [2/3], Step [1215/1349], Loss: 0.0543\n",
            "Epoch [2/3], Step [1216/1349], Loss: 0.0448\n",
            "Epoch [2/3], Step [1217/1349], Loss: 0.0447\n",
            "Epoch [2/3], Step [1218/1349], Loss: 0.0996\n",
            "Epoch [2/3], Step [1219/1349], Loss: 0.1529\n",
            "Epoch [2/3], Step [1220/1349], Loss: 0.0201\n",
            "Epoch [2/3], Step [1221/1349], Loss: 0.0864\n",
            "Epoch [2/3], Step [1222/1349], Loss: 0.0082\n",
            "Epoch [2/3], Step [1223/1349], Loss: 0.2247\n",
            "Epoch [2/3], Step [1224/1349], Loss: 0.0676\n",
            "Epoch [2/3], Step [1225/1349], Loss: 0.0928\n",
            "Epoch [2/3], Step [1226/1349], Loss: 0.0705\n",
            "Epoch [2/3], Step [1227/1349], Loss: 0.0691\n",
            "Epoch [2/3], Step [1228/1349], Loss: 0.1460\n",
            "Epoch [2/3], Step [1229/1349], Loss: 0.1923\n",
            "Epoch [2/3], Step [1230/1349], Loss: 0.0383\n",
            "Epoch [2/3], Step [1231/1349], Loss: 0.1071\n",
            "Epoch [2/3], Step [1232/1349], Loss: 0.0515\n",
            "Epoch [2/3], Step [1233/1349], Loss: 0.1011\n",
            "Epoch [2/3], Step [1234/1349], Loss: 0.0972\n",
            "Epoch [2/3], Step [1235/1349], Loss: 0.0052\n",
            "Epoch [2/3], Step [1236/1349], Loss: 0.0376\n",
            "Epoch [2/3], Step [1237/1349], Loss: 0.0521\n",
            "Epoch [2/3], Step [1238/1349], Loss: 0.0086\n",
            "Epoch [2/3], Step [1239/1349], Loss: 0.1507\n",
            "Epoch [2/3], Step [1240/1349], Loss: 0.0435\n",
            "Epoch [2/3], Step [1241/1349], Loss: 0.0487\n",
            "Epoch [2/3], Step [1242/1349], Loss: 0.1522\n",
            "Epoch [2/3], Step [1243/1349], Loss: 0.2734\n",
            "Epoch [2/3], Step [1244/1349], Loss: 0.0340\n",
            "Epoch [2/3], Step [1245/1349], Loss: 0.0331\n",
            "Epoch [2/3], Step [1246/1349], Loss: 0.0493\n",
            "Epoch [2/3], Step [1247/1349], Loss: 0.0405\n",
            "Epoch [2/3], Step [1248/1349], Loss: 0.0507\n",
            "Epoch [2/3], Step [1249/1349], Loss: 0.2682\n",
            "Epoch [2/3], Step [1250/1349], Loss: 0.0713\n",
            "Epoch [2/3], Step [1251/1349], Loss: 0.0645\n",
            "Epoch [2/3], Step [1252/1349], Loss: 0.0580\n",
            "Epoch [2/3], Step [1253/1349], Loss: 0.0152\n",
            "Epoch [2/3], Step [1254/1349], Loss: 0.0211\n",
            "Epoch [2/3], Step [1255/1349], Loss: 0.1352\n",
            "Epoch [2/3], Step [1256/1349], Loss: 0.1071\n",
            "Epoch [2/3], Step [1257/1349], Loss: 0.1391\n",
            "Epoch [2/3], Step [1258/1349], Loss: 0.1256\n",
            "Epoch [2/3], Step [1259/1349], Loss: 0.0945\n",
            "Epoch [2/3], Step [1260/1349], Loss: 0.0194\n",
            "Epoch [2/3], Step [1261/1349], Loss: 0.0573\n",
            "Epoch [2/3], Step [1262/1349], Loss: 0.0883\n",
            "Epoch [2/3], Step [1263/1349], Loss: 0.0544\n",
            "Epoch [2/3], Step [1264/1349], Loss: 0.0242\n",
            "Epoch [2/3], Step [1265/1349], Loss: 0.0621\n",
            "Epoch [2/3], Step [1266/1349], Loss: 0.2529\n",
            "Epoch [2/3], Step [1267/1349], Loss: 0.0949\n",
            "Epoch [2/3], Step [1268/1349], Loss: 0.0519\n",
            "Epoch [2/3], Step [1269/1349], Loss: 0.1177\n",
            "Epoch [2/3], Step [1270/1349], Loss: 0.0846\n",
            "Epoch [2/3], Step [1271/1349], Loss: 0.2196\n",
            "Epoch [2/3], Step [1272/1349], Loss: 0.0180\n",
            "Epoch [2/3], Step [1273/1349], Loss: 0.0977\n",
            "Epoch [2/3], Step [1274/1349], Loss: 0.0287\n",
            "Epoch [2/3], Step [1275/1349], Loss: 0.0930\n",
            "Epoch [2/3], Step [1276/1349], Loss: 0.0171\n",
            "Epoch [2/3], Step [1277/1349], Loss: 0.0461\n",
            "Epoch [2/3], Step [1278/1349], Loss: 0.0217\n",
            "Epoch [2/3], Step [1279/1349], Loss: 0.1835\n",
            "Epoch [2/3], Step [1280/1349], Loss: 0.0576\n",
            "Epoch [2/3], Step [1281/1349], Loss: 0.0452\n",
            "Epoch [2/3], Step [1282/1349], Loss: 0.1539\n",
            "Epoch [2/3], Step [1283/1349], Loss: 0.0192\n",
            "Epoch [2/3], Step [1284/1349], Loss: 0.0605\n",
            "Epoch [2/3], Step [1285/1349], Loss: 0.0420\n",
            "Epoch [2/3], Step [1286/1349], Loss: 0.0286\n",
            "Epoch [2/3], Step [1287/1349], Loss: 0.1162\n",
            "Epoch [2/3], Step [1288/1349], Loss: 0.0514\n",
            "Epoch [2/3], Step [1289/1349], Loss: 0.0282\n",
            "Epoch [2/3], Step [1290/1349], Loss: 0.1310\n",
            "Epoch [2/3], Step [1291/1349], Loss: 0.0092\n",
            "Epoch [2/3], Step [1292/1349], Loss: 0.0171\n",
            "Epoch [2/3], Step [1293/1349], Loss: 0.0314\n",
            "Epoch [2/3], Step [1294/1349], Loss: 0.0385\n",
            "Epoch [2/3], Step [1295/1349], Loss: 0.0309\n",
            "Epoch [2/3], Step [1296/1349], Loss: 0.0657\n",
            "Epoch [2/3], Step [1297/1349], Loss: 0.0349\n",
            "Epoch [2/3], Step [1298/1349], Loss: 0.0611\n",
            "Epoch [2/3], Step [1299/1349], Loss: 0.0058\n",
            "Epoch [2/3], Step [1300/1349], Loss: 0.1021\n",
            "Epoch [2/3], Step [1301/1349], Loss: 0.0398\n",
            "Epoch [2/3], Step [1302/1349], Loss: 0.0259\n",
            "Epoch [2/3], Step [1303/1349], Loss: 0.0564\n",
            "Epoch [2/3], Step [1304/1349], Loss: 0.0184\n",
            "Epoch [2/3], Step [1305/1349], Loss: 0.0913\n",
            "Epoch [2/3], Step [1306/1349], Loss: 0.1928\n",
            "Epoch [2/3], Step [1307/1349], Loss: 0.0260\n",
            "Epoch [2/3], Step [1308/1349], Loss: 0.0611\n",
            "Epoch [2/3], Step [1309/1349], Loss: 0.0901\n",
            "Epoch [2/3], Step [1310/1349], Loss: 0.0221\n",
            "Epoch [2/3], Step [1311/1349], Loss: 0.0356\n",
            "Epoch [2/3], Step [1312/1349], Loss: 0.3170\n",
            "Epoch [2/3], Step [1313/1349], Loss: 0.0515\n",
            "Epoch [2/3], Step [1314/1349], Loss: 0.0564\n",
            "Epoch [2/3], Step [1315/1349], Loss: 0.1922\n",
            "Epoch [2/3], Step [1316/1349], Loss: 0.0749\n",
            "Epoch [2/3], Step [1317/1349], Loss: 0.0727\n",
            "Epoch [2/3], Step [1318/1349], Loss: 0.0291\n",
            "Epoch [2/3], Step [1319/1349], Loss: 0.0927\n",
            "Epoch [2/3], Step [1320/1349], Loss: 0.0566\n",
            "Epoch [2/3], Step [1321/1349], Loss: 0.0580\n",
            "Epoch [2/3], Step [1322/1349], Loss: 0.1790\n",
            "Epoch [2/3], Step [1323/1349], Loss: 0.0459\n",
            "Epoch [2/3], Step [1324/1349], Loss: 0.1354\n",
            "Epoch [2/3], Step [1325/1349], Loss: 0.1021\n",
            "Epoch [2/3], Step [1326/1349], Loss: 0.0760\n",
            "Epoch [2/3], Step [1327/1349], Loss: 0.0742\n",
            "Epoch [2/3], Step [1328/1349], Loss: 0.0073\n",
            "Epoch [2/3], Step [1329/1349], Loss: 0.0253\n",
            "Epoch [2/3], Step [1330/1349], Loss: 0.0576\n",
            "Epoch [2/3], Step [1331/1349], Loss: 0.0393\n",
            "Epoch [2/3], Step [1332/1349], Loss: 0.0706\n",
            "Epoch [2/3], Step [1333/1349], Loss: 0.0531\n",
            "Epoch [2/3], Step [1334/1349], Loss: 0.0115\n",
            "Epoch [2/3], Step [1335/1349], Loss: 0.0334\n",
            "Epoch [2/3], Step [1336/1349], Loss: 0.0995\n",
            "Epoch [2/3], Step [1337/1349], Loss: 0.0106\n",
            "Epoch [2/3], Step [1338/1349], Loss: 0.0257\n",
            "Epoch [2/3], Step [1339/1349], Loss: 0.0131\n",
            "Epoch [2/3], Step [1340/1349], Loss: 0.0396\n",
            "Epoch [2/3], Step [1341/1349], Loss: 0.0078\n",
            "Epoch [2/3], Step [1342/1349], Loss: 0.0064\n",
            "Epoch [2/3], Step [1343/1349], Loss: 0.0493\n",
            "Epoch [2/3], Step [1344/1349], Loss: 0.0132\n",
            "Epoch [2/3], Step [1345/1349], Loss: 0.0090\n",
            "Epoch [2/3], Step [1346/1349], Loss: 0.1634\n",
            "Epoch [2/3], Step [1347/1349], Loss: 0.0216\n",
            "Epoch [2/3], Step [1348/1349], Loss: 0.0872\n",
            "Epoch [2/3], Step [1349/1349], Loss: 0.0915\n",
            "Epoch [3/3], Step [1/1349], Loss: 0.2837\n",
            "Epoch [3/3], Step [2/1349], Loss: 0.0189\n",
            "Epoch [3/3], Step [3/1349], Loss: 0.0447\n",
            "Epoch [3/3], Step [4/1349], Loss: 0.1460\n",
            "Epoch [3/3], Step [5/1349], Loss: 0.0146\n",
            "Epoch [3/3], Step [6/1349], Loss: 0.0468\n",
            "Epoch [3/3], Step [7/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [8/1349], Loss: 0.1993\n",
            "Epoch [3/3], Step [9/1349], Loss: 0.0247\n",
            "Epoch [3/3], Step [10/1349], Loss: 0.0479\n",
            "Epoch [3/3], Step [11/1349], Loss: 0.0595\n",
            "Epoch [3/3], Step [12/1349], Loss: 0.0536\n",
            "Epoch [3/3], Step [13/1349], Loss: 0.0163\n",
            "Epoch [3/3], Step [14/1349], Loss: 0.0141\n",
            "Epoch [3/3], Step [15/1349], Loss: 0.0560\n",
            "Epoch [3/3], Step [16/1349], Loss: 0.1320\n",
            "Epoch [3/3], Step [17/1349], Loss: 0.0165\n",
            "Epoch [3/3], Step [18/1349], Loss: 0.0956\n",
            "Epoch [3/3], Step [19/1349], Loss: 0.0380\n",
            "Epoch [3/3], Step [20/1349], Loss: 0.0041\n",
            "Epoch [3/3], Step [21/1349], Loss: 0.0351\n",
            "Epoch [3/3], Step [22/1349], Loss: 0.0359\n",
            "Epoch [3/3], Step [23/1349], Loss: 0.0879\n",
            "Epoch [3/3], Step [24/1349], Loss: 0.1082\n",
            "Epoch [3/3], Step [25/1349], Loss: 0.0647\n",
            "Epoch [3/3], Step [26/1349], Loss: 0.0521\n",
            "Epoch [3/3], Step [27/1349], Loss: 0.1534\n",
            "Epoch [3/3], Step [28/1349], Loss: 0.0584\n",
            "Epoch [3/3], Step [29/1349], Loss: 0.0651\n",
            "Epoch [3/3], Step [30/1349], Loss: 0.0320\n",
            "Epoch [3/3], Step [31/1349], Loss: 0.0470\n",
            "Epoch [3/3], Step [32/1349], Loss: 0.0174\n",
            "Epoch [3/3], Step [33/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [34/1349], Loss: 0.0244\n",
            "Epoch [3/3], Step [35/1349], Loss: 0.0768\n",
            "Epoch [3/3], Step [36/1349], Loss: 0.0101\n",
            "Epoch [3/3], Step [37/1349], Loss: 0.0460\n",
            "Epoch [3/3], Step [38/1349], Loss: 0.1320\n",
            "Epoch [3/3], Step [39/1349], Loss: 0.0178\n",
            "Epoch [3/3], Step [40/1349], Loss: 0.0351\n",
            "Epoch [3/3], Step [41/1349], Loss: 0.0474\n",
            "Epoch [3/3], Step [42/1349], Loss: 0.0058\n",
            "Epoch [3/3], Step [43/1349], Loss: 0.0835\n",
            "Epoch [3/3], Step [44/1349], Loss: 0.0426\n",
            "Epoch [3/3], Step [45/1349], Loss: 0.0675\n",
            "Epoch [3/3], Step [46/1349], Loss: 0.0821\n",
            "Epoch [3/3], Step [47/1349], Loss: 0.0028\n",
            "Epoch [3/3], Step [48/1349], Loss: 0.0143\n",
            "Epoch [3/3], Step [49/1349], Loss: 0.0354\n",
            "Epoch [3/3], Step [50/1349], Loss: 0.0482\n",
            "Epoch [3/3], Step [51/1349], Loss: 0.0612\n",
            "Epoch [3/3], Step [52/1349], Loss: 0.0304\n",
            "Epoch [3/3], Step [53/1349], Loss: 0.0347\n",
            "Epoch [3/3], Step [54/1349], Loss: 0.1687\n",
            "Epoch [3/3], Step [55/1349], Loss: 0.0752\n",
            "Epoch [3/3], Step [56/1349], Loss: 0.0649\n",
            "Epoch [3/3], Step [57/1349], Loss: 0.0288\n",
            "Epoch [3/3], Step [58/1349], Loss: 0.0488\n",
            "Epoch [3/3], Step [59/1349], Loss: 0.0074\n",
            "Epoch [3/3], Step [60/1349], Loss: 0.0025\n",
            "Epoch [3/3], Step [61/1349], Loss: 0.0139\n",
            "Epoch [3/3], Step [62/1349], Loss: 0.0339\n",
            "Epoch [3/3], Step [63/1349], Loss: 0.2608\n",
            "Epoch [3/3], Step [64/1349], Loss: 0.1394\n",
            "Epoch [3/3], Step [65/1349], Loss: 0.1027\n",
            "Epoch [3/3], Step [66/1349], Loss: 0.0260\n",
            "Epoch [3/3], Step [67/1349], Loss: 0.0027\n",
            "Epoch [3/3], Step [68/1349], Loss: 0.0036\n",
            "Epoch [3/3], Step [69/1349], Loss: 0.0531\n",
            "Epoch [3/3], Step [70/1349], Loss: 0.0223\n",
            "Epoch [3/3], Step [71/1349], Loss: 0.0928\n",
            "Epoch [3/3], Step [72/1349], Loss: 0.0764\n",
            "Epoch [3/3], Step [73/1349], Loss: 0.0185\n",
            "Epoch [3/3], Step [74/1349], Loss: 0.0020\n",
            "Epoch [3/3], Step [75/1349], Loss: 0.0185\n",
            "Epoch [3/3], Step [76/1349], Loss: 0.0249\n",
            "Epoch [3/3], Step [77/1349], Loss: 0.1589\n",
            "Epoch [3/3], Step [78/1349], Loss: 0.1806\n",
            "Epoch [3/3], Step [79/1349], Loss: 0.0139\n",
            "Epoch [3/3], Step [80/1349], Loss: 0.1461\n",
            "Epoch [3/3], Step [81/1349], Loss: 0.1012\n",
            "Epoch [3/3], Step [82/1349], Loss: 0.0680\n",
            "Epoch [3/3], Step [83/1349], Loss: 0.0985\n",
            "Epoch [3/3], Step [84/1349], Loss: 0.0716\n",
            "Epoch [3/3], Step [85/1349], Loss: 0.0929\n",
            "Epoch [3/3], Step [86/1349], Loss: 0.2069\n",
            "Epoch [3/3], Step [87/1349], Loss: 0.0065\n",
            "Epoch [3/3], Step [88/1349], Loss: 0.0260\n",
            "Epoch [3/3], Step [89/1349], Loss: 0.0839\n",
            "Epoch [3/3], Step [90/1349], Loss: 0.0390\n",
            "Epoch [3/3], Step [91/1349], Loss: 0.0101\n",
            "Epoch [3/3], Step [92/1349], Loss: 0.1526\n",
            "Epoch [3/3], Step [93/1349], Loss: 0.2226\n",
            "Epoch [3/3], Step [94/1349], Loss: 0.0497\n",
            "Epoch [3/3], Step [95/1349], Loss: 0.0662\n",
            "Epoch [3/3], Step [96/1349], Loss: 0.0084\n",
            "Epoch [3/3], Step [97/1349], Loss: 0.0246\n",
            "Epoch [3/3], Step [98/1349], Loss: 0.0372\n",
            "Epoch [3/3], Step [99/1349], Loss: 0.0473\n",
            "Epoch [3/3], Step [100/1349], Loss: 0.0353\n",
            "Epoch [3/3], Step [101/1349], Loss: 0.2675\n",
            "Epoch [3/3], Step [102/1349], Loss: 0.0140\n",
            "Epoch [3/3], Step [103/1349], Loss: 0.0475\n",
            "Epoch [3/3], Step [104/1349], Loss: 0.1218\n",
            "Epoch [3/3], Step [105/1349], Loss: 0.1079\n",
            "Epoch [3/3], Step [106/1349], Loss: 0.1314\n",
            "Epoch [3/3], Step [107/1349], Loss: 0.0261\n",
            "Epoch [3/3], Step [108/1349], Loss: 0.0101\n",
            "Epoch [3/3], Step [109/1349], Loss: 0.0464\n",
            "Epoch [3/3], Step [110/1349], Loss: 0.0538\n",
            "Epoch [3/3], Step [111/1349], Loss: 0.1557\n",
            "Epoch [3/3], Step [112/1349], Loss: 0.0153\n",
            "Epoch [3/3], Step [113/1349], Loss: 0.0327\n",
            "Epoch [3/3], Step [114/1349], Loss: 0.0828\n",
            "Epoch [3/3], Step [115/1349], Loss: 0.0910\n",
            "Epoch [3/3], Step [116/1349], Loss: 0.0196\n",
            "Epoch [3/3], Step [117/1349], Loss: 0.0642\n",
            "Epoch [3/3], Step [118/1349], Loss: 0.0070\n",
            "Epoch [3/3], Step [119/1349], Loss: 0.1621\n",
            "Epoch [3/3], Step [120/1349], Loss: 0.0768\n",
            "Epoch [3/3], Step [121/1349], Loss: 0.0143\n",
            "Epoch [3/3], Step [122/1349], Loss: 0.0632\n",
            "Epoch [3/3], Step [123/1349], Loss: 0.1360\n",
            "Epoch [3/3], Step [124/1349], Loss: 0.0301\n",
            "Epoch [3/3], Step [125/1349], Loss: 0.0373\n",
            "Epoch [3/3], Step [126/1349], Loss: 0.0157\n",
            "Epoch [3/3], Step [127/1349], Loss: 0.1422\n",
            "Epoch [3/3], Step [128/1349], Loss: 0.0662\n",
            "Epoch [3/3], Step [129/1349], Loss: 0.0476\n",
            "Epoch [3/3], Step [130/1349], Loss: 0.0919\n",
            "Epoch [3/3], Step [131/1349], Loss: 0.0242\n",
            "Epoch [3/3], Step [132/1349], Loss: 0.0036\n",
            "Epoch [3/3], Step [133/1349], Loss: 0.0368\n",
            "Epoch [3/3], Step [134/1349], Loss: 0.0425\n",
            "Epoch [3/3], Step [135/1349], Loss: 0.0029\n",
            "Epoch [3/3], Step [136/1349], Loss: 0.0286\n",
            "Epoch [3/3], Step [137/1349], Loss: 0.0551\n",
            "Epoch [3/3], Step [138/1349], Loss: 0.0532\n",
            "Epoch [3/3], Step [139/1349], Loss: 0.0235\n",
            "Epoch [3/3], Step [140/1349], Loss: 0.0057\n",
            "Epoch [3/3], Step [141/1349], Loss: 0.0247\n",
            "Epoch [3/3], Step [142/1349], Loss: 0.1113\n",
            "Epoch [3/3], Step [143/1349], Loss: 0.0116\n",
            "Epoch [3/3], Step [144/1349], Loss: 0.0160\n",
            "Epoch [3/3], Step [145/1349], Loss: 0.0023\n",
            "Epoch [3/3], Step [146/1349], Loss: 0.0028\n",
            "Epoch [3/3], Step [147/1349], Loss: 0.1212\n",
            "Epoch [3/3], Step [148/1349], Loss: 0.0042\n",
            "Epoch [3/3], Step [149/1349], Loss: 0.0224\n",
            "Epoch [3/3], Step [150/1349], Loss: 0.0553\n",
            "Epoch [3/3], Step [151/1349], Loss: 0.0197\n",
            "Epoch [3/3], Step [152/1349], Loss: 0.0725\n",
            "Epoch [3/3], Step [153/1349], Loss: 0.0308\n",
            "Epoch [3/3], Step [154/1349], Loss: 0.0407\n",
            "Epoch [3/3], Step [155/1349], Loss: 0.0763\n",
            "Epoch [3/3], Step [156/1349], Loss: 0.0465\n",
            "Epoch [3/3], Step [157/1349], Loss: 0.0159\n",
            "Epoch [3/3], Step [158/1349], Loss: 0.0904\n",
            "Epoch [3/3], Step [159/1349], Loss: 0.0053\n",
            "Epoch [3/3], Step [160/1349], Loss: 0.0184\n",
            "Epoch [3/3], Step [161/1349], Loss: 0.0099\n",
            "Epoch [3/3], Step [162/1349], Loss: 0.0055\n",
            "Epoch [3/3], Step [163/1349], Loss: 0.0046\n",
            "Epoch [3/3], Step [164/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [165/1349], Loss: 0.1002\n",
            "Epoch [3/3], Step [166/1349], Loss: 0.0017\n",
            "Epoch [3/3], Step [167/1349], Loss: 0.1575\n",
            "Epoch [3/3], Step [168/1349], Loss: 0.2071\n",
            "Epoch [3/3], Step [169/1349], Loss: 0.0816\n",
            "Epoch [3/3], Step [170/1349], Loss: 0.0956\n",
            "Epoch [3/3], Step [171/1349], Loss: 0.0205\n",
            "Epoch [3/3], Step [172/1349], Loss: 0.0280\n",
            "Epoch [3/3], Step [173/1349], Loss: 0.0666\n",
            "Epoch [3/3], Step [174/1349], Loss: 0.3955\n",
            "Epoch [3/3], Step [175/1349], Loss: 0.0295\n",
            "Epoch [3/3], Step [176/1349], Loss: 0.0737\n",
            "Epoch [3/3], Step [177/1349], Loss: 0.0309\n",
            "Epoch [3/3], Step [178/1349], Loss: 0.2465\n",
            "Epoch [3/3], Step [179/1349], Loss: 0.1240\n",
            "Epoch [3/3], Step [180/1349], Loss: 0.0636\n",
            "Epoch [3/3], Step [181/1349], Loss: 0.0456\n",
            "Epoch [3/3], Step [182/1349], Loss: 0.0635\n",
            "Epoch [3/3], Step [183/1349], Loss: 0.0521\n",
            "Epoch [3/3], Step [184/1349], Loss: 0.0772\n",
            "Epoch [3/3], Step [185/1349], Loss: 0.1031\n",
            "Epoch [3/3], Step [186/1349], Loss: 0.0255\n",
            "Epoch [3/3], Step [187/1349], Loss: 0.0139\n",
            "Epoch [3/3], Step [188/1349], Loss: 0.2591\n",
            "Epoch [3/3], Step [189/1349], Loss: 0.1184\n",
            "Epoch [3/3], Step [190/1349], Loss: 0.0593\n",
            "Epoch [3/3], Step [191/1349], Loss: 0.0457\n",
            "Epoch [3/3], Step [192/1349], Loss: 0.1419\n",
            "Epoch [3/3], Step [193/1349], Loss: 0.0433\n",
            "Epoch [3/3], Step [194/1349], Loss: 0.0142\n",
            "Epoch [3/3], Step [195/1349], Loss: 0.1778\n",
            "Epoch [3/3], Step [196/1349], Loss: 0.0277\n",
            "Epoch [3/3], Step [197/1349], Loss: 0.0382\n",
            "Epoch [3/3], Step [198/1349], Loss: 0.0268\n",
            "Epoch [3/3], Step [199/1349], Loss: 0.0045\n",
            "Epoch [3/3], Step [200/1349], Loss: 0.0336\n",
            "Epoch [3/3], Step [201/1349], Loss: 0.0212\n",
            "Epoch [3/3], Step [202/1349], Loss: 0.0964\n",
            "Epoch [3/3], Step [203/1349], Loss: 0.0033\n",
            "Epoch [3/3], Step [204/1349], Loss: 0.0661\n",
            "Epoch [3/3], Step [205/1349], Loss: 0.0286\n",
            "Epoch [3/3], Step [206/1349], Loss: 0.0021\n",
            "Epoch [3/3], Step [207/1349], Loss: 0.1492\n",
            "Epoch [3/3], Step [208/1349], Loss: 0.0597\n",
            "Epoch [3/3], Step [209/1349], Loss: 0.1031\n",
            "Epoch [3/3], Step [210/1349], Loss: 0.0372\n",
            "Epoch [3/3], Step [211/1349], Loss: 0.1106\n",
            "Epoch [3/3], Step [212/1349], Loss: 0.0162\n",
            "Epoch [3/3], Step [213/1349], Loss: 0.0999\n",
            "Epoch [3/3], Step [214/1349], Loss: 0.0790\n",
            "Epoch [3/3], Step [215/1349], Loss: 0.0439\n",
            "Epoch [3/3], Step [216/1349], Loss: 0.1301\n",
            "Epoch [3/3], Step [217/1349], Loss: 0.0371\n",
            "Epoch [3/3], Step [218/1349], Loss: 0.0036\n",
            "Epoch [3/3], Step [219/1349], Loss: 0.0330\n",
            "Epoch [3/3], Step [220/1349], Loss: 0.0216\n",
            "Epoch [3/3], Step [221/1349], Loss: 0.2512\n",
            "Epoch [3/3], Step [222/1349], Loss: 0.0435\n",
            "Epoch [3/3], Step [223/1349], Loss: 0.0179\n",
            "Epoch [3/3], Step [224/1349], Loss: 0.0185\n",
            "Epoch [3/3], Step [225/1349], Loss: 0.0163\n",
            "Epoch [3/3], Step [226/1349], Loss: 0.0164\n",
            "Epoch [3/3], Step [227/1349], Loss: 0.1464\n",
            "Epoch [3/3], Step [228/1349], Loss: 0.0171\n",
            "Epoch [3/3], Step [229/1349], Loss: 0.1531\n",
            "Epoch [3/3], Step [230/1349], Loss: 0.0359\n",
            "Epoch [3/3], Step [231/1349], Loss: 0.0919\n",
            "Epoch [3/3], Step [232/1349], Loss: 0.0101\n",
            "Epoch [3/3], Step [233/1349], Loss: 0.0819\n",
            "Epoch [3/3], Step [234/1349], Loss: 0.0513\n",
            "Epoch [3/3], Step [235/1349], Loss: 0.2054\n",
            "Epoch [3/3], Step [236/1349], Loss: 0.0416\n",
            "Epoch [3/3], Step [237/1349], Loss: 0.0073\n",
            "Epoch [3/3], Step [238/1349], Loss: 0.0664\n",
            "Epoch [3/3], Step [239/1349], Loss: 0.0255\n",
            "Epoch [3/3], Step [240/1349], Loss: 0.0472\n",
            "Epoch [3/3], Step [241/1349], Loss: 0.0524\n",
            "Epoch [3/3], Step [242/1349], Loss: 0.0323\n",
            "Epoch [3/3], Step [243/1349], Loss: 0.0066\n",
            "Epoch [3/3], Step [244/1349], Loss: 0.0912\n",
            "Epoch [3/3], Step [245/1349], Loss: 0.0503\n",
            "Epoch [3/3], Step [246/1349], Loss: 0.0900\n",
            "Epoch [3/3], Step [247/1349], Loss: 0.0914\n",
            "Epoch [3/3], Step [248/1349], Loss: 0.1670\n",
            "Epoch [3/3], Step [249/1349], Loss: 0.0918\n",
            "Epoch [3/3], Step [250/1349], Loss: 0.0100\n",
            "Epoch [3/3], Step [251/1349], Loss: 0.0457\n",
            "Epoch [3/3], Step [252/1349], Loss: 0.0513\n",
            "Epoch [3/3], Step [253/1349], Loss: 0.3218\n",
            "Epoch [3/3], Step [254/1349], Loss: 0.0822\n",
            "Epoch [3/3], Step [255/1349], Loss: 0.0123\n",
            "Epoch [3/3], Step [256/1349], Loss: 0.1098\n",
            "Epoch [3/3], Step [257/1349], Loss: 0.0397\n",
            "Epoch [3/3], Step [258/1349], Loss: 0.0187\n",
            "Epoch [3/3], Step [259/1349], Loss: 0.0341\n",
            "Epoch [3/3], Step [260/1349], Loss: 0.0161\n",
            "Epoch [3/3], Step [261/1349], Loss: 0.0178\n",
            "Epoch [3/3], Step [262/1349], Loss: 0.0761\n",
            "Epoch [3/3], Step [263/1349], Loss: 0.0923\n",
            "Epoch [3/3], Step [264/1349], Loss: 0.0208\n",
            "Epoch [3/3], Step [265/1349], Loss: 0.0627\n",
            "Epoch [3/3], Step [266/1349], Loss: 0.1114\n",
            "Epoch [3/3], Step [267/1349], Loss: 0.0501\n",
            "Epoch [3/3], Step [268/1349], Loss: 0.0923\n",
            "Epoch [3/3], Step [269/1349], Loss: 0.0368\n",
            "Epoch [3/3], Step [270/1349], Loss: 0.0046\n",
            "Epoch [3/3], Step [271/1349], Loss: 0.0278\n",
            "Epoch [3/3], Step [272/1349], Loss: 0.1852\n",
            "Epoch [3/3], Step [273/1349], Loss: 0.0173\n",
            "Epoch [3/3], Step [274/1349], Loss: 0.0714\n",
            "Epoch [3/3], Step [275/1349], Loss: 0.0785\n",
            "Epoch [3/3], Step [276/1349], Loss: 0.0204\n",
            "Epoch [3/3], Step [277/1349], Loss: 0.0106\n",
            "Epoch [3/3], Step [278/1349], Loss: 0.0427\n",
            "Epoch [3/3], Step [279/1349], Loss: 0.0757\n",
            "Epoch [3/3], Step [280/1349], Loss: 0.0367\n",
            "Epoch [3/3], Step [281/1349], Loss: 0.0193\n",
            "Epoch [3/3], Step [282/1349], Loss: 0.0536\n",
            "Epoch [3/3], Step [283/1349], Loss: 0.0921\n",
            "Epoch [3/3], Step [284/1349], Loss: 0.1538\n",
            "Epoch [3/3], Step [285/1349], Loss: 0.1626\n",
            "Epoch [3/3], Step [286/1349], Loss: 0.0658\n",
            "Epoch [3/3], Step [287/1349], Loss: 0.0597\n",
            "Epoch [3/3], Step [288/1349], Loss: 0.0762\n",
            "Epoch [3/3], Step [289/1349], Loss: 0.0665\n",
            "Epoch [3/3], Step [290/1349], Loss: 0.0664\n",
            "Epoch [3/3], Step [291/1349], Loss: 0.1136\n",
            "Epoch [3/3], Step [292/1349], Loss: 0.0446\n",
            "Epoch [3/3], Step [293/1349], Loss: 0.0902\n",
            "Epoch [3/3], Step [294/1349], Loss: 0.0543\n",
            "Epoch [3/3], Step [295/1349], Loss: 0.0426\n",
            "Epoch [3/3], Step [296/1349], Loss: 0.0233\n",
            "Epoch [3/3], Step [297/1349], Loss: 0.0333\n",
            "Epoch [3/3], Step [298/1349], Loss: 0.0615\n",
            "Epoch [3/3], Step [299/1349], Loss: 0.1070\n",
            "Epoch [3/3], Step [300/1349], Loss: 0.0167\n",
            "Epoch [3/3], Step [301/1349], Loss: 0.0294\n",
            "Epoch [3/3], Step [302/1349], Loss: 0.1744\n",
            "Epoch [3/3], Step [303/1349], Loss: 0.1073\n",
            "Epoch [3/3], Step [304/1349], Loss: 0.0206\n",
            "Epoch [3/3], Step [305/1349], Loss: 0.1147\n",
            "Epoch [3/3], Step [306/1349], Loss: 0.0048\n",
            "Epoch [3/3], Step [307/1349], Loss: 0.0308\n",
            "Epoch [3/3], Step [308/1349], Loss: 0.0886\n",
            "Epoch [3/3], Step [309/1349], Loss: 0.0053\n",
            "Epoch [3/3], Step [310/1349], Loss: 0.0742\n",
            "Epoch [3/3], Step [311/1349], Loss: 0.0365\n",
            "Epoch [3/3], Step [312/1349], Loss: 0.0411\n",
            "Epoch [3/3], Step [313/1349], Loss: 0.0399\n",
            "Epoch [3/3], Step [314/1349], Loss: 0.0345\n",
            "Epoch [3/3], Step [315/1349], Loss: 0.0327\n",
            "Epoch [3/3], Step [316/1349], Loss: 0.0144\n",
            "Epoch [3/3], Step [317/1349], Loss: 0.0733\n",
            "Epoch [3/3], Step [318/1349], Loss: 0.1349\n",
            "Epoch [3/3], Step [319/1349], Loss: 0.0080\n",
            "Epoch [3/3], Step [320/1349], Loss: 0.0295\n",
            "Epoch [3/3], Step [321/1349], Loss: 0.0852\n",
            "Epoch [3/3], Step [322/1349], Loss: 0.0222\n",
            "Epoch [3/3], Step [323/1349], Loss: 0.0213\n",
            "Epoch [3/3], Step [324/1349], Loss: 0.0783\n",
            "Epoch [3/3], Step [325/1349], Loss: 0.0079\n",
            "Epoch [3/3], Step [326/1349], Loss: 0.1578\n",
            "Epoch [3/3], Step [327/1349], Loss: 0.0356\n",
            "Epoch [3/3], Step [328/1349], Loss: 0.0790\n",
            "Epoch [3/3], Step [329/1349], Loss: 0.2844\n",
            "Epoch [3/3], Step [330/1349], Loss: 0.0124\n",
            "Epoch [3/3], Step [331/1349], Loss: 0.0674\n",
            "Epoch [3/3], Step [332/1349], Loss: 0.0677\n",
            "Epoch [3/3], Step [333/1349], Loss: 0.0038\n",
            "Epoch [3/3], Step [334/1349], Loss: 0.0182\n",
            "Epoch [3/3], Step [335/1349], Loss: 0.0584\n",
            "Epoch [3/3], Step [336/1349], Loss: 0.0080\n",
            "Epoch [3/3], Step [337/1349], Loss: 0.0524\n",
            "Epoch [3/3], Step [338/1349], Loss: 0.0421\n",
            "Epoch [3/3], Step [339/1349], Loss: 0.0446\n",
            "Epoch [3/3], Step [340/1349], Loss: 0.0492\n",
            "Epoch [3/3], Step [341/1349], Loss: 0.0079\n",
            "Epoch [3/3], Step [342/1349], Loss: 0.0348\n",
            "Epoch [3/3], Step [343/1349], Loss: 0.1356\n",
            "Epoch [3/3], Step [344/1349], Loss: 0.0355\n",
            "Epoch [3/3], Step [345/1349], Loss: 0.0247\n",
            "Epoch [3/3], Step [346/1349], Loss: 0.0210\n",
            "Epoch [3/3], Step [347/1349], Loss: 0.0644\n",
            "Epoch [3/3], Step [348/1349], Loss: 0.1148\n",
            "Epoch [3/3], Step [349/1349], Loss: 0.0206\n",
            "Epoch [3/3], Step [350/1349], Loss: 0.1361\n",
            "Epoch [3/3], Step [351/1349], Loss: 0.0281\n",
            "Epoch [3/3], Step [352/1349], Loss: 0.0552\n",
            "Epoch [3/3], Step [353/1349], Loss: 0.0919\n",
            "Epoch [3/3], Step [354/1349], Loss: 0.0036\n",
            "Epoch [3/3], Step [355/1349], Loss: 0.1149\n",
            "Epoch [3/3], Step [356/1349], Loss: 0.0322\n",
            "Epoch [3/3], Step [357/1349], Loss: 0.0121\n",
            "Epoch [3/3], Step [358/1349], Loss: 0.2228\n",
            "Epoch [3/3], Step [359/1349], Loss: 0.3742\n",
            "Epoch [3/3], Step [360/1349], Loss: 0.1463\n",
            "Epoch [3/3], Step [361/1349], Loss: 0.0070\n",
            "Epoch [3/3], Step [362/1349], Loss: 0.0221\n",
            "Epoch [3/3], Step [363/1349], Loss: 0.0173\n",
            "Epoch [3/3], Step [364/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [365/1349], Loss: 0.0461\n",
            "Epoch [3/3], Step [366/1349], Loss: 0.0056\n",
            "Epoch [3/3], Step [367/1349], Loss: 0.0227\n",
            "Epoch [3/3], Step [368/1349], Loss: 0.1119\n",
            "Epoch [3/3], Step [369/1349], Loss: 0.0254\n",
            "Epoch [3/3], Step [370/1349], Loss: 0.1630\n",
            "Epoch [3/3], Step [371/1349], Loss: 0.0231\n",
            "Epoch [3/3], Step [372/1349], Loss: 0.0532\n",
            "Epoch [3/3], Step [373/1349], Loss: 0.0371\n",
            "Epoch [3/3], Step [374/1349], Loss: 0.0056\n",
            "Epoch [3/3], Step [375/1349], Loss: 0.0703\n",
            "Epoch [3/3], Step [376/1349], Loss: 0.0261\n",
            "Epoch [3/3], Step [377/1349], Loss: 0.0159\n",
            "Epoch [3/3], Step [378/1349], Loss: 0.0486\n",
            "Epoch [3/3], Step [379/1349], Loss: 0.0048\n",
            "Epoch [3/3], Step [380/1349], Loss: 0.0652\n",
            "Epoch [3/3], Step [381/1349], Loss: 0.0189\n",
            "Epoch [3/3], Step [382/1349], Loss: 0.1022\n",
            "Epoch [3/3], Step [383/1349], Loss: 0.0468\n",
            "Epoch [3/3], Step [384/1349], Loss: 0.0491\n",
            "Epoch [3/3], Step [385/1349], Loss: 0.1886\n",
            "Epoch [3/3], Step [386/1349], Loss: 0.0849\n",
            "Epoch [3/3], Step [387/1349], Loss: 0.2436\n",
            "Epoch [3/3], Step [388/1349], Loss: 0.1439\n",
            "Epoch [3/3], Step [389/1349], Loss: 0.0147\n",
            "Epoch [3/3], Step [390/1349], Loss: 0.0585\n",
            "Epoch [3/3], Step [391/1349], Loss: 0.0186\n",
            "Epoch [3/3], Step [392/1349], Loss: 0.0367\n",
            "Epoch [3/3], Step [393/1349], Loss: 0.0474\n",
            "Epoch [3/3], Step [394/1349], Loss: 0.1597\n",
            "Epoch [3/3], Step [395/1349], Loss: 0.0368\n",
            "Epoch [3/3], Step [396/1349], Loss: 0.0128\n",
            "Epoch [3/3], Step [397/1349], Loss: 0.0524\n",
            "Epoch [3/3], Step [398/1349], Loss: 0.0265\n",
            "Epoch [3/3], Step [399/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [400/1349], Loss: 0.0336\n",
            "Epoch [3/3], Step [401/1349], Loss: 0.0103\n",
            "Epoch [3/3], Step [402/1349], Loss: 0.0250\n",
            "Epoch [3/3], Step [403/1349], Loss: 0.0475\n",
            "Epoch [3/3], Step [404/1349], Loss: 0.0641\n",
            "Epoch [3/3], Step [405/1349], Loss: 0.0214\n",
            "Epoch [3/3], Step [406/1349], Loss: 0.0300\n",
            "Epoch [3/3], Step [407/1349], Loss: 0.0518\n",
            "Epoch [3/3], Step [408/1349], Loss: 0.1984\n",
            "Epoch [3/3], Step [409/1349], Loss: 0.0189\n",
            "Epoch [3/3], Step [410/1349], Loss: 0.1348\n",
            "Epoch [3/3], Step [411/1349], Loss: 0.1509\n",
            "Epoch [3/3], Step [412/1349], Loss: 0.0941\n",
            "Epoch [3/3], Step [413/1349], Loss: 0.1253\n",
            "Epoch [3/3], Step [414/1349], Loss: 0.0090\n",
            "Epoch [3/3], Step [415/1349], Loss: 0.1215\n",
            "Epoch [3/3], Step [416/1349], Loss: 0.0569\n",
            "Epoch [3/3], Step [417/1349], Loss: 0.0708\n",
            "Epoch [3/3], Step [418/1349], Loss: 0.0305\n",
            "Epoch [3/3], Step [419/1349], Loss: 0.1286\n",
            "Epoch [3/3], Step [420/1349], Loss: 0.1499\n",
            "Epoch [3/3], Step [421/1349], Loss: 0.0507\n",
            "Epoch [3/3], Step [422/1349], Loss: 0.0058\n",
            "Epoch [3/3], Step [423/1349], Loss: 0.3132\n",
            "Epoch [3/3], Step [424/1349], Loss: 0.0392\n",
            "Epoch [3/3], Step [425/1349], Loss: 0.0723\n",
            "Epoch [3/3], Step [426/1349], Loss: 0.0551\n",
            "Epoch [3/3], Step [427/1349], Loss: 0.0528\n",
            "Epoch [3/3], Step [428/1349], Loss: 0.2537\n",
            "Epoch [3/3], Step [429/1349], Loss: 0.0615\n",
            "Epoch [3/3], Step [430/1349], Loss: 0.1635\n",
            "Epoch [3/3], Step [431/1349], Loss: 0.0295\n",
            "Epoch [3/3], Step [432/1349], Loss: 0.1781\n",
            "Epoch [3/3], Step [433/1349], Loss: 0.0163\n",
            "Epoch [3/3], Step [434/1349], Loss: 0.0364\n",
            "Epoch [3/3], Step [435/1349], Loss: 0.0956\n",
            "Epoch [3/3], Step [436/1349], Loss: 0.0994\n",
            "Epoch [3/3], Step [437/1349], Loss: 0.0807\n",
            "Epoch [3/3], Step [438/1349], Loss: 0.1599\n",
            "Epoch [3/3], Step [439/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [440/1349], Loss: 0.0327\n",
            "Epoch [3/3], Step [441/1349], Loss: 0.0926\n",
            "Epoch [3/3], Step [442/1349], Loss: 0.0722\n",
            "Epoch [3/3], Step [443/1349], Loss: 0.0799\n",
            "Epoch [3/3], Step [444/1349], Loss: 0.0685\n",
            "Epoch [3/3], Step [445/1349], Loss: 0.0317\n",
            "Epoch [3/3], Step [446/1349], Loss: 0.0324\n",
            "Epoch [3/3], Step [447/1349], Loss: 0.0650\n",
            "Epoch [3/3], Step [448/1349], Loss: 0.0341\n",
            "Epoch [3/3], Step [449/1349], Loss: 0.0837\n",
            "Epoch [3/3], Step [450/1349], Loss: 0.0434\n",
            "Epoch [3/3], Step [451/1349], Loss: 0.0735\n",
            "Epoch [3/3], Step [452/1349], Loss: 0.0802\n",
            "Epoch [3/3], Step [453/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [454/1349], Loss: 0.1171\n",
            "Epoch [3/3], Step [455/1349], Loss: 0.0365\n",
            "Epoch [3/3], Step [456/1349], Loss: 0.1447\n",
            "Epoch [3/3], Step [457/1349], Loss: 0.0589\n",
            "Epoch [3/3], Step [458/1349], Loss: 0.0333\n",
            "Epoch [3/3], Step [459/1349], Loss: 0.0443\n",
            "Epoch [3/3], Step [460/1349], Loss: 0.0401\n",
            "Epoch [3/3], Step [461/1349], Loss: 0.0412\n",
            "Epoch [3/3], Step [462/1349], Loss: 0.0215\n",
            "Epoch [3/3], Step [463/1349], Loss: 0.0256\n",
            "Epoch [3/3], Step [464/1349], Loss: 0.0191\n",
            "Epoch [3/3], Step [465/1349], Loss: 0.1260\n",
            "Epoch [3/3], Step [466/1349], Loss: 0.0506\n",
            "Epoch [3/3], Step [467/1349], Loss: 0.0116\n",
            "Epoch [3/3], Step [468/1349], Loss: 0.1140\n",
            "Epoch [3/3], Step [469/1349], Loss: 0.0586\n",
            "Epoch [3/3], Step [470/1349], Loss: 0.1352\n",
            "Epoch [3/3], Step [471/1349], Loss: 0.0199\n",
            "Epoch [3/3], Step [472/1349], Loss: 0.0952\n",
            "Epoch [3/3], Step [473/1349], Loss: 0.0289\n",
            "Epoch [3/3], Step [474/1349], Loss: 0.0190\n",
            "Epoch [3/3], Step [475/1349], Loss: 0.0151\n",
            "Epoch [3/3], Step [476/1349], Loss: 0.1718\n",
            "Epoch [3/3], Step [477/1349], Loss: 0.0341\n",
            "Epoch [3/3], Step [478/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [479/1349], Loss: 0.0289\n",
            "Epoch [3/3], Step [480/1349], Loss: 0.0339\n",
            "Epoch [3/3], Step [481/1349], Loss: 0.0491\n",
            "Epoch [3/3], Step [482/1349], Loss: 0.0264\n",
            "Epoch [3/3], Step [483/1349], Loss: 0.0580\n",
            "Epoch [3/3], Step [484/1349], Loss: 0.0510\n",
            "Epoch [3/3], Step [485/1349], Loss: 0.1130\n",
            "Epoch [3/3], Step [486/1349], Loss: 0.0152\n",
            "Epoch [3/3], Step [487/1349], Loss: 0.2242\n",
            "Epoch [3/3], Step [488/1349], Loss: 0.0146\n",
            "Epoch [3/3], Step [489/1349], Loss: 0.0850\n",
            "Epoch [3/3], Step [490/1349], Loss: 0.0527\n",
            "Epoch [3/3], Step [491/1349], Loss: 0.0332\n",
            "Epoch [3/3], Step [492/1349], Loss: 0.0023\n",
            "Epoch [3/3], Step [493/1349], Loss: 0.1154\n",
            "Epoch [3/3], Step [494/1349], Loss: 0.0438\n",
            "Epoch [3/3], Step [495/1349], Loss: 0.0326\n",
            "Epoch [3/3], Step [496/1349], Loss: 0.1508\n",
            "Epoch [3/3], Step [497/1349], Loss: 0.0710\n",
            "Epoch [3/3], Step [498/1349], Loss: 0.1369\n",
            "Epoch [3/3], Step [499/1349], Loss: 0.0033\n",
            "Epoch [3/3], Step [500/1349], Loss: 0.0880\n",
            "Epoch [3/3], Step [501/1349], Loss: 0.0080\n",
            "Epoch [3/3], Step [502/1349], Loss: 0.0104\n",
            "Epoch [3/3], Step [503/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [504/1349], Loss: 0.0669\n",
            "Epoch [3/3], Step [505/1349], Loss: 0.0142\n",
            "Epoch [3/3], Step [506/1349], Loss: 0.0147\n",
            "Epoch [3/3], Step [507/1349], Loss: 0.2059\n",
            "Epoch [3/3], Step [508/1349], Loss: 0.0225\n",
            "Epoch [3/3], Step [509/1349], Loss: 0.0215\n",
            "Epoch [3/3], Step [510/1349], Loss: 0.1512\n",
            "Epoch [3/3], Step [511/1349], Loss: 0.0821\n",
            "Epoch [3/3], Step [512/1349], Loss: 0.1219\n",
            "Epoch [3/3], Step [513/1349], Loss: 0.0073\n",
            "Epoch [3/3], Step [514/1349], Loss: 0.1688\n",
            "Epoch [3/3], Step [515/1349], Loss: 0.0525\n",
            "Epoch [3/3], Step [516/1349], Loss: 0.0657\n",
            "Epoch [3/3], Step [517/1349], Loss: 0.1523\n",
            "Epoch [3/3], Step [518/1349], Loss: 0.0129\n",
            "Epoch [3/3], Step [519/1349], Loss: 0.0185\n",
            "Epoch [3/3], Step [520/1349], Loss: 0.0700\n",
            "Epoch [3/3], Step [521/1349], Loss: 0.0428\n",
            "Epoch [3/3], Step [522/1349], Loss: 0.0116\n",
            "Epoch [3/3], Step [523/1349], Loss: 0.0478\n",
            "Epoch [3/3], Step [524/1349], Loss: 0.1142\n",
            "Epoch [3/3], Step [525/1349], Loss: 0.0191\n",
            "Epoch [3/3], Step [526/1349], Loss: 0.0565\n",
            "Epoch [3/3], Step [527/1349], Loss: 0.0138\n",
            "Epoch [3/3], Step [528/1349], Loss: 0.0107\n",
            "Epoch [3/3], Step [529/1349], Loss: 0.1662\n",
            "Epoch [3/3], Step [530/1349], Loss: 0.0589\n",
            "Epoch [3/3], Step [531/1349], Loss: 0.0376\n",
            "Epoch [3/3], Step [532/1349], Loss: 0.1042\n",
            "Epoch [3/3], Step [533/1349], Loss: 0.0613\n",
            "Epoch [3/3], Step [534/1349], Loss: 0.0235\n",
            "Epoch [3/3], Step [535/1349], Loss: 0.0411\n",
            "Epoch [3/3], Step [536/1349], Loss: 0.0450\n",
            "Epoch [3/3], Step [537/1349], Loss: 0.0357\n",
            "Epoch [3/3], Step [538/1349], Loss: 0.1091\n",
            "Epoch [3/3], Step [539/1349], Loss: 0.2194\n",
            "Epoch [3/3], Step [540/1349], Loss: 0.0699\n",
            "Epoch [3/3], Step [541/1349], Loss: 0.0803\n",
            "Epoch [3/3], Step [542/1349], Loss: 0.2389\n",
            "Epoch [3/3], Step [543/1349], Loss: 0.0246\n",
            "Epoch [3/3], Step [544/1349], Loss: 0.0472\n",
            "Epoch [3/3], Step [545/1349], Loss: 0.1686\n",
            "Epoch [3/3], Step [546/1349], Loss: 0.0292\n",
            "Epoch [3/3], Step [547/1349], Loss: 0.0144\n",
            "Epoch [3/3], Step [548/1349], Loss: 0.0104\n",
            "Epoch [3/3], Step [549/1349], Loss: 0.1038\n",
            "Epoch [3/3], Step [550/1349], Loss: 0.0183\n",
            "Epoch [3/3], Step [551/1349], Loss: 0.1440\n",
            "Epoch [3/3], Step [552/1349], Loss: 0.0383\n",
            "Epoch [3/3], Step [553/1349], Loss: 0.0099\n",
            "Epoch [3/3], Step [554/1349], Loss: 0.0522\n",
            "Epoch [3/3], Step [555/1349], Loss: 0.0427\n",
            "Epoch [3/3], Step [556/1349], Loss: 0.0375\n",
            "Epoch [3/3], Step [557/1349], Loss: 0.0370\n",
            "Epoch [3/3], Step [558/1349], Loss: 0.0025\n",
            "Epoch [3/3], Step [559/1349], Loss: 0.0961\n",
            "Epoch [3/3], Step [560/1349], Loss: 0.0677\n",
            "Epoch [3/3], Step [561/1349], Loss: 0.0801\n",
            "Epoch [3/3], Step [562/1349], Loss: 0.0693\n",
            "Epoch [3/3], Step [563/1349], Loss: 0.1358\n",
            "Epoch [3/3], Step [564/1349], Loss: 0.0603\n",
            "Epoch [3/3], Step [565/1349], Loss: 0.0040\n",
            "Epoch [3/3], Step [566/1349], Loss: 0.0141\n",
            "Epoch [3/3], Step [567/1349], Loss: 0.0124\n",
            "Epoch [3/3], Step [568/1349], Loss: 0.0071\n",
            "Epoch [3/3], Step [569/1349], Loss: 0.0373\n",
            "Epoch [3/3], Step [570/1349], Loss: 0.0104\n",
            "Epoch [3/3], Step [571/1349], Loss: 0.0677\n",
            "Epoch [3/3], Step [572/1349], Loss: 0.0433\n",
            "Epoch [3/3], Step [573/1349], Loss: 0.0482\n",
            "Epoch [3/3], Step [574/1349], Loss: 0.0528\n",
            "Epoch [3/3], Step [575/1349], Loss: 0.0463\n",
            "Epoch [3/3], Step [576/1349], Loss: 0.0396\n",
            "Epoch [3/3], Step [577/1349], Loss: 0.0155\n",
            "Epoch [3/3], Step [578/1349], Loss: 0.1169\n",
            "Epoch [3/3], Step [579/1349], Loss: 0.0616\n",
            "Epoch [3/3], Step [580/1349], Loss: 0.1202\n",
            "Epoch [3/3], Step [581/1349], Loss: 0.0044\n",
            "Epoch [3/3], Step [582/1349], Loss: 0.0066\n",
            "Epoch [3/3], Step [583/1349], Loss: 0.0243\n",
            "Epoch [3/3], Step [584/1349], Loss: 0.0474\n",
            "Epoch [3/3], Step [585/1349], Loss: 0.0009\n",
            "Epoch [3/3], Step [586/1349], Loss: 0.1503\n",
            "Epoch [3/3], Step [587/1349], Loss: 0.1421\n",
            "Epoch [3/3], Step [588/1349], Loss: 0.0463\n",
            "Epoch [3/3], Step [589/1349], Loss: 0.0920\n",
            "Epoch [3/3], Step [590/1349], Loss: 0.0697\n",
            "Epoch [3/3], Step [591/1349], Loss: 0.2454\n",
            "Epoch [3/3], Step [592/1349], Loss: 0.0218\n",
            "Epoch [3/3], Step [593/1349], Loss: 0.0356\n",
            "Epoch [3/3], Step [594/1349], Loss: 0.0124\n",
            "Epoch [3/3], Step [595/1349], Loss: 0.0035\n",
            "Epoch [3/3], Step [596/1349], Loss: 0.0314\n",
            "Epoch [3/3], Step [597/1349], Loss: 0.0937\n",
            "Epoch [3/3], Step [598/1349], Loss: 0.0150\n",
            "Epoch [3/3], Step [599/1349], Loss: 0.0179\n",
            "Epoch [3/3], Step [600/1349], Loss: 0.0708\n",
            "Epoch [3/3], Step [601/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [602/1349], Loss: 0.0012\n",
            "Epoch [3/3], Step [603/1349], Loss: 0.0282\n",
            "Epoch [3/3], Step [604/1349], Loss: 0.0155\n",
            "Epoch [3/3], Step [605/1349], Loss: 0.3857\n",
            "Epoch [3/3], Step [606/1349], Loss: 0.0290\n",
            "Epoch [3/3], Step [607/1349], Loss: 0.0804\n",
            "Epoch [3/3], Step [608/1349], Loss: 0.1346\n",
            "Epoch [3/3], Step [609/1349], Loss: 0.0160\n",
            "Epoch [3/3], Step [610/1349], Loss: 0.0029\n",
            "Epoch [3/3], Step [611/1349], Loss: 0.2227\n",
            "Epoch [3/3], Step [612/1349], Loss: 0.1160\n",
            "Epoch [3/3], Step [613/1349], Loss: 0.0880\n",
            "Epoch [3/3], Step [614/1349], Loss: 0.0444\n",
            "Epoch [3/3], Step [615/1349], Loss: 0.0061\n",
            "Epoch [3/3], Step [616/1349], Loss: 0.0265\n",
            "Epoch [3/3], Step [617/1349], Loss: 0.0293\n",
            "Epoch [3/3], Step [618/1349], Loss: 0.0108\n",
            "Epoch [3/3], Step [619/1349], Loss: 0.0893\n",
            "Epoch [3/3], Step [620/1349], Loss: 0.0786\n",
            "Epoch [3/3], Step [621/1349], Loss: 0.0849\n",
            "Epoch [3/3], Step [622/1349], Loss: 0.0546\n",
            "Epoch [3/3], Step [623/1349], Loss: 0.0138\n",
            "Epoch [3/3], Step [624/1349], Loss: 0.1166\n",
            "Epoch [3/3], Step [625/1349], Loss: 0.0521\n",
            "Epoch [3/3], Step [626/1349], Loss: 0.0144\n",
            "Epoch [3/3], Step [627/1349], Loss: 0.0285\n",
            "Epoch [3/3], Step [628/1349], Loss: 0.0935\n",
            "Epoch [3/3], Step [629/1349], Loss: 0.0058\n",
            "Epoch [3/3], Step [630/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [631/1349], Loss: 0.0498\n",
            "Epoch [3/3], Step [632/1349], Loss: 0.0306\n",
            "Epoch [3/3], Step [633/1349], Loss: 0.0243\n",
            "Epoch [3/3], Step [634/1349], Loss: 0.0179\n",
            "Epoch [3/3], Step [635/1349], Loss: 0.0629\n",
            "Epoch [3/3], Step [636/1349], Loss: 0.0463\n",
            "Epoch [3/3], Step [637/1349], Loss: 0.0166\n",
            "Epoch [3/3], Step [638/1349], Loss: 0.0444\n",
            "Epoch [3/3], Step [639/1349], Loss: 0.1069\n",
            "Epoch [3/3], Step [640/1349], Loss: 0.0317\n",
            "Epoch [3/3], Step [641/1349], Loss: 0.0144\n",
            "Epoch [3/3], Step [642/1349], Loss: 0.0383\n",
            "Epoch [3/3], Step [643/1349], Loss: 0.0352\n",
            "Epoch [3/3], Step [644/1349], Loss: 0.0504\n",
            "Epoch [3/3], Step [645/1349], Loss: 0.1365\n",
            "Epoch [3/3], Step [646/1349], Loss: 0.0073\n",
            "Epoch [3/3], Step [647/1349], Loss: 0.0234\n",
            "Epoch [3/3], Step [648/1349], Loss: 0.0019\n",
            "Epoch [3/3], Step [649/1349], Loss: 0.1960\n",
            "Epoch [3/3], Step [650/1349], Loss: 0.0565\n",
            "Epoch [3/3], Step [651/1349], Loss: 0.1316\n",
            "Epoch [3/3], Step [652/1349], Loss: 0.0746\n",
            "Epoch [3/3], Step [653/1349], Loss: 0.0246\n",
            "Epoch [3/3], Step [654/1349], Loss: 0.0115\n",
            "Epoch [3/3], Step [655/1349], Loss: 0.0093\n",
            "Epoch [3/3], Step [656/1349], Loss: 0.1869\n",
            "Epoch [3/3], Step [657/1349], Loss: 0.0327\n",
            "Epoch [3/3], Step [658/1349], Loss: 0.0076\n",
            "Epoch [3/3], Step [659/1349], Loss: 0.0522\n",
            "Epoch [3/3], Step [660/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [661/1349], Loss: 0.0372\n",
            "Epoch [3/3], Step [662/1349], Loss: 0.0512\n",
            "Epoch [3/3], Step [663/1349], Loss: 0.0116\n",
            "Epoch [3/3], Step [664/1349], Loss: 0.0224\n",
            "Epoch [3/3], Step [665/1349], Loss: 0.0024\n",
            "Epoch [3/3], Step [666/1349], Loss: 0.0100\n",
            "Epoch [3/3], Step [667/1349], Loss: 0.0466\n",
            "Epoch [3/3], Step [668/1349], Loss: 0.0933\n",
            "Epoch [3/3], Step [669/1349], Loss: 0.1325\n",
            "Epoch [3/3], Step [670/1349], Loss: 0.0311\n",
            "Epoch [3/3], Step [671/1349], Loss: 0.0082\n",
            "Epoch [3/3], Step [672/1349], Loss: 0.0020\n",
            "Epoch [3/3], Step [673/1349], Loss: 0.0385\n",
            "Epoch [3/3], Step [674/1349], Loss: 0.0808\n",
            "Epoch [3/3], Step [675/1349], Loss: 0.0441\n",
            "Epoch [3/3], Step [676/1349], Loss: 0.0238\n",
            "Epoch [3/3], Step [677/1349], Loss: 0.1182\n",
            "Epoch [3/3], Step [678/1349], Loss: 0.1747\n",
            "Epoch [3/3], Step [679/1349], Loss: 0.0915\n",
            "Epoch [3/3], Step [680/1349], Loss: 0.0454\n",
            "Epoch [3/3], Step [681/1349], Loss: 0.0056\n",
            "Epoch [3/3], Step [682/1349], Loss: 0.0600\n",
            "Epoch [3/3], Step [683/1349], Loss: 0.0138\n",
            "Epoch [3/3], Step [684/1349], Loss: 0.1263\n",
            "Epoch [3/3], Step [685/1349], Loss: 0.0611\n",
            "Epoch [3/3], Step [686/1349], Loss: 0.0278\n",
            "Epoch [3/3], Step [687/1349], Loss: 0.0170\n",
            "Epoch [3/3], Step [688/1349], Loss: 0.1005\n",
            "Epoch [3/3], Step [689/1349], Loss: 0.0206\n",
            "Epoch [3/3], Step [690/1349], Loss: 0.0339\n",
            "Epoch [3/3], Step [691/1349], Loss: 0.0270\n",
            "Epoch [3/3], Step [692/1349], Loss: 0.0410\n",
            "Epoch [3/3], Step [693/1349], Loss: 0.0316\n",
            "Epoch [3/3], Step [694/1349], Loss: 0.0536\n",
            "Epoch [3/3], Step [695/1349], Loss: 0.0080\n",
            "Epoch [3/3], Step [696/1349], Loss: 0.0318\n",
            "Epoch [3/3], Step [697/1349], Loss: 0.0366\n",
            "Epoch [3/3], Step [698/1349], Loss: 0.1145\n",
            "Epoch [3/3], Step [699/1349], Loss: 0.1557\n",
            "Epoch [3/3], Step [700/1349], Loss: 0.0028\n",
            "Epoch [3/3], Step [701/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [702/1349], Loss: 0.0741\n",
            "Epoch [3/3], Step [703/1349], Loss: 0.0250\n",
            "Epoch [3/3], Step [704/1349], Loss: 0.0477\n",
            "Epoch [3/3], Step [705/1349], Loss: 0.1179\n",
            "Epoch [3/3], Step [706/1349], Loss: 0.0734\n",
            "Epoch [3/3], Step [707/1349], Loss: 0.0968\n",
            "Epoch [3/3], Step [708/1349], Loss: 0.0226\n",
            "Epoch [3/3], Step [709/1349], Loss: 0.2607\n",
            "Epoch [3/3], Step [710/1349], Loss: 0.0243\n",
            "Epoch [3/3], Step [711/1349], Loss: 0.1600\n",
            "Epoch [3/3], Step [712/1349], Loss: 0.0961\n",
            "Epoch [3/3], Step [713/1349], Loss: 0.0426\n",
            "Epoch [3/3], Step [714/1349], Loss: 0.1393\n",
            "Epoch [3/3], Step [715/1349], Loss: 0.1372\n",
            "Epoch [3/3], Step [716/1349], Loss: 0.0521\n",
            "Epoch [3/3], Step [717/1349], Loss: 0.0089\n",
            "Epoch [3/3], Step [718/1349], Loss: 0.0136\n",
            "Epoch [3/3], Step [719/1349], Loss: 0.2310\n",
            "Epoch [3/3], Step [720/1349], Loss: 0.1805\n",
            "Epoch [3/3], Step [721/1349], Loss: 0.1616\n",
            "Epoch [3/3], Step [722/1349], Loss: 0.1426\n",
            "Epoch [3/3], Step [723/1349], Loss: 0.0514\n",
            "Epoch [3/3], Step [724/1349], Loss: 0.0305\n",
            "Epoch [3/3], Step [725/1349], Loss: 0.0637\n",
            "Epoch [3/3], Step [726/1349], Loss: 0.1058\n",
            "Epoch [3/3], Step [727/1349], Loss: 0.0580\n",
            "Epoch [3/3], Step [728/1349], Loss: 0.0585\n",
            "Epoch [3/3], Step [729/1349], Loss: 0.1038\n",
            "Epoch [3/3], Step [730/1349], Loss: 0.0320\n",
            "Epoch [3/3], Step [731/1349], Loss: 0.2209\n",
            "Epoch [3/3], Step [732/1349], Loss: 0.0015\n",
            "Epoch [3/3], Step [733/1349], Loss: 0.0155\n",
            "Epoch [3/3], Step [734/1349], Loss: 0.0174\n",
            "Epoch [3/3], Step [735/1349], Loss: 0.1530\n",
            "Epoch [3/3], Step [736/1349], Loss: 0.1693\n",
            "Epoch [3/3], Step [737/1349], Loss: 0.0150\n",
            "Epoch [3/3], Step [738/1349], Loss: 0.0868\n",
            "Epoch [3/3], Step [739/1349], Loss: 0.0615\n",
            "Epoch [3/3], Step [740/1349], Loss: 0.0046\n",
            "Epoch [3/3], Step [741/1349], Loss: 0.0231\n",
            "Epoch [3/3], Step [742/1349], Loss: 0.0588\n",
            "Epoch [3/3], Step [743/1349], Loss: 0.1047\n",
            "Epoch [3/3], Step [744/1349], Loss: 0.0928\n",
            "Epoch [3/3], Step [745/1349], Loss: 0.0393\n",
            "Epoch [3/3], Step [746/1349], Loss: 0.0233\n",
            "Epoch [3/3], Step [747/1349], Loss: 0.0142\n",
            "Epoch [3/3], Step [748/1349], Loss: 0.0872\n",
            "Epoch [3/3], Step [749/1349], Loss: 0.2464\n",
            "Epoch [3/3], Step [750/1349], Loss: 0.0059\n",
            "Epoch [3/3], Step [751/1349], Loss: 0.0403\n",
            "Epoch [3/3], Step [752/1349], Loss: 0.1088\n",
            "Epoch [3/3], Step [753/1349], Loss: 0.1747\n",
            "Epoch [3/3], Step [754/1349], Loss: 0.1513\n",
            "Epoch [3/3], Step [755/1349], Loss: 0.0687\n",
            "Epoch [3/3], Step [756/1349], Loss: 0.0621\n",
            "Epoch [3/3], Step [757/1349], Loss: 0.0612\n",
            "Epoch [3/3], Step [758/1349], Loss: 0.0098\n",
            "Epoch [3/3], Step [759/1349], Loss: 0.0611\n",
            "Epoch [3/3], Step [760/1349], Loss: 0.0199\n",
            "Epoch [3/3], Step [761/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [762/1349], Loss: 0.0139\n",
            "Epoch [3/3], Step [763/1349], Loss: 0.0356\n",
            "Epoch [3/3], Step [764/1349], Loss: 0.2135\n",
            "Epoch [3/3], Step [765/1349], Loss: 0.2399\n",
            "Epoch [3/3], Step [766/1349], Loss: 0.0379\n",
            "Epoch [3/3], Step [767/1349], Loss: 0.0778\n",
            "Epoch [3/3], Step [768/1349], Loss: 0.1196\n",
            "Epoch [3/3], Step [769/1349], Loss: 0.0212\n",
            "Epoch [3/3], Step [770/1349], Loss: 0.0221\n",
            "Epoch [3/3], Step [771/1349], Loss: 0.0477\n",
            "Epoch [3/3], Step [772/1349], Loss: 0.0487\n",
            "Epoch [3/3], Step [773/1349], Loss: 0.1378\n",
            "Epoch [3/3], Step [774/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [775/1349], Loss: 0.1085\n",
            "Epoch [3/3], Step [776/1349], Loss: 0.1620\n",
            "Epoch [3/3], Step [777/1349], Loss: 0.0398\n",
            "Epoch [3/3], Step [778/1349], Loss: 0.1914\n",
            "Epoch [3/3], Step [779/1349], Loss: 0.0487\n",
            "Epoch [3/3], Step [780/1349], Loss: 0.0175\n",
            "Epoch [3/3], Step [781/1349], Loss: 0.0907\n",
            "Epoch [3/3], Step [782/1349], Loss: 0.1023\n",
            "Epoch [3/3], Step [783/1349], Loss: 0.0160\n",
            "Epoch [3/3], Step [784/1349], Loss: 0.1115\n",
            "Epoch [3/3], Step [785/1349], Loss: 0.0102\n",
            "Epoch [3/3], Step [786/1349], Loss: 0.0220\n",
            "Epoch [3/3], Step [787/1349], Loss: 0.0318\n",
            "Epoch [3/3], Step [788/1349], Loss: 0.1416\n",
            "Epoch [3/3], Step [789/1349], Loss: 0.0440\n",
            "Epoch [3/3], Step [790/1349], Loss: 0.0142\n",
            "Epoch [3/3], Step [791/1349], Loss: 0.1093\n",
            "Epoch [3/3], Step [792/1349], Loss: 0.0389\n",
            "Epoch [3/3], Step [793/1349], Loss: 0.0173\n",
            "Epoch [3/3], Step [794/1349], Loss: 0.0356\n",
            "Epoch [3/3], Step [795/1349], Loss: 0.1121\n",
            "Epoch [3/3], Step [796/1349], Loss: 0.1922\n",
            "Epoch [3/3], Step [797/1349], Loss: 0.0328\n",
            "Epoch [3/3], Step [798/1349], Loss: 0.1173\n",
            "Epoch [3/3], Step [799/1349], Loss: 0.0602\n",
            "Epoch [3/3], Step [800/1349], Loss: 0.0225\n",
            "Epoch [3/3], Step [801/1349], Loss: 0.0637\n",
            "Epoch [3/3], Step [802/1349], Loss: 0.0129\n",
            "Epoch [3/3], Step [803/1349], Loss: 0.0071\n",
            "Epoch [3/3], Step [804/1349], Loss: 0.1641\n",
            "Epoch [3/3], Step [805/1349], Loss: 0.0611\n",
            "Epoch [3/3], Step [806/1349], Loss: 0.0115\n",
            "Epoch [3/3], Step [807/1349], Loss: 0.0501\n",
            "Epoch [3/3], Step [808/1349], Loss: 0.1385\n",
            "Epoch [3/3], Step [809/1349], Loss: 0.0624\n",
            "Epoch [3/3], Step [810/1349], Loss: 0.1565\n",
            "Epoch [3/3], Step [811/1349], Loss: 0.2405\n",
            "Epoch [3/3], Step [812/1349], Loss: 0.0197\n",
            "Epoch [3/3], Step [813/1349], Loss: 0.0730\n",
            "Epoch [3/3], Step [814/1349], Loss: 0.0745\n",
            "Epoch [3/3], Step [815/1349], Loss: 0.0091\n",
            "Epoch [3/3], Step [816/1349], Loss: 0.0299\n",
            "Epoch [3/3], Step [817/1349], Loss: 0.0672\n",
            "Epoch [3/3], Step [818/1349], Loss: 0.0169\n",
            "Epoch [3/3], Step [819/1349], Loss: 0.0362\n",
            "Epoch [3/3], Step [820/1349], Loss: 0.1831\n",
            "Epoch [3/3], Step [821/1349], Loss: 0.0314\n",
            "Epoch [3/3], Step [822/1349], Loss: 0.0327\n",
            "Epoch [3/3], Step [823/1349], Loss: 0.0690\n",
            "Epoch [3/3], Step [824/1349], Loss: 0.0456\n",
            "Epoch [3/3], Step [825/1349], Loss: 0.0912\n",
            "Epoch [3/3], Step [826/1349], Loss: 0.1503\n",
            "Epoch [3/3], Step [827/1349], Loss: 0.0930\n",
            "Epoch [3/3], Step [828/1349], Loss: 0.0373\n",
            "Epoch [3/3], Step [829/1349], Loss: 0.0737\n",
            "Epoch [3/3], Step [830/1349], Loss: 0.0198\n",
            "Epoch [3/3], Step [831/1349], Loss: 0.0115\n",
            "Epoch [3/3], Step [832/1349], Loss: 0.0221\n",
            "Epoch [3/3], Step [833/1349], Loss: 0.0098\n",
            "Epoch [3/3], Step [834/1349], Loss: 0.0598\n",
            "Epoch [3/3], Step [835/1349], Loss: 0.0230\n",
            "Epoch [3/3], Step [836/1349], Loss: 0.0632\n",
            "Epoch [3/3], Step [837/1349], Loss: 0.0607\n",
            "Epoch [3/3], Step [838/1349], Loss: 0.0792\n",
            "Epoch [3/3], Step [839/1349], Loss: 0.1275\n",
            "Epoch [3/3], Step [840/1349], Loss: 0.0082\n",
            "Epoch [3/3], Step [841/1349], Loss: 0.0753\n",
            "Epoch [3/3], Step [842/1349], Loss: 0.0967\n",
            "Epoch [3/3], Step [843/1349], Loss: 0.0834\n",
            "Epoch [3/3], Step [844/1349], Loss: 0.0312\n",
            "Epoch [3/3], Step [845/1349], Loss: 0.1838\n",
            "Epoch [3/3], Step [846/1349], Loss: 0.0245\n",
            "Epoch [3/3], Step [847/1349], Loss: 0.0361\n",
            "Epoch [3/3], Step [848/1349], Loss: 0.1323\n",
            "Epoch [3/3], Step [849/1349], Loss: 0.0753\n",
            "Epoch [3/3], Step [850/1349], Loss: 0.0253\n",
            "Epoch [3/3], Step [851/1349], Loss: 0.0803\n",
            "Epoch [3/3], Step [852/1349], Loss: 0.2047\n",
            "Epoch [3/3], Step [853/1349], Loss: 0.0674\n",
            "Epoch [3/3], Step [854/1349], Loss: 0.0484\n",
            "Epoch [3/3], Step [855/1349], Loss: 0.0815\n",
            "Epoch [3/3], Step [856/1349], Loss: 0.0996\n",
            "Epoch [3/3], Step [857/1349], Loss: 0.0247\n",
            "Epoch [3/3], Step [858/1349], Loss: 0.0701\n",
            "Epoch [3/3], Step [859/1349], Loss: 0.0841\n",
            "Epoch [3/3], Step [860/1349], Loss: 0.0634\n",
            "Epoch [3/3], Step [861/1349], Loss: 0.1370\n",
            "Epoch [3/3], Step [862/1349], Loss: 0.0241\n",
            "Epoch [3/3], Step [863/1349], Loss: 0.0177\n",
            "Epoch [3/3], Step [864/1349], Loss: 0.2082\n",
            "Epoch [3/3], Step [865/1349], Loss: 0.0686\n",
            "Epoch [3/3], Step [866/1349], Loss: 0.0051\n",
            "Epoch [3/3], Step [867/1349], Loss: 0.2095\n",
            "Epoch [3/3], Step [868/1349], Loss: 0.1189\n",
            "Epoch [3/3], Step [869/1349], Loss: 0.0906\n",
            "Epoch [3/3], Step [870/1349], Loss: 0.0397\n",
            "Epoch [3/3], Step [871/1349], Loss: 0.0141\n",
            "Epoch [3/3], Step [872/1349], Loss: 0.0910\n",
            "Epoch [3/3], Step [873/1349], Loss: 0.0069\n",
            "Epoch [3/3], Step [874/1349], Loss: 0.0154\n",
            "Epoch [3/3], Step [875/1349], Loss: 0.1259\n",
            "Epoch [3/3], Step [876/1349], Loss: 0.0639\n",
            "Epoch [3/3], Step [877/1349], Loss: 0.1020\n",
            "Epoch [3/3], Step [878/1349], Loss: 0.1653\n",
            "Epoch [3/3], Step [879/1349], Loss: 0.0101\n",
            "Epoch [3/3], Step [880/1349], Loss: 0.0506\n",
            "Epoch [3/3], Step [881/1349], Loss: 0.1413\n",
            "Epoch [3/3], Step [882/1349], Loss: 0.1170\n",
            "Epoch [3/3], Step [883/1349], Loss: 0.0323\n",
            "Epoch [3/3], Step [884/1349], Loss: 0.1704\n",
            "Epoch [3/3], Step [885/1349], Loss: 0.0483\n",
            "Epoch [3/3], Step [886/1349], Loss: 0.0686\n",
            "Epoch [3/3], Step [887/1349], Loss: 0.0161\n",
            "Epoch [3/3], Step [888/1349], Loss: 0.0201\n",
            "Epoch [3/3], Step [889/1349], Loss: 0.1888\n",
            "Epoch [3/3], Step [890/1349], Loss: 0.1657\n",
            "Epoch [3/3], Step [891/1349], Loss: 0.0584\n",
            "Epoch [3/3], Step [892/1349], Loss: 0.0784\n",
            "Epoch [3/3], Step [893/1349], Loss: 0.0738\n",
            "Epoch [3/3], Step [894/1349], Loss: 0.1266\n",
            "Epoch [3/3], Step [895/1349], Loss: 0.0992\n",
            "Epoch [3/3], Step [896/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [897/1349], Loss: 0.0283\n",
            "Epoch [3/3], Step [898/1349], Loss: 0.0216\n",
            "Epoch [3/3], Step [899/1349], Loss: 0.0323\n",
            "Epoch [3/3], Step [900/1349], Loss: 0.0272\n",
            "Epoch [3/3], Step [901/1349], Loss: 0.0416\n",
            "Epoch [3/3], Step [902/1349], Loss: 0.0770\n",
            "Epoch [3/3], Step [903/1349], Loss: 0.0664\n",
            "Epoch [3/3], Step [904/1349], Loss: 0.0926\n",
            "Epoch [3/3], Step [905/1349], Loss: 0.0901\n",
            "Epoch [3/3], Step [906/1349], Loss: 0.0160\n",
            "Epoch [3/3], Step [907/1349], Loss: 0.0485\n",
            "Epoch [3/3], Step [908/1349], Loss: 0.0493\n",
            "Epoch [3/3], Step [909/1349], Loss: 0.0093\n",
            "Epoch [3/3], Step [910/1349], Loss: 0.0942\n",
            "Epoch [3/3], Step [911/1349], Loss: 0.0293\n",
            "Epoch [3/3], Step [912/1349], Loss: 0.0623\n",
            "Epoch [3/3], Step [913/1349], Loss: 0.0428\n",
            "Epoch [3/3], Step [914/1349], Loss: 0.0710\n",
            "Epoch [3/3], Step [915/1349], Loss: 0.1022\n",
            "Epoch [3/3], Step [916/1349], Loss: 0.0409\n",
            "Epoch [3/3], Step [917/1349], Loss: 0.1154\n",
            "Epoch [3/3], Step [918/1349], Loss: 0.1411\n",
            "Epoch [3/3], Step [919/1349], Loss: 0.0524\n",
            "Epoch [3/3], Step [920/1349], Loss: 0.1013\n",
            "Epoch [3/3], Step [921/1349], Loss: 0.0784\n",
            "Epoch [3/3], Step [922/1349], Loss: 0.0141\n",
            "Epoch [3/3], Step [923/1349], Loss: 0.0030\n",
            "Epoch [3/3], Step [924/1349], Loss: 0.0116\n",
            "Epoch [3/3], Step [925/1349], Loss: 0.0080\n",
            "Epoch [3/3], Step [926/1349], Loss: 0.1092\n",
            "Epoch [3/3], Step [927/1349], Loss: 0.0109\n",
            "Epoch [3/3], Step [928/1349], Loss: 0.0647\n",
            "Epoch [3/3], Step [929/1349], Loss: 0.0449\n",
            "Epoch [3/3], Step [930/1349], Loss: 0.0303\n",
            "Epoch [3/3], Step [931/1349], Loss: 0.0293\n",
            "Epoch [3/3], Step [932/1349], Loss: 0.0126\n",
            "Epoch [3/3], Step [933/1349], Loss: 0.0476\n",
            "Epoch [3/3], Step [934/1349], Loss: 0.0507\n",
            "Epoch [3/3], Step [935/1349], Loss: 0.0624\n",
            "Epoch [3/3], Step [936/1349], Loss: 0.0899\n",
            "Epoch [3/3], Step [937/1349], Loss: 0.0456\n",
            "Epoch [3/3], Step [938/1349], Loss: 0.0093\n",
            "Epoch [3/3], Step [939/1349], Loss: 0.0590\n",
            "Epoch [3/3], Step [940/1349], Loss: 0.0596\n",
            "Epoch [3/3], Step [941/1349], Loss: 0.0816\n",
            "Epoch [3/3], Step [942/1349], Loss: 0.1288\n",
            "Epoch [3/3], Step [943/1349], Loss: 0.0150\n",
            "Epoch [3/3], Step [944/1349], Loss: 0.0711\n",
            "Epoch [3/3], Step [945/1349], Loss: 0.0031\n",
            "Epoch [3/3], Step [946/1349], Loss: 0.1475\n",
            "Epoch [3/3], Step [947/1349], Loss: 0.0655\n",
            "Epoch [3/3], Step [948/1349], Loss: 0.0124\n",
            "Epoch [3/3], Step [949/1349], Loss: 0.0711\n",
            "Epoch [3/3], Step [950/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [951/1349], Loss: 0.1030\n",
            "Epoch [3/3], Step [952/1349], Loss: 0.0173\n",
            "Epoch [3/3], Step [953/1349], Loss: 0.0114\n",
            "Epoch [3/3], Step [954/1349], Loss: 0.0309\n",
            "Epoch [3/3], Step [955/1349], Loss: 0.2524\n",
            "Epoch [3/3], Step [956/1349], Loss: 0.0706\n",
            "Epoch [3/3], Step [957/1349], Loss: 0.0717\n",
            "Epoch [3/3], Step [958/1349], Loss: 0.0134\n",
            "Epoch [3/3], Step [959/1349], Loss: 0.0014\n",
            "Epoch [3/3], Step [960/1349], Loss: 0.2138\n",
            "Epoch [3/3], Step [961/1349], Loss: 0.1007\n",
            "Epoch [3/3], Step [962/1349], Loss: 0.0128\n",
            "Epoch [3/3], Step [963/1349], Loss: 0.0320\n",
            "Epoch [3/3], Step [964/1349], Loss: 0.0190\n",
            "Epoch [3/3], Step [965/1349], Loss: 0.0603\n",
            "Epoch [3/3], Step [966/1349], Loss: 0.0641\n",
            "Epoch [3/3], Step [967/1349], Loss: 0.1362\n",
            "Epoch [3/3], Step [968/1349], Loss: 0.0137\n",
            "Epoch [3/3], Step [969/1349], Loss: 0.0335\n",
            "Epoch [3/3], Step [970/1349], Loss: 0.0474\n",
            "Epoch [3/3], Step [971/1349], Loss: 0.0199\n",
            "Epoch [3/3], Step [972/1349], Loss: 0.0194\n",
            "Epoch [3/3], Step [973/1349], Loss: 0.0278\n",
            "Epoch [3/3], Step [974/1349], Loss: 0.0727\n",
            "Epoch [3/3], Step [975/1349], Loss: 0.0278\n",
            "Epoch [3/3], Step [976/1349], Loss: 0.0381\n",
            "Epoch [3/3], Step [977/1349], Loss: 0.1326\n",
            "Epoch [3/3], Step [978/1349], Loss: 0.0834\n",
            "Epoch [3/3], Step [979/1349], Loss: 0.3676\n",
            "Epoch [3/3], Step [980/1349], Loss: 0.0164\n",
            "Epoch [3/3], Step [981/1349], Loss: 0.0959\n",
            "Epoch [3/3], Step [982/1349], Loss: 0.0359\n",
            "Epoch [3/3], Step [983/1349], Loss: 0.0350\n",
            "Epoch [3/3], Step [984/1349], Loss: 0.1200\n",
            "Epoch [3/3], Step [985/1349], Loss: 0.0040\n",
            "Epoch [3/3], Step [986/1349], Loss: 0.1536\n",
            "Epoch [3/3], Step [987/1349], Loss: 0.0147\n",
            "Epoch [3/3], Step [988/1349], Loss: 0.0259\n",
            "Epoch [3/3], Step [989/1349], Loss: 0.0893\n",
            "Epoch [3/3], Step [990/1349], Loss: 0.0145\n",
            "Epoch [3/3], Step [991/1349], Loss: 0.0352\n",
            "Epoch [3/3], Step [992/1349], Loss: 0.0148\n",
            "Epoch [3/3], Step [993/1349], Loss: 0.1239\n",
            "Epoch [3/3], Step [994/1349], Loss: 0.0267\n",
            "Epoch [3/3], Step [995/1349], Loss: 0.0480\n",
            "Epoch [3/3], Step [996/1349], Loss: 0.0124\n",
            "Epoch [3/3], Step [997/1349], Loss: 0.0190\n",
            "Epoch [3/3], Step [998/1349], Loss: 0.0750\n",
            "Epoch [3/3], Step [999/1349], Loss: 0.0672\n",
            "Epoch [3/3], Step [1000/1349], Loss: 0.1099\n",
            "Epoch [3/3], Step [1001/1349], Loss: 0.0351\n",
            "Epoch [3/3], Step [1002/1349], Loss: 0.0106\n",
            "Epoch [3/3], Step [1003/1349], Loss: 0.0562\n",
            "Epoch [3/3], Step [1004/1349], Loss: 0.0132\n",
            "Epoch [3/3], Step [1005/1349], Loss: 0.0838\n",
            "Epoch [3/3], Step [1006/1349], Loss: 0.0208\n",
            "Epoch [3/3], Step [1007/1349], Loss: 0.0442\n",
            "Epoch [3/3], Step [1008/1349], Loss: 0.0213\n",
            "Epoch [3/3], Step [1009/1349], Loss: 0.0850\n",
            "Epoch [3/3], Step [1010/1349], Loss: 0.0256\n",
            "Epoch [3/3], Step [1011/1349], Loss: 0.0762\n",
            "Epoch [3/3], Step [1012/1349], Loss: 0.1577\n",
            "Epoch [3/3], Step [1013/1349], Loss: 0.1176\n",
            "Epoch [3/3], Step [1014/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [1015/1349], Loss: 0.0272\n",
            "Epoch [3/3], Step [1016/1349], Loss: 0.0083\n",
            "Epoch [3/3], Step [1017/1349], Loss: 0.0594\n",
            "Epoch [3/3], Step [1018/1349], Loss: 0.0462\n",
            "Epoch [3/3], Step [1019/1349], Loss: 0.0685\n",
            "Epoch [3/3], Step [1020/1349], Loss: 0.0372\n",
            "Epoch [3/3], Step [1021/1349], Loss: 0.0234\n",
            "Epoch [3/3], Step [1022/1349], Loss: 0.0607\n",
            "Epoch [3/3], Step [1023/1349], Loss: 0.0384\n",
            "Epoch [3/3], Step [1024/1349], Loss: 0.0226\n",
            "Epoch [3/3], Step [1025/1349], Loss: 0.1727\n",
            "Epoch [3/3], Step [1026/1349], Loss: 0.0668\n",
            "Epoch [3/3], Step [1027/1349], Loss: 0.0189\n",
            "Epoch [3/3], Step [1028/1349], Loss: 0.0231\n",
            "Epoch [3/3], Step [1029/1349], Loss: 0.1402\n",
            "Epoch [3/3], Step [1030/1349], Loss: 0.1600\n",
            "Epoch [3/3], Step [1031/1349], Loss: 0.0566\n",
            "Epoch [3/3], Step [1032/1349], Loss: 0.0377\n",
            "Epoch [3/3], Step [1033/1349], Loss: 0.0678\n",
            "Epoch [3/3], Step [1034/1349], Loss: 0.0243\n",
            "Epoch [3/3], Step [1035/1349], Loss: 0.0945\n",
            "Epoch [3/3], Step [1036/1349], Loss: 0.1407\n",
            "Epoch [3/3], Step [1037/1349], Loss: 0.0680\n",
            "Epoch [3/3], Step [1038/1349], Loss: 0.0591\n",
            "Epoch [3/3], Step [1039/1349], Loss: 0.0594\n",
            "Epoch [3/3], Step [1040/1349], Loss: 0.0808\n",
            "Epoch [3/3], Step [1041/1349], Loss: 0.1541\n",
            "Epoch [3/3], Step [1042/1349], Loss: 0.0108\n",
            "Epoch [3/3], Step [1043/1349], Loss: 0.1932\n",
            "Epoch [3/3], Step [1044/1349], Loss: 0.0118\n",
            "Epoch [3/3], Step [1045/1349], Loss: 0.0862\n",
            "Epoch [3/3], Step [1046/1349], Loss: 0.0078\n",
            "Epoch [3/3], Step [1047/1349], Loss: 0.0024\n",
            "Epoch [3/3], Step [1048/1349], Loss: 0.0371\n",
            "Epoch [3/3], Step [1049/1349], Loss: 0.1165\n",
            "Epoch [3/3], Step [1050/1349], Loss: 0.0269\n",
            "Epoch [3/3], Step [1051/1349], Loss: 0.0877\n",
            "Epoch [3/3], Step [1052/1349], Loss: 0.0591\n",
            "Epoch [3/3], Step [1053/1349], Loss: 0.0680\n",
            "Epoch [3/3], Step [1054/1349], Loss: 0.0721\n",
            "Epoch [3/3], Step [1055/1349], Loss: 0.0167\n",
            "Epoch [3/3], Step [1056/1349], Loss: 0.0919\n",
            "Epoch [3/3], Step [1057/1349], Loss: 0.0084\n",
            "Epoch [3/3], Step [1058/1349], Loss: 0.1969\n",
            "Epoch [3/3], Step [1059/1349], Loss: 0.0734\n",
            "Epoch [3/3], Step [1060/1349], Loss: 0.0479\n",
            "Epoch [3/3], Step [1061/1349], Loss: 0.0187\n",
            "Epoch [3/3], Step [1062/1349], Loss: 0.0102\n",
            "Epoch [3/3], Step [1063/1349], Loss: 0.1221\n",
            "Epoch [3/3], Step [1064/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [1065/1349], Loss: 0.1775\n",
            "Epoch [3/3], Step [1066/1349], Loss: 0.0221\n",
            "Epoch [3/3], Step [1067/1349], Loss: 0.0251\n",
            "Epoch [3/3], Step [1068/1349], Loss: 0.0325\n",
            "Epoch [3/3], Step [1069/1349], Loss: 0.0568\n",
            "Epoch [3/3], Step [1070/1349], Loss: 0.0239\n",
            "Epoch [3/3], Step [1071/1349], Loss: 0.0095\n",
            "Epoch [3/3], Step [1072/1349], Loss: 0.1418\n",
            "Epoch [3/3], Step [1073/1349], Loss: 0.1308\n",
            "Epoch [3/3], Step [1074/1349], Loss: 0.0083\n",
            "Epoch [3/3], Step [1075/1349], Loss: 0.0854\n",
            "Epoch [3/3], Step [1076/1349], Loss: 0.1485\n",
            "Epoch [3/3], Step [1077/1349], Loss: 0.0751\n",
            "Epoch [3/3], Step [1078/1349], Loss: 0.0247\n",
            "Epoch [3/3], Step [1079/1349], Loss: 0.1505\n",
            "Epoch [3/3], Step [1080/1349], Loss: 0.1014\n",
            "Epoch [3/3], Step [1081/1349], Loss: 0.0490\n",
            "Epoch [3/3], Step [1082/1349], Loss: 0.0370\n",
            "Epoch [3/3], Step [1083/1349], Loss: 0.2996\n",
            "Epoch [3/3], Step [1084/1349], Loss: 0.0599\n",
            "Epoch [3/3], Step [1085/1349], Loss: 0.0566\n",
            "Epoch [3/3], Step [1086/1349], Loss: 0.0054\n",
            "Epoch [3/3], Step [1087/1349], Loss: 0.1863\n",
            "Epoch [3/3], Step [1088/1349], Loss: 0.1496\n",
            "Epoch [3/3], Step [1089/1349], Loss: 0.0269\n",
            "Epoch [3/3], Step [1090/1349], Loss: 0.0313\n",
            "Epoch [3/3], Step [1091/1349], Loss: 0.1486\n",
            "Epoch [3/3], Step [1092/1349], Loss: 0.0251\n",
            "Epoch [3/3], Step [1093/1349], Loss: 0.0537\n",
            "Epoch [3/3], Step [1094/1349], Loss: 0.0275\n",
            "Epoch [3/3], Step [1095/1349], Loss: 0.0163\n",
            "Epoch [3/3], Step [1096/1349], Loss: 0.0197\n",
            "Epoch [3/3], Step [1097/1349], Loss: 0.0326\n",
            "Epoch [3/3], Step [1098/1349], Loss: 0.0279\n",
            "Epoch [3/3], Step [1099/1349], Loss: 0.0742\n",
            "Epoch [3/3], Step [1100/1349], Loss: 0.0448\n",
            "Epoch [3/3], Step [1101/1349], Loss: 0.0331\n",
            "Epoch [3/3], Step [1102/1349], Loss: 0.2351\n",
            "Epoch [3/3], Step [1103/1349], Loss: 0.0388\n",
            "Epoch [3/3], Step [1104/1349], Loss: 0.1898\n",
            "Epoch [3/3], Step [1105/1349], Loss: 0.0882\n",
            "Epoch [3/3], Step [1106/1349], Loss: 0.0468\n",
            "Epoch [3/3], Step [1107/1349], Loss: 0.0510\n",
            "Epoch [3/3], Step [1108/1349], Loss: 0.1111\n",
            "Epoch [3/3], Step [1109/1349], Loss: 0.1263\n",
            "Epoch [3/3], Step [1110/1349], Loss: 0.0137\n",
            "Epoch [3/3], Step [1111/1349], Loss: 0.1069\n",
            "Epoch [3/3], Step [1112/1349], Loss: 0.0168\n",
            "Epoch [3/3], Step [1113/1349], Loss: 0.0533\n",
            "Epoch [3/3], Step [1114/1349], Loss: 0.0372\n",
            "Epoch [3/3], Step [1115/1349], Loss: 0.0197\n",
            "Epoch [3/3], Step [1116/1349], Loss: 0.0903\n",
            "Epoch [3/3], Step [1117/1349], Loss: 0.0418\n",
            "Epoch [3/3], Step [1118/1349], Loss: 0.0557\n",
            "Epoch [3/3], Step [1119/1349], Loss: 0.0173\n",
            "Epoch [3/3], Step [1120/1349], Loss: 0.1755\n",
            "Epoch [3/3], Step [1121/1349], Loss: 0.0546\n",
            "Epoch [3/3], Step [1122/1349], Loss: 0.0338\n",
            "Epoch [3/3], Step [1123/1349], Loss: 0.0056\n",
            "Epoch [3/3], Step [1124/1349], Loss: 0.0019\n",
            "Epoch [3/3], Step [1125/1349], Loss: 0.0510\n",
            "Epoch [3/3], Step [1126/1349], Loss: 0.0242\n",
            "Epoch [3/3], Step [1127/1349], Loss: 0.0352\n",
            "Epoch [3/3], Step [1128/1349], Loss: 0.0071\n",
            "Epoch [3/3], Step [1129/1349], Loss: 0.1206\n",
            "Epoch [3/3], Step [1130/1349], Loss: 0.0857\n",
            "Epoch [3/3], Step [1131/1349], Loss: 0.1787\n",
            "Epoch [3/3], Step [1132/1349], Loss: 0.0326\n",
            "Epoch [3/3], Step [1133/1349], Loss: 0.0210\n",
            "Epoch [3/3], Step [1134/1349], Loss: 0.0103\n",
            "Epoch [3/3], Step [1135/1349], Loss: 0.1403\n",
            "Epoch [3/3], Step [1136/1349], Loss: 0.0271\n",
            "Epoch [3/3], Step [1137/1349], Loss: 0.0971\n",
            "Epoch [3/3], Step [1138/1349], Loss: 0.0421\n",
            "Epoch [3/3], Step [1139/1349], Loss: 0.0164\n",
            "Epoch [3/3], Step [1140/1349], Loss: 0.2655\n",
            "Epoch [3/3], Step [1141/1349], Loss: 0.0398\n",
            "Epoch [3/3], Step [1142/1349], Loss: 0.1952\n",
            "Epoch [3/3], Step [1143/1349], Loss: 0.0935\n",
            "Epoch [3/3], Step [1144/1349], Loss: 0.0139\n",
            "Epoch [3/3], Step [1145/1349], Loss: 0.0183\n",
            "Epoch [3/3], Step [1146/1349], Loss: 0.1595\n",
            "Epoch [3/3], Step [1147/1349], Loss: 0.0205\n",
            "Epoch [3/3], Step [1148/1349], Loss: 0.1600\n",
            "Epoch [3/3], Step [1149/1349], Loss: 0.0211\n",
            "Epoch [3/3], Step [1150/1349], Loss: 0.0573\n",
            "Epoch [3/3], Step [1151/1349], Loss: 0.0053\n",
            "Epoch [3/3], Step [1152/1349], Loss: 0.0309\n",
            "Epoch [3/3], Step [1153/1349], Loss: 0.0425\n",
            "Epoch [3/3], Step [1154/1349], Loss: 0.0145\n",
            "Epoch [3/3], Step [1155/1349], Loss: 0.2107\n",
            "Epoch [3/3], Step [1156/1349], Loss: 0.1479\n",
            "Epoch [3/3], Step [1157/1349], Loss: 0.0127\n",
            "Epoch [3/3], Step [1158/1349], Loss: 0.0824\n",
            "Epoch [3/3], Step [1159/1349], Loss: 0.0900\n",
            "Epoch [3/3], Step [1160/1349], Loss: 0.0226\n",
            "Epoch [3/3], Step [1161/1349], Loss: 0.0370\n",
            "Epoch [3/3], Step [1162/1349], Loss: 0.0632\n",
            "Epoch [3/3], Step [1163/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [1164/1349], Loss: 0.1051\n",
            "Epoch [3/3], Step [1165/1349], Loss: 0.0448\n",
            "Epoch [3/3], Step [1166/1349], Loss: 0.0616\n",
            "Epoch [3/3], Step [1167/1349], Loss: 0.0755\n",
            "Epoch [3/3], Step [1168/1349], Loss: 0.0097\n",
            "Epoch [3/3], Step [1169/1349], Loss: 0.0069\n",
            "Epoch [3/3], Step [1170/1349], Loss: 0.0649\n",
            "Epoch [3/3], Step [1171/1349], Loss: 0.0521\n",
            "Epoch [3/3], Step [1172/1349], Loss: 0.0366\n",
            "Epoch [3/3], Step [1173/1349], Loss: 0.0095\n",
            "Epoch [3/3], Step [1174/1349], Loss: 0.0742\n",
            "Epoch [3/3], Step [1175/1349], Loss: 0.0196\n",
            "Epoch [3/3], Step [1176/1349], Loss: 0.0171\n",
            "Epoch [3/3], Step [1177/1349], Loss: 0.0157\n",
            "Epoch [3/3], Step [1178/1349], Loss: 0.0052\n",
            "Epoch [3/3], Step [1179/1349], Loss: 0.0190\n",
            "Epoch [3/3], Step [1180/1349], Loss: 0.1546\n",
            "Epoch [3/3], Step [1181/1349], Loss: 0.0844\n",
            "Epoch [3/3], Step [1182/1349], Loss: 0.0038\n",
            "Epoch [3/3], Step [1183/1349], Loss: 0.0536\n",
            "Epoch [3/3], Step [1184/1349], Loss: 0.0058\n",
            "Epoch [3/3], Step [1185/1349], Loss: 0.1062\n",
            "Epoch [3/3], Step [1186/1349], Loss: 0.0113\n",
            "Epoch [3/3], Step [1187/1349], Loss: 0.0528\n",
            "Epoch [3/3], Step [1188/1349], Loss: 0.0905\n",
            "Epoch [3/3], Step [1189/1349], Loss: 0.0495\n",
            "Epoch [3/3], Step [1190/1349], Loss: 0.1468\n",
            "Epoch [3/3], Step [1191/1349], Loss: 0.0092\n",
            "Epoch [3/3], Step [1192/1349], Loss: 0.1085\n",
            "Epoch [3/3], Step [1193/1349], Loss: 0.0492\n",
            "Epoch [3/3], Step [1194/1349], Loss: 0.0015\n",
            "Epoch [3/3], Step [1195/1349], Loss: 0.1612\n",
            "Epoch [3/3], Step [1196/1349], Loss: 0.0108\n",
            "Epoch [3/3], Step [1197/1349], Loss: 0.0870\n",
            "Epoch [3/3], Step [1198/1349], Loss: 0.0236\n",
            "Epoch [3/3], Step [1199/1349], Loss: 0.0376\n",
            "Epoch [3/3], Step [1200/1349], Loss: 0.0063\n",
            "Epoch [3/3], Step [1201/1349], Loss: 0.0148\n",
            "Epoch [3/3], Step [1202/1349], Loss: 0.1086\n",
            "Epoch [3/3], Step [1203/1349], Loss: 0.0341\n",
            "Epoch [3/3], Step [1204/1349], Loss: 0.1221\n",
            "Epoch [3/3], Step [1205/1349], Loss: 0.0260\n",
            "Epoch [3/3], Step [1206/1349], Loss: 0.0844\n",
            "Epoch [3/3], Step [1207/1349], Loss: 0.0878\n",
            "Epoch [3/3], Step [1208/1349], Loss: 0.0899\n",
            "Epoch [3/3], Step [1209/1349], Loss: 0.0238\n",
            "Epoch [3/3], Step [1210/1349], Loss: 0.0680\n",
            "Epoch [3/3], Step [1211/1349], Loss: 0.0649\n",
            "Epoch [3/3], Step [1212/1349], Loss: 0.0351\n",
            "Epoch [3/3], Step [1213/1349], Loss: 0.0186\n",
            "Epoch [3/3], Step [1214/1349], Loss: 0.0197\n",
            "Epoch [3/3], Step [1215/1349], Loss: 0.0364\n",
            "Epoch [3/3], Step [1216/1349], Loss: 0.0017\n",
            "Epoch [3/3], Step [1217/1349], Loss: 0.0706\n",
            "Epoch [3/3], Step [1218/1349], Loss: 0.0782\n",
            "Epoch [3/3], Step [1219/1349], Loss: 0.0055\n",
            "Epoch [3/3], Step [1220/1349], Loss: 0.0269\n",
            "Epoch [3/3], Step [1221/1349], Loss: 0.0359\n",
            "Epoch [3/3], Step [1222/1349], Loss: 0.0012\n",
            "Epoch [3/3], Step [1223/1349], Loss: 0.0042\n",
            "Epoch [3/3], Step [1224/1349], Loss: 0.0231\n",
            "Epoch [3/3], Step [1225/1349], Loss: 0.2575\n",
            "Epoch [3/3], Step [1226/1349], Loss: 0.1012\n",
            "Epoch [3/3], Step [1227/1349], Loss: 0.1390\n",
            "Epoch [3/3], Step [1228/1349], Loss: 0.0209\n",
            "Epoch [3/3], Step [1229/1349], Loss: 0.0104\n",
            "Epoch [3/3], Step [1230/1349], Loss: 0.1072\n",
            "Epoch [3/3], Step [1231/1349], Loss: 0.0678\n",
            "Epoch [3/3], Step [1232/1349], Loss: 0.0017\n",
            "Epoch [3/3], Step [1233/1349], Loss: 0.0147\n",
            "Epoch [3/3], Step [1234/1349], Loss: 0.0550\n",
            "Epoch [3/3], Step [1235/1349], Loss: 0.0480\n",
            "Epoch [3/3], Step [1236/1349], Loss: 0.0046\n",
            "Epoch [3/3], Step [1237/1349], Loss: 0.0023\n",
            "Epoch [3/3], Step [1238/1349], Loss: 0.1804\n",
            "Epoch [3/3], Step [1239/1349], Loss: 0.0048\n",
            "Epoch [3/3], Step [1240/1349], Loss: 0.0041\n",
            "Epoch [3/3], Step [1241/1349], Loss: 0.0037\n",
            "Epoch [3/3], Step [1242/1349], Loss: 0.0453\n",
            "Epoch [3/3], Step [1243/1349], Loss: 0.0873\n",
            "Epoch [3/3], Step [1244/1349], Loss: 0.0959\n",
            "Epoch [3/3], Step [1245/1349], Loss: 0.0339\n",
            "Epoch [3/3], Step [1246/1349], Loss: 0.1471\n",
            "Epoch [3/3], Step [1247/1349], Loss: 0.0143\n",
            "Epoch [3/3], Step [1248/1349], Loss: 0.1282\n",
            "Epoch [3/3], Step [1249/1349], Loss: 0.0360\n",
            "Epoch [3/3], Step [1250/1349], Loss: 0.1455\n",
            "Epoch [3/3], Step [1251/1349], Loss: 0.0074\n",
            "Epoch [3/3], Step [1252/1349], Loss: 0.0083\n",
            "Epoch [3/3], Step [1253/1349], Loss: 0.1312\n",
            "Epoch [3/3], Step [1254/1349], Loss: 0.0057\n",
            "Epoch [3/3], Step [1255/1349], Loss: 0.0167\n",
            "Epoch [3/3], Step [1256/1349], Loss: 0.1728\n",
            "Epoch [3/3], Step [1257/1349], Loss: 0.0055\n",
            "Epoch [3/3], Step [1258/1349], Loss: 0.0212\n",
            "Epoch [3/3], Step [1259/1349], Loss: 0.1885\n",
            "Epoch [3/3], Step [1260/1349], Loss: 0.0431\n",
            "Epoch [3/3], Step [1261/1349], Loss: 0.0196\n",
            "Epoch [3/3], Step [1262/1349], Loss: 0.0085\n",
            "Epoch [3/3], Step [1263/1349], Loss: 0.0399\n",
            "Epoch [3/3], Step [1264/1349], Loss: 0.0202\n",
            "Epoch [3/3], Step [1265/1349], Loss: 0.1525\n",
            "Epoch [3/3], Step [1266/1349], Loss: 0.0239\n",
            "Epoch [3/3], Step [1267/1349], Loss: 0.0015\n",
            "Epoch [3/3], Step [1268/1349], Loss: 0.0069\n",
            "Epoch [3/3], Step [1269/1349], Loss: 0.0081\n",
            "Epoch [3/3], Step [1270/1349], Loss: 0.0573\n",
            "Epoch [3/3], Step [1271/1349], Loss: 0.0317\n",
            "Epoch [3/3], Step [1272/1349], Loss: 0.0528\n",
            "Epoch [3/3], Step [1273/1349], Loss: 0.0177\n",
            "Epoch [3/3], Step [1274/1349], Loss: 0.0196\n",
            "Epoch [3/3], Step [1275/1349], Loss: 0.0242\n",
            "Epoch [3/3], Step [1276/1349], Loss: 0.0427\n",
            "Epoch [3/3], Step [1277/1349], Loss: 0.0243\n",
            "Epoch [3/3], Step [1278/1349], Loss: 0.0091\n",
            "Epoch [3/3], Step [1279/1349], Loss: 0.0140\n",
            "Epoch [3/3], Step [1280/1349], Loss: 0.0285\n",
            "Epoch [3/3], Step [1281/1349], Loss: 0.0215\n",
            "Epoch [3/3], Step [1282/1349], Loss: 0.0578\n",
            "Epoch [3/3], Step [1283/1349], Loss: 0.0156\n",
            "Epoch [3/3], Step [1284/1349], Loss: 0.0262\n",
            "Epoch [3/3], Step [1285/1349], Loss: 0.0479\n",
            "Epoch [3/3], Step [1286/1349], Loss: 0.0576\n",
            "Epoch [3/3], Step [1287/1349], Loss: 0.0131\n",
            "Epoch [3/3], Step [1288/1349], Loss: 0.0952\n",
            "Epoch [3/3], Step [1289/1349], Loss: 0.0879\n",
            "Epoch [3/3], Step [1290/1349], Loss: 0.0096\n",
            "Epoch [3/3], Step [1291/1349], Loss: 0.0244\n",
            "Epoch [3/3], Step [1292/1349], Loss: 0.0277\n",
            "Epoch [3/3], Step [1293/1349], Loss: 0.0365\n",
            "Epoch [3/3], Step [1294/1349], Loss: 0.0374\n",
            "Epoch [3/3], Step [1295/1349], Loss: 0.0282\n",
            "Epoch [3/3], Step [1296/1349], Loss: 0.1702\n",
            "Epoch [3/3], Step [1297/1349], Loss: 0.0153\n",
            "Epoch [3/3], Step [1298/1349], Loss: 0.0571\n",
            "Epoch [3/3], Step [1299/1349], Loss: 0.0413\n",
            "Epoch [3/3], Step [1300/1349], Loss: 0.0106\n",
            "Epoch [3/3], Step [1301/1349], Loss: 0.0430\n",
            "Epoch [3/3], Step [1302/1349], Loss: 0.0776\n",
            "Epoch [3/3], Step [1303/1349], Loss: 0.0034\n",
            "Epoch [3/3], Step [1304/1349], Loss: 0.0100\n",
            "Epoch [3/3], Step [1305/1349], Loss: 0.0191\n",
            "Epoch [3/3], Step [1306/1349], Loss: 0.0087\n",
            "Epoch [3/3], Step [1307/1349], Loss: 0.0363\n",
            "Epoch [3/3], Step [1308/1349], Loss: 0.0487\n",
            "Epoch [3/3], Step [1309/1349], Loss: 0.0520\n",
            "Epoch [3/3], Step [1310/1349], Loss: 0.0806\n",
            "Epoch [3/3], Step [1311/1349], Loss: 0.1046\n",
            "Epoch [3/3], Step [1312/1349], Loss: 0.0540\n",
            "Epoch [3/3], Step [1313/1349], Loss: 0.0599\n",
            "Epoch [3/3], Step [1314/1349], Loss: 0.0290\n",
            "Epoch [3/3], Step [1315/1349], Loss: 0.0494\n",
            "Epoch [3/3], Step [1316/1349], Loss: 0.0237\n",
            "Epoch [3/3], Step [1317/1349], Loss: 0.0009\n",
            "Epoch [3/3], Step [1318/1349], Loss: 0.0129\n",
            "Epoch [3/3], Step [1319/1349], Loss: 0.1622\n",
            "Epoch [3/3], Step [1320/1349], Loss: 0.0072\n",
            "Epoch [3/3], Step [1321/1349], Loss: 0.0681\n",
            "Epoch [3/3], Step [1322/1349], Loss: 0.0345\n",
            "Epoch [3/3], Step [1323/1349], Loss: 0.0200\n",
            "Epoch [3/3], Step [1324/1349], Loss: 0.2086\n",
            "Epoch [3/3], Step [1325/1349], Loss: 0.0637\n",
            "Epoch [3/3], Step [1326/1349], Loss: 0.0479\n",
            "Epoch [3/3], Step [1327/1349], Loss: 0.0011\n",
            "Epoch [3/3], Step [1328/1349], Loss: 0.0164\n",
            "Epoch [3/3], Step [1329/1349], Loss: 0.1057\n",
            "Epoch [3/3], Step [1330/1349], Loss: 0.0166\n",
            "Epoch [3/3], Step [1331/1349], Loss: 0.0389\n",
            "Epoch [3/3], Step [1332/1349], Loss: 0.0225\n",
            "Epoch [3/3], Step [1333/1349], Loss: 0.0037\n",
            "Epoch [3/3], Step [1334/1349], Loss: 0.1601\n",
            "Epoch [3/3], Step [1335/1349], Loss: 0.0718\n",
            "Epoch [3/3], Step [1336/1349], Loss: 0.0462\n",
            "Epoch [3/3], Step [1337/1349], Loss: 0.1121\n",
            "Epoch [3/3], Step [1338/1349], Loss: 0.0771\n",
            "Epoch [3/3], Step [1339/1349], Loss: 0.0730\n",
            "Epoch [3/3], Step [1340/1349], Loss: 0.0445\n",
            "Epoch [3/3], Step [1341/1349], Loss: 0.0155\n",
            "Epoch [3/3], Step [1342/1349], Loss: 0.2205\n",
            "Epoch [3/3], Step [1343/1349], Loss: 0.0385\n",
            "Epoch [3/3], Step [1344/1349], Loss: 0.0526\n",
            "Epoch [3/3], Step [1345/1349], Loss: 0.0471\n",
            "Epoch [3/3], Step [1346/1349], Loss: 0.0881\n",
            "Epoch [3/3], Step [1347/1349], Loss: 0.0468\n",
            "Epoch [3/3], Step [1348/1349], Loss: 0.0371\n",
            "Epoch [3/3], Step [1349/1349], Loss: 0.0058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test\n"
      ],
      "metadata": {
        "id": "bRpcsbfudkXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predicted_labels = torch.max(outputs, 1)\n",
        "\n",
        "# Move predictions and labels to CPU for sklearn metrics\n",
        "predicted_labels = predicted_labels.cpu().numpy()\n",
        "y_test = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "precision = precision_score(y_test, predicted_labels, average='weighted')\n",
        "recall = recall_score(y_test, predicted_labels, average='weighted')\n",
        "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
        "classification_rep = classification_report(y_test, predicted_labels, target_names=['SELL', 'HOLD', 'BUY'])\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Model Precision: {precision:.2f}\")\n",
        "print(f\"Model Recall: {recall:.2f}\")\n",
        "print(f\"Model F1 Score: {f1:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-4epidBIHlR",
        "outputId": "537d609e-31b7-4d30-9b21-2ae5418c79df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.99\n",
            "Model Precision: 0.99\n",
            "Model Recall: 0.99\n",
            "Model F1 Score: 0.99\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        SELL       1.00      0.99      0.99      3093\n",
            "        HOLD       0.99      0.99      0.99      4216\n",
            "         BUY       0.99      1.00      0.99      3479\n",
            "\n",
            "    accuracy                           0.99     10788\n",
            "   macro avg       0.99      0.99      0.99     10788\n",
            "weighted avg       0.99      0.99      0.99     10788\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate predictions for X_test\n"
      ],
      "metadata": {
        "id": "gHuP37MLdVE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
        "    normalized_features, y, np.arange(len(y)), test_size=0.2, random_state=42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "action_mapping = {0: 'SELL', 1: 'HOLD', 2: 'BUY'}\n",
        "transformer_actions = [action_mapping[pred.item()] for pred in predictions]\n",
        "\n",
        "timestamp = pd.to_datetime(data.loc[test_indices, 'ts_event'])\n",
        "symbol = data.loc[test_indices, 'symbol']\n",
        "\n",
        "transformer_results_df = pd.DataFrame({\n",
        "    'timestamp': timestamp,\n",
        "    'symbol': symbol,\n",
        "    'predicted_action': transformer_actions,\n",
        "})\n",
        "\n",
        "transformer_results_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tBWf_2AnNx0R",
        "outputId": "043d76ab-9dd8-4df4-94f4-d95d0f6bea19"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          timestamp symbol predicted_action\n",
              "6976  2023-07-03 13:33:00.369389502   AAPL             HOLD\n",
              "44896 2023-07-03 15:45:02.864795506   AAPL              BUY\n",
              "44691 2023-07-03 15:43:09.480320052   AAPL             HOLD\n",
              "7789  2023-07-03 13:34:10.406059043   AAPL             HOLD\n",
              "13297 2023-07-03 13:46:18.374664839   AAPL             SELL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f10fcf15-8235-48c8-b08c-331ac6c8d64a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>symbol</th>\n",
              "      <th>predicted_action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6976</th>\n",
              "      <td>2023-07-03 13:33:00.369389502</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>HOLD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44896</th>\n",
              "      <td>2023-07-03 15:45:02.864795506</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>BUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44691</th>\n",
              "      <td>2023-07-03 15:43:09.480320052</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>HOLD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7789</th>\n",
              "      <td>2023-07-03 13:34:10.406059043</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>HOLD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13297</th>\n",
              "      <td>2023-07-03 13:46:18.374664839</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>SELL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f10fcf15-8235-48c8-b08c-331ac6c8d64a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f10fcf15-8235-48c8-b08c-331ac6c8d64a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f10fcf15-8235-48c8-b08c-331ac6c8d64a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35defaad-4656-4d66-ae01-0bb8d11cb84f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35defaad-4656-4d66-ae01-0bb8d11cb84f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35defaad-4656-4d66-ae01-0bb8d11cb84f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "transformer_results_df",
              "summary": "{\n  \"name\": \"transformer_results_df\",\n  \"rows\": 10788,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-07-03 08:00:01.478356044\",\n        \"max\": \"2023-07-03 16:51:14.810769798\",\n        \"num_unique_values\": 8543,\n        \"samples\": [\n          \"2023-07-03 14:42:40.366950502\",\n          \"2023-07-03 14:04:49.985376432\",\n          \"2023-07-03 13:51:16.016782515\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_action\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HOLD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}